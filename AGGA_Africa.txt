1. Artificial Intelligence for Teaching & Learning 

 

The availability and uptake of generative Artificial Intelligence (AI) tools such as ChatGPT is impacting on the ways in which staff and students in universities teach, learn and assess. There are both risks and opportunities for an educational future shaped by the availability of AI tools, and both staff and students need to be aware of these in the context of the field of study and teaching of their discipline. The technologies themselves are rapidly evolving but there is an emerging consensus that students and staff need to develop ways of ethically using these technologies, be aware of the constraints and limitations but also the potential for innovation and enhancement in teaching and learning. 

In response to teaching staff questions and as a way of keeping abreast of developments and issues, we have developed a series of guides for both staff and students. 

AI Resource Guides 

These guides are regularly updated to keep up with the fast-changing AI landscape. Written during May-July 2023, they aim to provide current information and will be continuously refreshed to include significant developments. 

1.1. Staff Guide: Assessment and academic integrity in the age of AI 

Discover our staff guide addressing the challenges surrounding assessments in light of the widespread accessibility of generative artificial intelligence tools. This guide delves into various issues and offers practical strategies, approaches, and recommended tools to safeguard academic integrity. Stay informed and learn how to effectively mitigate the potential threats posed by AI tools in the assessment process. 

AI tools such as ChatGPT have sparked vigorous debates about assessments at universities. There are concerns around plagiarism and cheating as well as questions when it is appropriate for students to use AI. There have been calls for changes in the ways assessments are conceived, while others propose a return to paper-based only assessment strategies. Although AI tools have been on the horizon, access to ChatGPT compelled educational institutions to develop responses. How we respond will vary, so this guide presents a range of suggestions. 

ChatGPT, which stands for Chat Generative Pre-Trained Transformer uses neural transformer networks to generate text. It and otherAI tools such as Bard and Bing Chat are built on a category of AI tools known as ‘Large Language Models’ (LLM). These can perform various natural language processing tasks, such as, generate and classify text, provide answers to questions in a conversational style and translate texts from one language to another. These types of tools are commonly known as ‘generative AI’ which distinguishes them from other types of AI, already widely used in education (eg. writing aids such as Grammarly or Quillbot). The use of generative AI, such as ChatGPT requires the user to insert a language prompt. ChatGPT then splits out the words and makes a prediction of the best answer to the prompt based on the information it was trained on. 

AI tools like these might help to minimize some repetitive or administrative tasks. However, these tools can still pose risks of giving inaccurate information or producing a low-quality output. This despite the very confident way results are presented.  

Students have responded to these easy-to-access, powerful capabilities by using the tools for assessments, raising concerns about academic integrity. While the AI landscape and its effects on higher education are still being unpacked, there are attempts to circumvent the use of AI, such as by returning to more personal, handwritten and invigilated in-person exams. 

There have also been calls for adapting some assessments so that they discourage the use of AI. For example, if assessments involve a relatively simple fact recall that generative AI can respond to,  there may be enhanced ways to assess which can reduce tools like ChatGPT’s capacity to generate plausible answers. For instance, could the assessment also test students’ abilities to compare, use and analyse this knowledge? Or could an assessment include an interactive short oral presentation that can be scalable and effective? These strategies may not always be appropriate or practical. 

 

Communicating with your students 

 

AI literacies are becoming an essential skill. This involves developing an understanding of how the benefits must be balanced with the drawbacks. There is a need to equip our students with the necessary skills to navigate AI for their discipline.  

At the beginning of your course, communicate to your students what you consider to be appropriate uses of generative AI tools for their assessments. There will be a spectrum across the university. This may include a requirement for a declaration that either such AI tools have not been used or that the use of these tools be cited appropriately. If the use of AI is encouraged, you may want to specify tools or how/when students may use it. Consider conveying the following to your students: 

Specify whether generative AI tools can be used at the start of the course. It will be useful to have a discussion with your students about this to allow for questions. Lance Eaton’s ‘Syllabi Policies for Generative AI’ is a collection of statements used by different courses globally.  

Specify how the AI tool should be referenced (e.g., APA style) and if further declarations should be made (i.e., including the prompts used). 

Include conditions in the course plagiarism declaration/honour pledge or in the assignment submission instructions (see below). 

Provide further guidance to students on using AI (CILT student guide).  

Explain the consequences of academic dishonesty and inappropriate use of AI . (If you plan to make use of AI detection tools in the course, explain how you will go about verifying - see below).  The following adapted standard declaration can be used for your course with the additional clause on third party and software to generate assessments. You may use or alter this statement to suit the course’s needs.  It is not recommended to ban the outright use of artificial intelligence software as many existing tools (e.g., grammar and style tools) are AI-based. However, one can restrict the generation or creation of an assignment using AI software. 

 

Student plagiarism declaration 

Example of adapting a plagiarism declaration to include using artificial intelligence software: 

I know that plagiarism is wrong. Plagiarism is to use another’s work and pretend that it is one’s own.  

I have used the …………………….. convention for citation and referencing. Each contribution to, and quotation in, this essay/report/project/ ……………….. from the work(s) of other people has been attributed, and has been cited and referenced. Any section taken from an internet source has been referenced to that source.  

This essay/report/project/………………………… is my own work, and is in my own words 

(except where I have attributed it to others).   

I have not paid a third party to complete my work on my behalf. My use of artificial intelligence software has been limited to ……………….. (specify precisely how you used AI to assist with this assignment).  

I have not allowed and will not allow anyone to copy my work with the intention of passing it off as his or her own work.  

I acknowledge that copying someone else’s assignment or essay, or part of it, is wrong, and declare that this is my own work. 

Approaches used in other university plagiarism declarations may also be considered. The 

Liverpool University declaration specifies ‘no commissioned production’ that includes ChatGPT. 

Queens University, Belfast has a simple statement “I certify that the submission is my own work, all sources are correctly attributed, and the contribution of any AI technologies is fully acknowledged”. 

 

Academic integrity strategies 

 

Current generative AI can be used to ‘cheat’ on multiple choice quizzes, essays or coding assessments, and will undoubtedly continue to evolve. There are different ways to approach this challenge, as outlined by Michael Webb from JISC’s National Centre for AI in A Generative AI 

Primer. Where possible, the ‘embrace and adapt’ approach seems more likely to be effective and successful going forward. 

How students use generative AI tools for support 

 

Understanding more closely how students use generative AI tools for assessments is important. Popular uses of generative AI include summarising and paraphrasing long readings, generating ideas for assessment prompts, writing code, spelling and grammar checks (like Word and Grammarly), and generating practice questions for assessments. This may be analogous to how Wikipedia gives an introductory overview of a topic, which may be less of a concern or even encouraged. 

AI detection tools 

 

There is a concern that students are increasingly using AI tools to complete their assessments. In response, AI detection tools are being developed to flag parts of written assignments that could possibly have been AI generated, say for example, using ChatGPT. Unfortunately, the accuracy of these tools is generally poor. This accuracy is certainly not comparable to a plagiarism checker such as Turnitin.  

AI text detectors do not work in the same way as plagiarism checkers. A plagiarism checker such as Turnitin checks human generated text against other human generated text. AI text detectors estimate or guess the probability of text being written by AI. Some detectors were trained on datasets of human-written text and AI-written text to predict the probability that any given text was written by AI. Others work by looking for indicators within the text, such as linguistic patterns, repeated words or structural patterns. 

When using plagiarism detection or originality tools to identify AI generated text: 

There is a risk of falsely accusing students of plagiarism because detection errors are high.  

Assume any detector will be unreliable given the rapidly evolving changes in AI. 

Sharing student data by uploading it into a detector that is managed by a third-party company with unknown privacy and data usage policies is ethically and legally risky. 

In an empirical review of AI text generation detectors, Sadasivan et al. (2023) found “that several 

AI-text detectors are not reliable in practical scenarios”. In a research study Ibrahim et al. (2023) state that “current AI-text classifiers cannot reliably detect ChatGPT’s use in school work”.  The widespread use of other types of AI, such as Grammarly or Quillbot, further undermines accurate detection. The researchers found it was relatively easy to evade detection by running ”the ChatGPT- generated text through Quillbot— a popular paraphrasing/ rewriting tool utilized by students worldwide” resulting in rendering “these algorithms futile, failing to detect 95% of 

ChatGPT answers.” 

There are freely available tools that given AI generated text will reduce the chances of this being detected as AI generated. These are known as AI content detection bypassers. These tools claim to be able to “humanise” your AI generated text, often through paraphrasing. 

Given these issues, there is an emerging consensus within the academic community that detectors are not reliable and may cause harm to particular groups of students. AI detectors have been found to be more likely to label text written by “non-native English” speakers as AIwritten. In the study by Stanford researchers, further revealed a trend “where more literary language was classified as more ‘‘human’’: enhancement of word choice in non-native English writing samples reduced misclassification, while simplifying native writing samples increased it, suggesting that GPT detectors are inadvertently penalizing individuals with limited linguistic proficiency.” (Liang et al., 2023). 

Several AI detection tools are available, including Turnitin, Copyleaks, Content at Scale and Originality.AI, however none of these has proved totally reliable. Initial claims from the vendors suggested high accuracy but real world testing and empirical is revealing these purported accuracy rates are unreliable and need further scrutiny:    

Turnitin has backtracked on the initial claims after wider usage and testing. A number of universities have switched off the Turnitin detector including Wits and Vanderbilt University. 

OpenAI has shut down its own AI detector due to low accuracy rates. 

A sample of the more commonly used detectors’ webpages or terms of reference indicate they should not be used as a primary mode to determine whether a text is AI-generated (source AI detectors slide deck from Torrey Trust)  

Recommendations on  AI detection tools 

AI detectors should not be relied upon for accurately ascertaining or giving a definitive result as to whether text is AI or human generated. 

AI detection reports cannot be relied on as stand-alone evidence of whether a student submission has been AI generated in a disciplinary context. Staff should use AI detectors with care bearing in mind:  

the possibility of false positives, 

the relative ease in which detection can be evaded,  

AI detectors may disproportionately flag text written by non first language speakers as AI generated.  

 

Risks and concerns of using AI 

 

There are wider risks and concerns to be considered if you plan to use AI in your classroom that may not be immediately apparent. 

Relevance of data set: Generative AI may not have the latest information or developments in a field or topic. For example, ChatGPT version 3.5 was trained on data up until 2021. When proposing using AI tools, you should double-check its outputs and consult sources to ensure that the information provided is appropriate and accurate. 

Inaccuracies in what is generated: While AI outputs may come across as authoritative and convincing, its responses are based on next word predictions. The software has no real understanding. This leads to ‘hallucinations’ and allows it to produce disinformation (see why ChatGPT produces inaccuracies). It is important to evaluate this risk in the context of how you intend using generative AI. 

Bias in data fed: AI follows the ‘garbage-in-garbage out’ principle whereby if the data it has been fed is biased, then its responses will reflect that bias. There are a number of biases that are present in AI data, such as, historical, representative, algorithmic, ranking, behavioural and social biases (read more about bias and fairness in AI systems). You need to be aware of the potential bias in AI outputs and critically evaluate the information it produces.  

 

Dependence/Overreliance: Assignments serve the purpose of helping students learn and practice skills that we will need in society. While AI can help automate some tasks, it is important that students do not become overly reliant on it as this may hinder their ability to craft and think critically. Research suggests that being too reliant on AI can lead to loss of some important cognitive skills and prime us to think in a certain way. (See ChatGPT can homogenise our lives). 

 

Designing assessments for higher order thinking  

 

Courses involve different levels of knowledge. Generative AI is far less capable at higher levels. Table 1 shows examples of opportunities to adapt assessments to target these higher forms of learning. Additional tips include reviewing the grading mechanism and rubrics and reducing the emphasis on recall. 

Table 1: Assessment difficulty spectrum for AI (Adapted from Monash, 2023) 

Difficulty level 

Assessment type 

Explanation of use 

Easy 

MCQ quizzes and questions involving recall 

Generative AI can easily provide output to factoid or lowlevel questions, especially on widely taught topics. 

Easy 

	Generic 	short 

written assignments 



Generative AI can produce convincing essays and poems. For example, “Write a 1000-word essay on the history of Nelson Mandela”. 

Medium 

Scaffolded submissions 



Creating a scaffolded assignment allows students to build on their previous work and feedback. Include pre-writing and drafting in the assignment process. Verifiable sources and citations should be required 

Medium 

Personalised context-based assessment 

or 

A simple essay can be made more challenging by introducing personalisation. Encourage personalisation where students are asked to draw on personal experiences. Ask students to write to a particular audience whose knowledge and values must be considered amplifying their student voice. Ask questions that would require them to give a response that draws from concepts that were done in class, in a lab, field trip or real-life experiences in their contexts. 

Hard 

Projects 



Projects involving real-world applications give students the opportunity for meaningful learning experiences. 

Hard 

Oral tests / exam with Q&A / panels or 

discussions 

Synchronous oral assessment allows checking a student’s understanding of their submitted work and gives the opportunity to interrogate their submission with follow up questions and discussion. While time intensive for larger classes, some have found ways to use these strategies. 

 

Using  prompts for preparation 

 

Generative AI has also been explored for routine assessment tasks and anticipating what students might find. There are, of course, limitations and concerns. Investigating these uses can help to understand how the AI tool works, what routine tasks can be automated, and how your students may use it.  

Testing existing assessments  

Test your assignment briefs in an AI generative tool to see if it can be easily completed. Review the results and fine tune your prompts as a student would. Look closely at the output as while it may seem reasonable it may lack the finer details required from assignment briefs. 

Create quiz questions  

Generative AI tools, given a lecture transcript or notes, can then be asked to generate multiple choice questions with answer options. It is usually good at generating the quiz format, the questions and options will require substantial editing and checking before being used in a course.  

Prompt: "Read the following transcript from a lecture video and write 10 multiple choice quiz questions with 4 distractors each and feedback. Indicate the correct answer. This quiz should be pitched at a university level." 

Suggestions for improving prompts include avoiding making them overly complicated as the output will become confused. One may also suggest to ChatGPT or similar tool to ‘take the task step by step’ and to ‘rethink’ earlier responses if the generated output is not satisfactory.  

Create rubrics  

ChatGPT, Bing Chat or Bard can be asked to generate a marking rubric. The prompt could include details such as the total marks and details of the task being assessed. This short video shows how to Create a Marking Rubric With AI (ChatGPT) 

Prompt: “Generate a rubric out of 12 for a student assignment that requires them to create an app on Fliplet. These are university students studying in an education discipline.”  

 

Generate writing prompts 

ChatGPT or similar tools can generate possible writing prompts or sample data for a student assignment. Make sure to include the topic and theme in your prompt. 

Prompt: “Generate five essay topics on using AI for teaching school mathematics. The essay should be 1000 words in length and use an example of how AI is used in schools 

 

1.1.1. AI-proof checklist for your assessments 

 

An AI misuse or proof checklist (Table 2) may assist when planning new assessments. No assignment can be made completely “AI-proof”, but clear communications and reducing the likelihood that students could use AI tools inappropriately can be planned ahead. This is not to underestimate the time and potential resource implications of making changes to AI-proof assignments. 

Table 2: AI proofing checklist (Adapted from Turnitin, 2023) 

Criteria 

 

Does the assignment brief make explicit your institution and course’s academic integrity policy, especially regarding the use of AI text tools? 

 

Does the assignment brief communicate the acceptable and unacceptable limits of using generative AI tools for the student response?  

 

Does the assignment brief require critical thinking or reasoning? Does the assignment encourage/require student voice? 

 

Does the assignment brief require the student to incorporate personal stories and/ or authentic situations? 

 

Does the assignment brief require a list of verifiable sources and/or citations? Are students asked to include a reflection or rationale for their approach to the assignment solutions? 

 

Have you instituted checkpoints to review outlines or drafts throughout the course, rather than focusing on a final submission only? 

 

Have you included time for peer reviews and/or discussions on learning activities throughout the course or assignment? 

 

Have you run the assignment brief through an AI generative tool? 

 

 

 

  

1.2. Staff Guide: Teaching and learning with AI tools 

 

Explore our comprehensive guide on the uses of generative AI tools like ChatGPT in teaching and learning. Discover potential applications, examine ethical concerns, and access additional resources. 

Introduction 

 

ChatGPT has grabbed the headlines since its public release in November 2022. ChatGPT (https://chat.openai.com/), which stands for Chat Generative Pre-trained Transformer, has a basic version available to anyone who signs up for a free account while a more functional version (eg. ChatGPT Plus) is being released as a subscription service. It can perform various natural language processing tasks, such as, generating and classifying text, providing answers to questions in a conversational style and translating texts from one language to another.  

The AI definition has developed over time, but broadly AI is a range of technologies that perform cognitive tasks, through machine learning, natural language processing, data mining, neural networks or an algorithm (Zawacki-Richter et al., 2019).    

Some claim ChatGPT will become the ‘greatest cheating machine ever’ , while others suggest it will open new possibilities to augment our skills by helping to automate mundane and routine tasks. More AI tools are being developed, for example, Bing Chat and Google Bard which also operate using LLMs, like ChatGPT but access information from the internet, and focus more on operating as search tools. 

The explosion of interest reflects how the applications and uses  of AI are rapidly developing – including being used by students. As educators, we need to be keeping up to ensure that our teaching and learning is providing students with the skills and knowledge they need to navigate the world of AI.  

 

Setting expectations 

 

Outlining what faculties, programmes or departments expect from students and staff around the use of AI tools in teaching and learning, especially before any assessments are undertaken is essential.   

Instead of trying to stop students using AI, lay out expectations about the need to make visible and acknowledge the use of AI tools. Engagement with staff and students to promote debate and knowledge sharing is part of the development of new literacies for education and work.  

Some higher education institutions have ‘banned’ the use of AI and students using AI are considered to have been academically dishonest (University World News), with severe penalties. Using AI detection tools (for example, Turnitin) has been adopted as a screening mechanism in some contexts.  But detection tools are unreliable (see discussion from Monash University and CILT tests), and some universities explicitly refrain from using them because they risk students being wrongfully accused of cheating, or of evading detection. While academic integrity is a concern, taking a punitive approach is likely to drive practices underground rather than build key skills for the future.   

AI is here to stay, and higher education has to adapt to incorporate the emerging uses of the new technologies. However, we need to be mindful of the ethical issues associated with using AI in education. 

 

Ethics of Using ChatGPT (or similar tools) in education 

 

Academic integrity – There should be an emphasis on the distinction between using AI as an enabler or assistant and using AI as an authoring tool which impacts on academic integrity. Unless made explicit, it can be tempting for students to pass off AI generated work as their own, since it is not ‘copied’ as in the traditional form of plagiarism.   

Privacy risks – ChatGPT’s Privacy Policy clearly states that “By using our Service, you understand and acknowledge that your Personal Information will be processed and stored in our facilities and servers in the United States …” noting that the US privacy environment/legislation according to general consensus understanding is deemed to not be equivalent or better when assessing it against our own legislation. Refer Section 72 of POPIA.  The fundamental take away is no personal information should be submitted to ChatGPT.   

Inaccuracies – AI outputs are known to include inaccurate information, limited by the training dataset exposure and the AI’s capacity to ‘hallucinate’. This means that AI tools like ChatGPT have a high risk of spreading misinformation, given it has no capacity to distinguish right from wrong, correct from incorrect.   

Built in-biases – AI trained off data sets which contain implicit and explicit biases (overlooking local knowledge, lack of cultural diversity, dominance of Western hegemonic knowledge; baked in racism, sexism, and other undesirable values)  

Exploitation of labour – there have been allegations of exploitative labour practices in the training of AI   

Accessibility – there is a risk that those with poorer access to connectivity, devices, data and literacies will get unequal access to the opportunities being provided by AI. More powerful AI capabilities will be marketized and only available to those with resources (which has already happened with ChatGPT Plus and DALL-E, the visual generator).  In a context with existing inequality, planning the use of tools such as these for teaching and learning should be cognizant of access.   

 

 

Important literacies associated with AI   

 

There are three core literacies (AI, Critical and Information literacy) required for all stakeholders to navigate AI effectively and ought to be considered as part of graduate attributes. 

 

 

 

AI Literacy  

 

AI literacy involves sound knowledge about the basic functions of AI, ability to ethically apply AI knowledge, concepts and applications in different scenarios and ability to critically evaluate AI technologies, communicate and collaborate effectively with AI (Ng et al., 2021). AI literacy includes understanding what AI can be used for, what it does not do well and how to acknowledge its use (see Monash University library advice and  APA citation style for  ChatGPT as an example).  

Users need to understand the basic operation of the models and be familiar with the inherent limits of the systems they are making use of – for example, the lack of ‘common sense’ or real understanding which allows for unrealistic or inaccurate answers. An infographic developed by UNESCO provides basic guidelines about when it is safe to use ChatGPT, which could also be applied to other AI tools. 

A new skill required is learning “prompt engineering”, which means how best to formulate the questions that provide the parameters and guidelines for how the AI should respond. 

 Here are some guidelines for writing requests for generative AI summarised from an extended article on using ChatGPT for Higher Education and Professional Development (Atlas, 2023; pp.41-48):  

Choose your words carefully   

Begin by defining the purpose and focus   

Be specific and concise  

Provide context   

Ask for more; or stop and redirect     

 

 

Critical literacy  

 

This involves the questioning and examination of ideas, and requires you to synthesise, analyse, interpret, evaluate and respond to the texts you read or listen to (see the University of Melbourne for some ideas for interrogating text). Bearing in mind that the Large Language Models (LLMs) are based on predictions and only have access to the dataset of information they are trained on, and that AI generated information is not always accurate and authentic, students need to be critically literate. With the responses generated from the Large Language Models, which are usually well formulated in terms of grammar, syntax and natural language expressions, making them sound authoritative and plausible, the value of learning the skills for critical literacy, which is a traditional learning outcome of higher education, is even more important.   

This may mean creating orientation modules, courses or components of courses that build students’ capacity to effectively understand and apply AI tools both in their educational projects and their professional domain areas of expertise.  Designing learning activities which challenge students to interact with AI to get a sense of its capabilities, and to evaluate its value and outputs can be incorporated into all courses and programmes. Treating AI as another tool in teaching and learning which students are expected to gain skills and competence in shifts it out of the underground world of cheating or short cuts to becoming a resource for achieving tasks.  

 

Information literacy  

 

Given the potential and capacity of AI in education, it becomes imperative that rapid upskilling all incoming students in information literacy - "the ability to use critical thinking to create meaningful knowledge from information" (Claremont Colleges Library Information Literacy Steering Group) - is a baseline part of their induction into university. That is, students need to be able to identify what information is required to complete their assignments or assessments, and then evaluate this information and communicate it in an ethical and legal manner (see how this group frames the Critical Information Literacy Habits of Mind). 

Early assessment and training on information literacy for effective learning is critical. Ensure that all first-year students attend visits to the UCT Libraries for such assistance. 

AI and academic integrity 

 

The use of AI tools by students for assessments is being seen as a challenge in higher education globally. The current AI capabilities can be used to ‘cheat’ at simple multiple choice, basic essay or coding assessments, and will undoubtedly continue to improve. As educators, there are several ways to approach this challenge, as outlined by Michael Webb from JISC’s National Centre for AI in A Generative AI Primer. 

 

 

 

Where possible, the ‘embrace and adapt’ approach seems more likely to be effective and successful. In the companion CILT guide: Staff Guide to Assessment and Academic Integrity in the age of AI we outline in more detail ways in which you can design and think about assessments that embrace and adapt to AI tools.  

 

Roles and uses to explore for AI tools in teaching and learning  

 

While we must be responsible in how we use the emerging capabilities of technology, there are also interesting new opportunities to be explored, depending on your context and your students. The list of use cases below is not exhaustive but provides a glimpse of the enormous potential for deployment in teaching and learning. 

 

Staff 

Students 

Content Creation 

Adaptive Learning Materials 



Using AI to generate educational materials such as lesson plans, quizzes, and interactive content 

Students accessing adaptive learning materials that adjust difficulty levels based on their progress 

Intelligent Tutoring Systems 

Deploying AI-powered tutoring systems that adapt to individual student needs 

Virtual Mentors 

Accessing virtual mentors, powered by AI, to provide guidance and support throughout their learning journey 

Automated Administrative Tasks 

Utilising AI for automating administrative tasks such as scheduling, and record-keeping 

Language Learning Support 

Using AI-based language learning tools that simulate conversations, provide instant feedback, and generate language exercises 

Adaptive Learning Paths 

Creating personalised learning paths for students based on their individual progress and learning styles 

Personalised Learning Paths 

Students receiving tailored learning paths based on their individual strengths and weaknesses 

Virtual Reality Simulations 

Integrating AI with virtual reality technology to create immersive educational simulations 

Personalised Assessments 

Students taking assessments that dynamically adjust difficulty levels based on their performance and provide personalized feedback 

Automated Quiz Grading 

Utilising AI algorithms to automatically grade objective assignments 

Study and Homework Assistance 

Accessing AI-powered study and homework assistance tools that provide explanations, suggestions, and resources 

Learning Analytics 

Applying AI to analyse learning patterns and provide actionable 	insights to optimise instruction 

Skill Development and Practice 

Using AI-based platforms to develop and practice specific skills, such as coding or language proficiency 

Rubric categories 

Generate a marking rubric for an open-ended topic 

Personalised Study Schedules 

Students receiving AI-generated study schedules tailored to their preferences and optimal learning times 

Natural Language Processing 

Utilising AI's natural language processing capabilities for tasks like automated language translation, question-answering systems, and text analysis 

Concept Understanding and Reinforcement AI-powered tools that help students understand and reinforce complex concepts through interactive explanations, visualisations, and practice exercises 

 

The UNESCO Quick Guide has also outlined 10 educational ‘roles’ for AI tools ranging from ‘Socratic opponent’ to ‘study buddy’ and ‘dynamic assessor’.  

If you make use of AI for teaching, please share your experiences in this form, so we can create new appropriate cases from our own context.  

 

What AI tools are there for education? 

 

While ChatGPT has won the media headlines, there are many ways in which AI is being built into a variety of tools and platforms to use in education and industry. Here are a few examples for you to explore (some may require a payment while others are free).  

Interactive (ChatGPT, YouChat, ChatSonic) 

Writing/text (QuillBot, Sudowrite, WriteSonic, Jasper, You, Moonbeam)  

Visual AI (DALL E2, Midjourney) 

Research and publishing (Perplexity AI, Researcher Life, Elicit, Sci Space) 

The  Futuretools website offers an extensive list of AI tools for various activities (you can filter for free tools).  

  

1.3. Student Guide: Using ChatGPT and other AI tools in education 

 

Explore our comprehensive guide on the uses of generative AI tools like ChatGPT in teaching and learning. Discover potential applications, examine ethical concerns, and access additional resources. 

The purpose of this guide is to take you through some of the current debates about the risks and benefits of using artificial intelligence and more particularly, ChatGPT for learning. To effectively make use of the ChatGPT tool, it is important to know how it generates its outputs. 

 

 

 

 

What is AI? 

 

The Artificial Intelligence (AI) definition has developed over time, from “the science and engineering of making intelligent machines” in 1956 (McCarthy, 2007, p.2) to broader ones describing AI as a range of technologies that perform intellectual learning tasks, such as machine learning, natural language processing, data mining, neutral networks or an algorithm (ZawackiRichter et al., 2019). AI has become an integral part of various applications and settings. As AI evolves, a powerful branch called generative AI is emerging. This type of AI can create new content, like text, images, and code. ChatGPT, CoPilot and Google Bard are examples of generative AI. 

What’s the big deal with generative AI such as ChatGPT?  

ChatGPT (https://chat.openai.com/), which stands for Chat Generative Pre-trained Transformer, has gained a lot of attention since its release in November 2022. Currently, anyone can sign up for a free account using version 3.5, although improved versions (eg. ChatGPT Plus) are a paid-for service. 

It is a software in the form of a chatbot that was developed by OpenAI. It is built on a category of AI tools known as ‘Large Language Models’ (LLM), which can perform various natural language processing tasks, such as generating and classifying text, providing answers to questions in a conversational style and translating texts from one language to another.    

Some claim ChatGPT will become the ‘greatest cheating machine ever’, while others argue that it will open new possibilities to enhance or improve our skills as the tool that can help automate mundane and routine tasks.  

More AI tools are being developed, which also operate using LLMs, like ChatGPT but access information from the internet, and focus more on operating as search tools. 

 

How does ChatGPT generate its outputs?  

 

ChatGPT is a software that generates its outputs using natural language processing algorithms. When a user inputs a prompt, it analyses the prompt using its trained knowledge and generates a response. ChatGPT’s trained knowledge is based on a vast amount of text data that it has been fed from the Internet. Its outputs are thus only as good as the data it has been trained on. If the training data contains misinformation and biases, then its outputs will reflect those issues.   

As a software which produces its response based on algorithms, it lacks understanding of realworld experiences, social and cultural distinctions. The responses it produces thus may not be contextually relevant or lack real understanding. These mechanisms that govern how ChatGPT produces its responses lead to some risks in using ChatGPT or similar AI tools.  

 

Risks and Ethics of using ChatGPT (or similar tools) in education  

 

While ChatGPT can help you with your learning or preparing for an assignment, its outputs may be outdated or contain errors and biases. Here are some risks associated with using ChatGPT:     

Inaccuracies in data fed: While ChatGPT’s outputs may come across as reliable and convincing, its responses are based on next word predictions. The software has no real understanding, and no capacity to distinguish right from wrong, or correct from incorrect. ChatGPT-3.5, as an AI has the capacity to ‘hallucinate’ and produce misinformation. It is important to evaluate and verify ChatGPT responses and not take the information generated as given. Read more about why ChatGPT produces inaccuracies. 

Built-in biases: AI is trained off data sets which contain implicit/indirect and explicit/direct biases, including overlooking local knowledge, lack of cultural diversity, dominance of Western influential knowledge; baked in racism, sexism, and other undesirable values (read more about bias and fairness in AI systems). ChatGPT follows the ‘garbage-in-garbage out’ principle, meaning if the data it has been fed is biased, then its responses will reflect that bias. You need to be aware of the potential bias in ChatGPT’s outputs and critically evaluate the information it produces. There have  also been allegations of unfair/ exploitative labour practices in the training of AI.  

Relevance of data fed: ChatGPT-3.5 is trained on data that is publicly available up until January 2022. It, thus, may not have the latest information or developments in a field or topic. When using ChatGPT, you should double-check its outputs and consult sources to ensure that the information provided is up-to-date and relevant. 

Dependence/Overreliance: Assignments serve the purpose of helping us learn and practice skills that we will need in society. While ChatGPT can help automate some tasks, it is important that you do not become overly reliant on it so that it hinders your ability to craft and think critically for yourself. Research suggests that being too reliant on ChatGPT can lead to loss of some important cognitive skills and prime us to think in a certain way. You can read more about how ChatGPT can homogenise our lives.   

Now that you know how ChatGPT generates its outputs and the risks and ethical considerations associated with it, let’s look at how you can effectively use the tool to help you learn better. 

 

How ChatGPT can help you in your learning processes? 

 

AI tools are here to stay and can be used to aid your learning but should not be used to complete your assignments. There are several ways ChatGPT can be used effectively in your learning, such as the examples below:  

 

 

Figure 1: Less-risky ways of using ChatGPT for effective learning (adapted from the 2023 

UNESCO  Quick Start Guide: ChatGPT and Artificial Intelligence in higher education) Here are other AI tools to explore:    

Generative AI (Google Bard, CoPilot)  

Writing/text (QuillBot, Sudowrite, WriteSonic, Jasper, You, Moonbeam)   

Visual AI (DALL E2, DALL E3, Midjourney)  

Media generation (AI-generated art) 

Research and publishing (Perplexity AI, Researcher Life, Elicit, Sci Space),  

However, it is important for you to know what is permitted in your course so you can make informed decisions. To begin with, check the university, department and course policies around academic integrity and plagiarism, and ask your lecturer to clarify about the use of AI for course assessments.  

 

AI Tools and Academic Integrity  

 

You need to make sure you do not use AI tools inappropriately and be accused of plagiarism. It may be tempting to pass off AI generated work as your own, since it is not ‘copying’ other students’ work but unless you declare it, generating assignments using ChatGPT means it is not your own work. Assessments are designed to test your understanding of a subject and your ability to apply that knowledge and to prepare you for the workplace. If you use AI to simply write your assessment the value of the assessment would be diminished; you may not develop the required skills for your future studies or career, and you could be accused of plagiarism. 

 

“Plagiarism is the misappropriation of others’ words, thoughts and ideas by presenting them as one’s own, and is treated very seriously in the academic world. Under no circumstances is it acceptable to present the work of others as your own.”  UCT Author-date Reference Guide: based on the Harvard referencing style (2016)  

The distinction between using AI as an enabler or assistant and using AI as an authoring tool has an impact on academic integrity – using AI tools for assistance can be done effectively without plagiarising. Not all lecturers and supervisors will have the same views, so check first, but the following are some examples of appropriate and questionable uses of generative AI. 

 

D

O 

Uses of generative AI  at university likely to be acceptable 

DON

’T 

Uses of generative AI at university likely to be unacceptable 

✔ 

Find out whether or how AI tools can be used for each assignment before starting 

x 

Use AI tools when they are specifically prohibited 

✔ 

Attribute the use of AI (eg APA style) 

x 

Use AI tools without acknowledgement 

✔ 

Use AI as a prompt for an outline (unless specifically prohibited)  

x 

Copy an AI output and pass it off as your own work 

✔ 

Brainstorm ideas or request summaries of information  

x 

Trust AI outputs without doing a critical check for facts and sources 

✔ 

Ask ChatGPT to rephrase a difficult concept into simpler language  

x 

			Share 	any 	personal 	information

or  upload copyrighted materials  

✔ 

Save your prompts and the outputs in case you are challenged about your use 

x 

Use AI tools when original content is being expected 

 

 

First ask the lecturers and tutors for guidance about using AI tools for the course assessments. Always validate outputs from ChatGPT or other AI tools – that is, applying critical literacy skills to evaluate content. 

Make sure that the final product is your own work, and not just copied from an AI generator. You can use the generated text as a learning tool to formulate initial ideas or to suggest an essay structure, but the final submitted assessment must be your own work, creation, and analysis.  You must appropriately acknowledge where AI generative tools have been used in an assessment or any other part of your work, clearly indicate where you have used the AI generative tool and the extent to which it was used. Using AI-generated content without acknowledgement is a breach of academic integrity that may result in academic misconduct allegations and subsequent consequences.  

 

The UCT Code of Conduct  

 

UCT RULES ON CONDUCT FOR STUDENTS       

Student Rules - Academic conduct  

RCS2.3 

A student may not submit the work of any other person in any examination, test or in respect of the completion and/or submission of any other form of academic assessment without full and proper attribution and acknowledgement - dishonest conduct. 

NOTE: Guidance on forms of referencing is available from academic staff, the staff of the UCT Libraries and from the Writing Centre. 

 

1.4. Student Guide: Developing effective prompts for generative AI tools 

 

Prompting involves crafting effective strategies to engage with generative AI tools. Clearer instructions result in more accurate outputs. Ambiguous prompts are more likely to produce inaccurate outputs. This guide summarises productive prompting strategies and common practices. 

Prompting involves crafting effective strategies to engage with generative AI tools. Clearer instructions result in more accurate outputs. Ambiguous prompts are more likely to produce inaccurate outputs. This guide summarises productive prompting strategies and common practices.  

 

Understanding how generative AI works 

  

The natural language style of generative AI tools invites us to “think about a prompt as a conversation” (White, 2023a; Cathey, 2023). However, these are NOT human conversations, even though they mimic human interactions. Generative AI uses large language models (LLMs) that are responding to your inputs by trying to predict a next likely word (see A Generative AI Primer). By crafting prompts one can control and direct what is generated so it becomes more useful. 

 

The growing number of generative AI tools (for example, ChatGPT, Bard, Bing Chat, Claude) all have some differences around how they operate and the data on which they were trained. One large distinguisher is the amount of prompt information they permit, some also allow you to upload documents or images to assist with the tasks. Trying more than one platform is useful to get a sense of their capabilities and weaknesses.  

Whichever platform you select, the prompting strategies will be similar. We have included a short, 

‘cheat sheet’ approach below, and a longer explanation of specific prompt patterns you can adopt.   

 

Prompts ‘cheat sheet’ 

 

You can use the acronym CREATE, as a shorthand approach to writing prompts: Clarity, Revelant info, Examples, Avoid Ambiguity, Tinker, Evaluate (Barrett, 2023)  

 

Clarity 

Clearly define the task or intent of the prompt, including specific information about the output. 

Relevant info 

Provide relevant details, including specific keywords and facts, the tone, audience, format, and structure.  

Examples 

Use examples in the prompt to provide context and direction for the output. 

Avoid ambiguity 

Focus on the key information and delete unnecessary details in the prompt. 

Tinker 

Test and refine the prompt through multiple iterations. Explore different input versions to discover the best results. Try different platforms.  

Evaluate 

Continuously evaluate the output and adjust the prompt as needed to improve the quality.  

 

Giving a context is more likely to generate the results you anticipated. The following pattern strategies are more directive and can be used when prompting.   

 

Useful prompt patterns strategies 

 

Prompt engineering is an emerging discipline which refers to the development of prompts to efficiently use generative AI tools for a wide variety of applications. But anyone can draw on these ideas to improve the phrasing of queries to generate outputs. There are many emerging frameworks for prompt engineering, but since this guide is not concerned with the technical aspects, we simply use the term ‘prompting’ to refer to crafting the best approach to engage a generative AI tool.   The guide offers an introduction to some of the most widely used pattern-based strategies for AI tools (White et al., 2023; Corrall, 2023; Alattas, 2023; Ismuguzel, 2023). Each of the strategies is briefly explained and a longer illustrative example of how this pattern can be used is linked to the Addendum.   

The strategies are roughly grouped into three prompting pattern types:  

Patterns based on inputs and outputs.  

Role playing   

Audience 

Patterns based on refining and interrogating the questions.  

Question refinement  

Cognitive verification  

Flipped interaction  

Patterns based on specifying a template.  

 

Patterns based on inputs and outputs 

 

These are prompts that specify what kind of input the model should expect and what kind of output it should generate. For example, the role-playing or persona pattern requires you to ask the AI tool to assume the role of an expert, or a specified character. The audience pattern defines exactly for whom the output is intended. You could combine both patterns in a series of prompts.    

 

Role-playing Pattern 

This type of prompt instructs the AI tool to respond from the perspective of a specific persona or role. This may range from assuming the appropriate tone to having the AI tool take on a coaching or teaching role for you. In specifying a role, you can also formulate your expectation of the output. Before prompting, you may want to also provide examples of your writing style, or the output style you want. 

Best for: delivering more tailored and accurate outputs with the correct tone Here is an example of a role-playing prompt: 

Your role as a coding tutor is to create personalized study plans to help first year university students learn how to code in the Python language. Your responsibilities will include understanding the goals, time commitment, and preferred learning resources of each student, and using that information to develop a comprehensive study plan with clear timelines and links to relevant resources. You should be able to adapt your teaching style to meet the individual needs of each student and provide ongoing support and guidance throughout the learning process. Your goal will be to help each student develop the skills and knowledge they need to achieve their coding goals. 

Prompt format: Act as persona X. Provide information about topic Y. Nyakundi (2023) suggests using the 5 Ws framework in formulating role-based prompts.  

Who – specify the role you need the AI tool to assume.  

What – indicate the action you require the AI tool to perform.  

When – specify the timeframe in which the AI tool must complete its task.  

Where – specify the location or context of your prompt.  

Why – articulate the motivation, reasoning, or goals governing the prompts.  

 

Remember that the more specifications you give, the more tailored results you will get. Tip: The role does not have to be human; you can ask the AI to pretend to be an inanimate object like a database or a Linux machine.  

 

     Worked Example: Applying the Role-playing 

Pattern 

 

Audience Pattern   

The Audience Pattern moves the focus to who is reading the outputs. When formulating this type of prompt, you should request information from the AI tool for a specific audience (Corrall, 2023, White et al., 2023). 

 

Prompt format: 

Explain X to me.  

Assume that I am persona Y. 

 

Best for: Tasks such as summarizing, translating, paraphrasing, or captioning.   

 

Prompt format example:  

Please help me write helpful information for university researchers. The writing style should be similar. I want you to understand this writing style so I will provide some examples. Remember my writing style as being PATTERN_STYLE. Afterwards when I ask you to write using 

PATTERN_STYLE, then use this style of writing. (afterwards provide example paragraphs) 

 

     Worked Example: Applying the Audience 

Pattern 

 

Patterns based on refining and interrogating the questions 

   

Another approach is to focus on refining and interrogating the questions you give the AI tools and making use of the AI’s capacity to enhance your prompts. Three related patterns are the question refinement pattern, the cognitive verification pattern and the flipped interaction pattern which asks the AI to come up with better formulated questions, asks the AI to fact check its answers or asks the AI to solicit more information from you.   

Best for: Approaching complex tasks or ambiguous queries, providing explanations or justifications, or checking facts or logic.  Question Refinement Pattern  

This type of prompt enables you to utilize the AI tool’s capabilities to help in framing a question to arrive at an accurate answer (White et al., 2023) by suggesting a better version of the question to use instead. 

Prompt format: 

When I ask a question, suggest a better version of the question to use instead.  

Optional: Ask me if I would like to use the better version instead. 

 

Applying the Question Refinement Pattern  

 

     Worked Examples: Exchange 1 showcases a basic version of this. 

       This method of prompting can also be further refined for specificity, see Exchange 2.  

 

Cognitive Verification Pattern  

This type of prompt has the user providing the AI tool with rules on how to respond to secure a comprehensive answer. It involves subdividing the initial question into smaller ones that may aid in informing the response. The aim is to improve the accuracy of the AI tool’s response to the main question by forcing it to incorporate potentially omitted pieces of information.  

Prompt format example: (adapted from White et al., 2023: 5): 

When I ask a question, follow these rules. Generate a few additional questions that would help you answer the question more accurately. Combine the answers to the individual questions to produce the final answer to the question. Assume I know little about the topic we are discussing and please define any terms that are not general knowledge. When I have answered three of your questions, combine the answers to produce the final answer to my original question. 

 

Step 1: Start by specifying ‘when you are asked a question, follow these rules’.  

Step 2: Generate sub-questions that would help answer the question more accurately.  

Ask the AI tool to generate questions in response to the first question with the aim of using that additional input to answer the question more accurately. You can also specify how many subquestions the AI tool can ask and provide additional question refinement in the form of context.   Step 3: Instruct the AI tool to combine your answers to the sub-questions it provides to produce the final answer to the main (overall) question. Once the AI tool acknowledges your instructions, ask your question. 

 

     Worked Example: Applying the Cognitive Verifier Pattern 

 

 

Flipped Interaction Pattern  

In this approach, you instruct the AI tool to generate questions for you to answer to enable it to improve the required output.   

Example:  

I want to create a workshop plan to develop a strategic plan for my organisation for the coming year. You should ask me questions until you have enough information to create the lesson plan. 

Ask one question at a time. 

 

It consists of two steps:  

Step 1: Specify the goal of the interaction, e.g. I want you to ask me questions to achieve X (replace X with the desired goal). Focus on a particular topic or outcome.  

Step 2: Specify the duration of the interaction and/or the number of questions it can ask, e.g. You should ask me questions until you have sufficient information to produce the desired outcome.   

After inputting the above steps, prompt the AI tool to ask you the first question, e.g. “Ask me the first question.”  

This pattern can be a useful tool for getting an AI tool to provide you with your required output based on questions it asks you. While similar to the Cognitive Verifier pattern (in which the AI tool is also asked to generate questions), it places more onus on the AI tool to ask you clarifying questions until it can generate the required output. 

 

✅   Worked Example: Applying the Flipped Interaction Pattern 

 

 

Patterns which use a standard template   

 

Template Pattern  

This method constitutes an attempt to control the structure and context of the AI tool output by providing the data and specifying a template to be used to format the information provided. You need to know, beforehand, what formatting components your AI tool will recognize to be able to respond appropriately/accurately. 

A template pattern exchange contains the following steps:  

Step 1: Specify about a template, e.g. “I am going to provide a template for your output.”  

Step 2: Indicate the format of the placeholder you will use. This must be something that the AI tool has been trained on, such as using ALL CAPS, enclosing in brackets/markup tags, etc. For example, “CAPITALIZED WORDS are my placeholders.”  

Step 3: Instruct the AI tool to fit the output into one or more of the placeholders provided, e.g., 

“Fill in my placeholders with your output.”/ “Any time that you generate text, try to fit it into one of the placeholders that I list.”  

 

 

Step 4: Instruct the AI tool to not deviate from the template by trying to include other elements, e.g. “Please preserve the formatting and overall template that I provide.”  While this is a useful way to control the output of the AI tool, a potential drawback of this pattern is that specified template components may exclude potentially useful information.    

Best for: Tasks that require following a fixed structure or format for the output, such as generating computer code, specific poetic styles or technical reports.  

 

✅   Worked Example: Applying the Template Pattern in ChatGPT  

There are many other types of prompts that you can explore, such as prompts that use keywords, provide detailed examples, partial input, instructions, or contextual information.  

 

 

Take away points 

 

It is worth spending time developing your queries or prompts to get the best results. Try more than one type of prompt and consider using different AI tools depending on what you are seeking so you can get to know their strengths.  

Assume you will have multiple interactions until you get the desired result. Keep refining your prompt based on the responses you received previously and keep asking for further refinements. You can include many conditions and specific qualifiers in your questions.   Your approach should be iterative so that each set of output improves on the previous one. Use your existing knowledge to tailor each request to make it as specific and relevant as possible (White, 2023c).  

It is also possible to combine patterns, and you should experiment to see what gets you the best results. Here is one example: 

“From now on, whenever I ask a question, ask four additional questions that would help you produce a better version of my original question (Cognitive verification pattern). Then, use my answers to suggest a better version of my original question (Question refinement pattern). After the follow-up questions, temporarily act as a user with no knowledge of AWS and define any terms that I need to know to accurately answer the questions (Role playing pattern).” (White et al., 2023: 10, our annotation)  

Be aware of the in-built bias which can skew your results, particularly that the training data will be largely based on content available on the open internet which is dominated by mainstream knowledge and languages. To control for the bias, give explicit instructions and use consciously inclusive language.  

  

The following illustrates the power of prompts to skew outputs and demonstrates the importance of refining and evaluating first responses. 

 

First Prompt  

Provide a list of the most successful entrepreneurs of all time.  

Bard response 

Generates a list of 10 business leaders from the USA (Andrew Carnegie, John 

Rockefeller, Thomas Edison, Oprah Winfrey, Sam Walton, Charles Schwab, 

Steve Jobs, George Bezos, Bill Gates, Elon Musk)  

	Follow 	up 

prompt  

This list comprises people from the USA only. Please revise the list to be more globally representative.  

Bard  

Provides a list with 10 people mostly from Asian countries (Jack Ma, Masayoshi Son, Bernard Arnault, Amancio Ortega, He Xiangjian, Lei Jun, Ren Zhengfei, 

Ma Huateng, Lee Byung-chul, Chung Ju-yung, Azim Premji)  

Additional 

	follow 	up 

prompt   

Review the first and second lists you produced and provide a new list of the top 10 entrepreneurs globally, based on ranking the success of the companies they are associated with.  

Bard  

Here is a list of the top 10 most successful entrepreneurs globally, based on the success of their companies: (Elon Musk; Jeff Bezos; Bill Gates; Mark Zuckerberg; Jack Ma; Masayoshi Son; Bernard Arnault; Amancio Ortega; He 

Xiangjian; Lei Jun)  

 

While it is possible to provide the AI tool with information that may assist it to generate the required output, remember that this information could also be incorporated into the server on which the tool runs and then may become accessible to other users of that tool (White, 2023a).  Always view Generative AI as a tool that can offer assistance, never an author. Take responsibility and critically review any outputs before using them. 

 

Addendum: AI Prompt Pattern Examples 

Role-Playing (Persona) Patterns 

Prompt  

Act as a 3D modelling teacher who uses Blender 3D. A student is struggling to conceptualize procedural nodes-based 3D modelling. Provide a metaphor for understanding the concept of nodes-based 3D modelling and help the student understand when to use traditional modelling and when to use procedural modelling. Include some points on getting started with some simple nodes as a way of getting started successfully. 

Bing chat 

 

   

 

Hello, this is Bing. I can help you with learning 3D modelling using Blender 3D.  

One way to understand the concept of nodes-based 3D modelling is to think of it as a recipe for creating a 3D object. A recipe consists of ingredients and instructions that tell you how to combine them to make a dish. Similarly, a nodes-based 3D model consists of nodes and links that tell you how to manipulate them to create a shape. 

 

Nodes are like the ingredients of the recipe. They are the basic building blocks that can store or generate data, such as colors, textures, coordinates, vectors, etc. Links are like the instructions of the recipe. They are the connections that transfer data from one node to another, creating a flow of information. 

 

By using nodes and links, you can create complex and realistic 3D models without having to manually sculpt or edit every detail. You can also easily change or tweak any aspect of the model by adjusting the nodes or links, without affecting the rest of the model. 



 

Some advantages of using nodes-based 3D modelling are: 

It allows you to create procedural models, which are models that are generated by an algorithm rather than by hand. Procedural models can have infinite variations and details, and can be easily customized or randomized.  

It saves you time and memory, as you don’t have to store or load large amounts of geometry or texture data. You only need to store or load the nodes and links that define the model.  

It gives you more control and flexibility, as you can modify any part of the model by changing the nodes or links, without affecting the rest of the model. Some disadvantages of using nodes-based 3D modelling are: 

It has a steep learning curve, as you need to understand how different types of nodes work and how to connect them properly.  

It can be difficult to achieve precise or specific results, as you have to rely on the algorithm rather than your own intuition or vision.  

It can be slow or unstable, as it requires more computation power and memory to process the nodes and links.  

 

When to use traditional modelling and when to use procedural modelling?  

There is no definitive answer to this question, as it depends on your personal preference, style, and goals. However, some general guidelines are:  

Use traditional modelling when you want to create simple or stylized models, such as low-poly or cartoon-like models. Traditional modelling gives you more direct control and feedback over the shape and appearance of your model. 

Use procedural modelling when you want to create complex or realistic models, such as landscapes, plants, rocks, clouds, etc. Procedural modelling allows you to generate detailed and varied models with less effort and time. 

 

How to get started with some simple nodes?  

A good way to get started with nodes-based 3D modelling is to use the Geometry Nodes Editor in Blender 3D. The Geometry Nodes Editor is a tool that lets you create and edit nodes-based 3D models in a visual way. 

 

To use the Geometry Nodes Editor, you need to follow these steps:  

Create a new Geometry Nodes Modifier on an object in your scene. This will open the Geometry Nodes Editor window.  

In the Geometry Nodes Editor window, you will see two default nodes: a Geometry Node and a Group Output Node. The Geometry Node represents the input geometry of your object, and the Group Output Node represents the output geometry of your modifier.  

To add new nodes, press Shift + A and select a node from the menu. You can choose from different categories of nodes, such as Input, Output, Attribute, Geometry, Mesh, Point, etc.  

To connect nodes, drag a link from an output socket (the circles on the right side of a node) to an input socket (the circles on the left side of a node). You can also cut links by pressing Ctrl + Left Click on them.  

To edit node properties, select a node and look at the sidebar on the right side of the window. You can change various parameters such as values, colors, vectors, etc.  

To preview your model, look at the 3D viewport window. You can also toggle between solid and wireframe mode by pressing Z.  

 

Here is an example of a simple nodes-based 3D model that creates a sphere with random spikes:  

Geometry Node -> Point Distribute Node -> Point Instance Node -> Group Output Node  

Point Distribute Node: Density = 1000  

Point Instance Node: Geometry = Icosphere  

Icosphere: Radius = 0.1 

 

I hope this helps you understand the concept of nodes-based 3D modelling better. If you have any questions or feedback, please let me know. 

Here are some other role-playing pattern prompt examples for various subjects: 

 

Task  

Example of prompt  

Social sciences lecturers can use generative AI tools to construct historical role play activities. The same could be done for historical science figures.  

 

 

Hello ChatGPT, I am Nelson Mandela. I would like to 

 

discuss my political role in the anti-apartheid struggle.  

 

Students can be assigned a task that requires them to have a conversation with a Chatbot in the persona of that character.  

 

Can you play the role of Elizabeth Gilbert from Eat, Pray 

 

Love? I want to know more about your thoughts on self-

 

discovery and love.  

Students can role play as scientists conducting an experiment in a lab with specific roles can be given such as a researcher and lab technician.   

 

 Can you play the role of a Chemist who is testing and  comparing the density of water and ethanol?  

Chat bots can generate mathematical and science scenarios such as solving real-world math problems.  

Can you play the role of my mathematics teacher and  create a set of prompts that will help me to design a  propeller boat using mathematical concepts? Don’t give me the final answer but correct me as I move through the steps.  

Chat bots can generate real life type of scenarios where students communicate in a foreign language such as asking for directions to a stranger.  

 

 Can you please act as my kiSwahili tutor and tell me how  I can ask to buy tickets for a theatre show?  

 

 

Role-Playing (Persona) Pattern (Bard, Bing, and ChatGPT)  

 

Bard  

Bing  

ChatGPT  

Prompt: You are an object-oriented programming lecturer. 

Introduce students to Python programming language.  

  

The same prompt (displayed above) requesting the tool to act as a lecturer was entered into three generative AI tools and the following outcomes were noted:  

Bard provides different options for the answer in that three are immediately generated and can be toggled between. The style in which the answer is provided is much like what one might find in a textbook.  

Bing’s output has an interactive feel to it. It addresses the students in the way in which a lecturer would, provides an example that an explanation is included with and speaks to what will be covered in the next chapter.  

The output provided by ChatGPT is a combination of the styles of Bard and Bing in that it addresses the students in the way in which a lecturer would, but the content is written in a textbook style.  

Both Bard and Bing caution the user with regard to the generated code.  

 

All three tools followed the prompt without issue, but it would be the user’s decision to decide on the preferred output style and refine the interaction accordingly. The outputs can and should be edited with further prompts. 

 

 

Audience Pattern (ChatGPT 3.5) 

Prompt  

Explain information retrieval to me summarised in a set of bullet points. Assume I am a university mathematics lecturer. 

 

Chat GPT 

 



  

 

  

 



 

Certainly! Here's a summary of information retrieval in a set of bullet points: 

  

Definition: Information retrieval (IR) is a field in computer science and information science that focuses on the process of obtaining relevant information from large collections of data, typically text-based.  

 

Key Goals: 

Retrieve relevant documents or data in response to user queries.  

Evaluate and rank results based on relevance.  

Support efficient and effective access to information. 

 

Components: 

Document Collection: The set of documents, such as web pages, books, or articles, that the system searches through.  

Query: The user's request for information, usually expressed as a set of keywords or a longer natural language query.  

Indexing: The process of pre-processing and structuring documents for faster retrieval, often involving techniques like tokenization and stemming.  

Ranking: Determining the order in which documents are presented to the user based on their relevance to the query.  

 

Methods:  

Boolean Retrieval: Uses logical operators (AND, OR, NOT) to match documents based on the presence or absence of keywords.  

Vector Space Models: Represent documents and queries as vectors in a multi-dimensional space, allowing for similarity-based ranking.  

Probabilistic Models: Rank documents based on the likelihood of relevance given the query.  Machine Learning and Deep Learning: Utilize advanced algorithms, including neural networks, to improve retrieval and ranking.  



 

Evaluation Metrics:  

Precision: Measures how many of the retrieved items are relevant.  

Recall: Measures how many of the relevant items were retrieved.  

F1 Score: A combination of precision and recall for a balanced evaluation.  

Mean Average Precision (MAP): A common metric for ranked retrieval systems.  

Challenges:  

Scalability: Managing and searching through vast amounts of data efficiently.  

Relevance Ranking: Developing accurate models for ranking documents.  

Query Understanding: Interpreting user queries effectively, including handling synonyms and natural language queries.  

 

Applications:  

Web Search Engines: Google, Bing, etc.  

Digital Libraries: Managing and searching through vast collections of documents.  

Recommendation Systems: Suggesting products, content, or services to users.  

Information Filtering: Filtering emails, news articles, or social media content.  

Mathematical Foundations: Information retrieval often involves mathematical concepts like set theory, probability theory, and linear algebra for indexing and ranking.  

Ongoing Research: Continual advancements in IR include deep learning techniques, personalized search, and handling multimedia data.  

Relevance to Mathematics: Information retrieval intersects with mathematics through the use of mathematical models, algorithms, and statistics for improved search and retrieval processes.  Ethical Considerations: Concerns about privacy, bias, and fairness in information retrieval systems are significant topics of discussion and research.  

References: Numerous academic journals, conferences, and research groups are dedicated to advancing the field of information retrieval. 

 

As a mathematics lecturer, you may find relevance in the mathematical underpinnings and modeling techniques used in information retrieval, especially if you're interested in data analysis and algorithms.  

 

Here are some other audience pattern prompt examples:  

 

Task   

Example of prompt  

	Explaining 	a

concept  

 Explain large language models to me. Assume that I know nothing about Computer Science.  

Generate outlines for writing

assignments  

 I have to write an essay about the impact of plastic use on the environment  for my environmental science course. Please help me create an outline to map out my ideas. Assume I am a first-year undergraduate university student.  

  

Question Refinement Pattern – Exchange 1 (ChatGPT-3.5) 

 

Prompt  

From now on, whenever I ask a question, suggest a better question, and ask me if I would like to use it instead. 

 

Chat GPT 

 

   

 

Certainly! I can suggest better questions when I think there's room for improvement. However, I'll always prioritize your original question and provide the suggested question as an option. If you'd like to use the suggested question instead, simply let me know, and I'll proceed with that. Please go ahead and ask your first question or request, and I'll do my best to assist you. 

 



Additional follow up prompt  

Should I enroll at the University of Cape Town to study? 

 

ChatGPT  

Here's a suggested rephrased question: "What factors should I consider when deciding whether to enroll at the University of Cape Town for my studies?" 

 

Would you like to use this suggested question instead, or do you have any specific criteria or preferences you'd like me to consider when providing advice? 

 

Additional follow up prompt  

Yes please use that question 

 

ChatGPT  

Of course! Here's your revised question: "What factors should I consider when deciding whether to enroll at the University of Cape Town for my studies?"  

 

ChatGPT  

Choosing a university for your studies is a significant decision, and there are several factors you should consider when deciding whether to enroll at the University of Cape Town (UCT) or any other institution. Here are some important factors to take into account:  

 

Academic Programs:  

Ensure that UCT offers the academic programs and majors that align with your interests and career goals.  

Research the reputation and rankings of specific programs or departments relevant to your field of study. 

 

Accreditation:  



Verify that UCT is accredited by the appropriate educational authorities to ensure the validity of your degree.  

Location:  

Consider the location of the university. UCT is in Cape Town, South Africa, which is known for its natural beauty and cultural diversity. Think about whether you'd enjoy living in this location. 

 

Cost and Financial Aid:  

Calculate the cost of tuition, fees, and living expenses, and assess whether you can afford it.  

Explore scholarship and financial aid opportunities that UCT may offer.  

 

Reputation and Rankings:  

Research the university's reputation and rankings both nationally and internationally.  

Read reviews and seek the opinions of current and former students.  

 

Campus Facilities:  

Visit the campus or research the available facilities, including libraries, laboratories, sports facilities, and student housing. 

 

Faculty and Research:  

Investigate the faculty's credentials and their expertise in your chosen field.  

Look into the university's research initiatives and opportunities for student involvement.  

 

Student Life:  

Consider the extracurricular activities, clubs, and organizations available on campus.  

Think about the social and cultural opportunities offered in and around Cape Town.  

 

International Opportunities:  

Assess the availability of exchange programs or study abroad opportunities, as they can enhance your educational experience.  

 

Career Services:  

Investigate the university's career services, internships, and job placement support.  

Look for connections with local and international companies and organizations.  

 

Diversity and Inclusivity:  

Consider the diversity of the student body and the university's commitment to inclusivity and equal opportunity.  

 

Campus Safety:  

Research the safety of the campus and the surrounding area.  

 

Alumni Network:  

A strong alumni network can be beneficial for networking and job opportunities. Research the reach and influence of UCT's alumni.  

 

Personal Preferences:  

Consider your personal preferences, such as class sizes, teaching style, and the overall atmosphere of the university.  

Long-Term Goals:  

Think about your long-term career goals and how UCT can help you achieve them.  

 

Admission Requirements:  

Ensure you meet the university's admission requirements and deadlines. 

 

It's crucial to visit the campus if possible, talk to current students and faculty, and carefully review the university's website and materials to gather the information you need to make an informed decision about enrolling at the University of Cape Town or any other institution. Each student's priorities and needs are different, so weigh these factors based on your specific circumstances and aspirations. 

  

Question Refinement Pattern – Exchange 2 (ChatGPT-3.5)  

Prompt  

Whenever I ask a question about studying at the University of Cape Town, suggest a better question which emphasises the academic merits of the institution. Ask me for the first question to refine and ask me if I would like to use that question instead. 

 

Chat GPT 

 

   

 

Of course, I can help you refine questions about studying at the University of Cape Town to emphasize its academic merits. Please provide me with the first question you'd like to refine, and I'll suggest a better question for you. If you prefer to use the refined question, just let me know.  

 

Follow up prompt  

Should I enroll at the University of Cape Town to study? 

 

ChatGPT  

To emphasize the academic merits of the University of Cape Town, how about this refined question: "What academic programs and research opportunities make the University of Cape Town a compelling choice for prospective students?" Would you like to use this question instead?  

 

Follow up prompt  

Yes, answer the question 

 

ChatGPT 

Certainly! The University of Cape Town (UCT) is known for its strong academic programs and research opportunities. UCT offers a wide range of undergraduate, postgraduate, and doctoral programs in various fields, including humanities, sciences, engineering, business, health sciences, and more. Some key academic merits of UCT include:  

World-Class Faculty: UCT has a renowned faculty consisting of experts, scholars, and researchers who are leaders in their respective fields.  

Research Excellence: UCT is a research-intensive institution, and its research output is highly regarded globally. It has a significant impact on the advancement of knowledge in numerous disciplines.  

State-of-the-Art Facilities: The university provides modern, well-equipped facilities, laboratories, and libraries to support students and researchers.  

International Reputation: UCT consistently ranks as one of the top universities in Africa and is well-regarded worldwide.  

Diverse Student Body: UCT attracts a diverse student body, fostering a rich cultural and academic exchange environment.  

Global Opportunities: The university offers international exchange programs, encouraging students to broaden their horizons by studying abroad.  

Community Engagement: UCT is actively involved in community engagement and outreach, providing opportunities for students to make a positive impact.  

 

If you have specific questions about a particular academic program or department at UCT, feel free to ask for more detailed information.  

 

  

Cognitive Verifier Pattern (ChatGPT-3.5) 

Prompt  

When I ask a question, follow these rules. Generate a number of additional questions that will allow you to more accurately answer the question. After three additional questions, combine the individual answers to respond to the original question. 

Chat GPT 



 

  

 

 

 

  

 

 



 

Sure, I can follow those rules to help provide more accurate answers to your questions. Please go ahead and ask your original question, and I'll generate up to three additional questions to gather more information before providing a response.  

 

Follow up prompt  

How many South Africans live without indoor sanitation? 

 

ChatGPT  

To answer your question accurately, I'll generate up to three additional questions to gather more information:  

Do you want to know the current number of South Africans living without indoor sanitation, or are you interested in a specific year or time frame?  

Are you looking for statistics related to urban or rural areas, or an overall national figure?  

Could you specify what you mean by "indoor sanitation"? Does this include access to flush toilets, improved pit latrines, or other forms of indoor sanitation facilities? Once I have this additional information, I can provide a more precise response.  

  

Follow up prompt  

1. Could you provide a percentage of households currently living without indoor sanitation? 2. 

overall national figure 3. indoor sanitation = piped water and flush toilets 

 

ChatGPT  

Thank you for providing the additional questions. Here are the answers based on the information available up to my last knowledge update in January 2022:  

Percentage of households currently living without indoor sanitation in South Africa: As of my last knowledge update, it was reported that approximately 19% of South African households did not have access to basic sanitation services, which includes both piped water and flush toilets. However, please note that these statistics may have changed since then, so it's essential to refer to more recent data for the most accurate figures.  

Overall national figure: The overall national figure for the percentage of South African households without indoor sanitation was around 19% according to the information available up to 2022. To get the most up-to-date statistics, you should consult the latest reports or government sources.  Indoor sanitation - piped water and flush toilets: In the context of access to indoor sanitation, "indoor sanitation" typically includes access to piped water and flush toilets. As of my last knowledge update, efforts were being made to improve access to these facilities in South Africa. Please refer to more recent sources for the latest developments and statistics related to indoor sanitation in South Africa. 

 

Keep in mind that statistics can change over time, so I recommend consulting recent reports or government sources for the most current information on this topic.  

 

Flipped Interaction Pattern (ChatGPT-3.5) 

Prompt  

I want to create a lesson plan on climate change for a South African Grade 8 class. You should ask me questions until you have enough information to create the lesson plan. Ask one question at a time. 

 

  

 

Certainly! Let's start by gathering some information for your Grade 8 climate change lesson plan in South Africa. What is the typical duration of a class session for Grade 8 in South Africa?  

Follow up prompt  

Usually 45 minutes but sometimes there are double sessions 

  

ChatGPT  

Thank you for the information. Now, let's consider the following:  



What specific learning objectives or goals would you like to achieve with this lesson on climate change for Grade 8 students in South Africa?  

 

Follow up prompt  

For the class to understand the basic causes of human induced climate change and likely impacts in this region 

 

ChatGPT  

Great! Understanding the causes of human-induced climate change and its likely impacts in the South African region will be the focus of your lesson. 

 

Do you have any specific resources or materials available for this lesson, such as textbooks, videos, or online resources related to climate change that you would like to use?  

 

Follow up prompt  

Online resources from the Keep it Cool Climate Change Education Project and the IPCC 

 

ChatGPT  

Excellent! You have access to online resources from the "Keep it Cool Climate Change Education Project" and the Intergovernmental Panel on Climate Change (IPCC).  

 

Follow up prompt  

How many class sessions or lessons do you have available to cover this topic, considering that some sessions may be double sessions? 

 

ChatGPT  

Thank you for providing the number of class sessions. Now, let's plan the structure of your lesson.  

 

Would you like to start with an introductory session and then proceed with more in-depth lessons, or do you have a different structure in mind for these 5 sessions?  



 

Follow up prompt  

I would like to start with an excursion somewhere within 5kms of Cape Town city that could be used to highlight the issues as an impactful start to the learning process - then proceed to the science and political issues. 

  

ChatGPT  

Starting with an excursion near Cape Town to highlight the issues related to climate change sounds like an engaging way to kick off the lesson. Do you have a particular location or site in mind for this excursion, or would you like some suggestions for suitable places within 5km of Cape Town city? 

 

Follow up prompt  

Yes, let’s plan a research project on the impact of extreme weather events at the Sea Point Promenade (damaged by recent storms). What do you suggest for the remainder sessions that can link to that topic and lead into the other areas I need to cover. 

 

ChatGPT  

Great choice! Investigating the impact of extreme weather events at the Sea Point Promenade is a meaningful project. Here's a suggested structure for your lesson plan with subsequent sessions: 

 

Session 1: Excursion (3 hours)  

Visit Sea Point Promenade, document storm damage, and gather initial data.  

Discuss the students' observations and findings during the excursion. 

 

Session 2: Introduction to Climate Change and Extreme Weather (45 minutes)  Provide an overview of climate change and its link to extreme weather events.  

Discuss the concept of attribution - how scientists determine if an extreme weather event is linked to climate change.  

Show relevant resources from the "Keep it Cool Climate Change Education Project."  

 

Session 3: The Science of Climate Change and Global Warming (45 minutes)  

Focus on the science behind climate change, including the greenhouse effect, the role of greenhouse gases, and global warming.  

Explain how human activities, such as burning fossil fuels, contribute to increased greenhouse gas concentrations.  

Explore the basic physics of the Earth's energy balance.  

Use visuals and simple experiments to illustrate these concepts.  

 

Session 4: Analyzing Data (45 minutes)  

Have students work on their research project: Analyze data from the Sea Point Promenade excursion and discuss the scientific aspects related to the storm damage and climate change.  

 

Session 5: Regional Impacts, Adaptation, and Climate Policy (45 minutes)  

Explore the regional impacts of climate change on Cape Town and South Africa.  

Discuss how communities are adapting to extreme weather events and the role of local government.  

Introduce international agreements and policies related to climate change.  

Encourage a class discussion on what can be done to combat climate change. 

 

Incorporating a dedicated science session (Session 3) will help students gain a deeper understanding of the scientific principles underpinning climate change and global warming. It's essential to link the scientific aspects to the practical observations made during the excursion and the broader context of regional impacts and climate policy.  

Template Pattern (ChatGPT-3.5) 

 

Prompt  

I am going to provide a template for your output. CAPITALIZED WORDS are my placeholders. 

Fill in my placeholders with your output. Please preserve the overall formatting of the template. 

 

My template is:  

***Question:***QUESTION  

***Answer:***ANSWER  

 

Use the data I will give to you below and create 5 questions and answers using the template I provided above.  

 

Data = """Prompt engineering, primarily used in communication with a text-to-text model and text-to-image model, is the process of structuring text that can be interpreted and understood by a generative AI model.[1][2] Prompt engineering is enabled by in-context learning, defined as a model's ability to temporarily learn from prompts. The ability for in-context learning is an emergent ability[3] of large language models. 

 

A prompt is natural language text describing the task that an AI should perform.[4] A prompt for a text-to-text model can be a query such as "what is Fermat's little theorem?"[5] a command such as "write a poem about leaves falling",[6] a short statement of feedback (for example, "too verbose", "too formal", "rephrase again", "omit this word") or a longer statement including context, instructions,[7] and input data. Prompt engineering may involve phrasing a query, specifying a style,[6] providing relevant context[8] or assigning a role to the AI such as "Act as a native French speaker".[9] Prompt engineering may consist of a single prompt that includes a few examples for a model to learn from, such as "maison -> house, chat -> cat, chien ->",[10] an approach called few-shot learning.[11] 

 

When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as "a high-quality photo of an astronaut riding a horse"[12] or "Lo-fi slow BPM electro chill with organic samples".[13] Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style,[1] layout, lighting,[14] and aesthetic.  



 

 

 

 

 

 

 

 

 

 

Question: What is the primary purpose of prompt engineering in communication with generative AI models?Answer: The primary purpose of prompt engineering in communication with generative AI models is to structure text that can be understood by the AI model, enabling it to perform specific tasks. 

 

Question: How is in-context learning defined in the context of prompt engineering?Answer: In the context of prompt engineering, in-context learning is defined as a model's ability to temporarily learn from prompts, allowing it to adapt and generate appropriate responses.  

Question: Can you provide an example of a prompt for a text-to-text model?Answer: Certainly, a prompt for a text-to-text model could be a query like "what is Fermat's little theorem?" or a command like "write a poem about leaves falling."  

 

Question: What are some elements that prompt engineering may involve when communicating with a text-to-text model?Answer: Prompt engineering when communicating with a text-to-text model may involve phrasing a query, specifying a style, providing relevant context, or even assigning a specific role to the AI, such as "Act as a native French speaker."  

 

Question: How does prompting work when communicating with a text-to-image or text-to-audio model?Answer: When communicating with a text-to-image or text-to-audio model, prompting involves providing a description of the desired output, such as requesting "a high-quality photo of an astronaut riding a horse" or specifying the desired audio style like "Lo-fi slow BPM electro chill with organic samples.  

  

Here is simple prompt template you could start with which combines some of the other prompt patterns:  

Act as {{persona you want the AI tool to simulate}}.   

I am {{audience}}.   

I want you to {{task}}.   

Constraints: • {{constraint 1}} • {{constraint 2}} • {{constraint 3}}   Output format: • {{format instruction 1}} • {{format instruction 2}} 

 

 

1.5. Student Guide: Ethical use of generative AI for research purposes 

 

The availability and rapid uptake of Artificial Intelligence (AI) tools poses both challenges and opportunities for researchers. This guide looks at how generative AI is starting to be used, the implications for research integrity, and suggestions on how these tools can be used productively and ethically for the research process. 

 

The availability and rapid uptake of Artificial Intelligence (AI) tools poses both challenges and opportunities for researchers. This guide looks at how generative AI is starting to be used, the implications for research integrity, and suggestions on how these tools can be used productively and ethically for the research process. Examples of interest to researchers, students, supervisors, and others are included. 

While the outputs produced by generative AI are widely deemed unacceptable as substitutes for what researchers are expected to perform, there are routine tasks forming a part of research processes where generative AI is being used. Researchers, when faced with identifying relevant articles, have for example used generative AI to summarise these and make the task of reading selected articles more manageable. Ethical concerns may arise if, for example, sensitive interview transcripts needed to be summarized, as uploading these into generative AI may potentially give others access to them and violate confidentiality. 

Balancing productivity and ethical concerns requires careful consideration. This is a changing and uncertain space requiring those involved to develop shared understandings. This guide provides some cases and examples that can support this process. 

 

General use 

 

This guide deals primarily with generative AI such as ChatGPT, Gemini, Copilot Chat, and Claude, which are based on large language models. This natural language styles of generative AI invites one to have a conversation, however these are not human conversations nor is the information necessary factually correct. The large language models that are responding to your prompts by predicting a likely next word. By crafting prompts one can control and direct what is generated so that it will be more useful.  

 

Providing context to generative AI will often improve the response. For example, it may be useful to include your role, your knowledge area, or any constraints on the output. In ChatGPT for example, you can include this under “Custom Instructions” that are associated with your login (bottom left corner on the ChatGPT page). These would be used each time you use ChatGPT. Otherwise include such information when you start your session to help make the results more relevant. 

Additionally, you can request generative AI to follow the preferred style of writing, by providing some examples. 

Prompt: "Please help me write helpful information for university researchers. I want you to understand this writing style so I will provide some examples. Remember my writing style as being MY_STYLE. Afterwards when I ask you to write using MY_STYLE, then follow this style of writing." 

 

Examples other than academic writing might include computer programming, and marketing applications where the expectations would be different. More generic strategies for using Generative AI are introduced in other CILT Guides (see A Generative AI Primer). Specialized generative AI tools have been developed for some of these tasks. Examples of these are listed later in this guide as part of a research cycle. 

 

General characteristics 

 

Knowing how generative AI functions can help with crafting prompts and anticipating cases where it will be useful: 

Language generation: Generative AI models are trained on natural language text and can generate coherent and grammatically correct content. Useful for tasks like summarising articles, drafting papers, or generating ideas. 

Large-scale information base: Generative AI models are trained on many diverse sources, which provides them with a broad information base. Researchers could use these models to gain insights into various subjects, identify relevant literature, and explore interdisciplinary connections. 

Intended use cases: Typically, generative AI models are trained to conduct conversations in a customer support role, so are polite, direct and avoid sensitive topics. There are many commercial applications for this chatbot use case. The support role can be established, to play the role of editor, tutor, or idea generator. There are opportunities for follow-up questions and requesting revisions to improve responses. 

Speed and efficiency: Generative AI models can quickly process large amounts of new data and generate outputs immediately.  Researchers could save time and effort on tasks such as identifying possible sources for literature reviews, in getting assistance with data analysis, or brainstorming to get started on writing tasks. 

Pattern recognition: Generative AI models are capable of identifying patterns, trends, and relationships within data. Generating code to perform additional analysis and outputs on your data is also possible, such as in Python or R. Valuable for discovering new insights or generating hypotheses in research. 

Customizability: Researchers can tailor generative AI models to their specific needs. Generative AI can be asked to adopt specific genres for creating a variety of outputs suitable to different audiences. Researchers can fine-tune models. 

Considerations and limitations 

Being aware of the considerations and limitations helps identify where unreliable responses are more likely and where checking is needed. 

Lack of transparency: The inner workings of many generative AI models are complex and opaque, making it difficult to understand how they generate their outputs. Can be challenging for researchers to be transparent about their process. The lack of transparency makes it difficult to identify errors in the generated data. 

Inherent biases or errors in training dataset: Generative AI models learn from the data they are trained on, which may contain bias or particular perspectives. Researchers need to critically evaluate outputs for bias/hegemonic perspectives.  

Misuse of generated data: Generative AI can also be used to create fake data or manipulate existing data. Researchers need to critically evaluate any data. 

Reproducibility issues: Generative AI models may not be reproducible, as the same model may produce different outputs each time it is run due to the random nature of the generative process. This can make it difficult for researchers to replicate results and make claims about reproducibility. 

 

Research integrity implications 

 

Researchers and students should follow the widely discussed integrity and ethical issues: 

Journals and publications: AI will not be acceptable for assisting with producing most parts of research publications. Some journals will allow AI for conceptualisation or copyediting but not for discussion or conclusions (original contribution). AI can also not be listed as a co-author by most journals. Most journals have clear instructions on how to acknowledge the use of generative AI in research, which differ from disciplines to discipline. Where AI is legitimately used to generate text, this should be referenced (e.g., APA style) with further declarations (i.e., including the prompts used). See for example citing ChatGPT and generative AI. 

  

Publisher 

Authorship policy update 

Remark 

Springer-

Nature 

(2023) 

LLMs, such as ChatGPT, do not satisfy the authorship criteria. However, if the researchers use these tools, s(he) must mention their use in the appropriate section of their 

academic paper, such as the ‘methodology’ or ‘acknowledgements’ section. 

Generative AI cannot be an author or co-author. If used this should be clarified in the appropriate section. 

	Taylor 	& 

Francis 

(2023) 

Authors must be accountable for their research work per the publishing agreement. As AI tools do not take this accountability, thus: AI tools cannot be co-authors in an academic paper. However, if a researcher uses these tools, s(he) must mention their use in the appropriate section. 

Generative AI cannot be an author or co-author. If used this should be clarified in the appropriate section. 

 

Elsevier  

(2023) 

Though AI and AI-assisted technologies help you to enhance the quality and readability of the language of the 

Generative AI cannot be an author or co-author. 



work, they do not replace key researchers. Thus, the researchers are not allowed to list AI and AI-assisted technologies as an author or co-author nor cite AI as an author. 

AI cannot be cited as an author. 

Authorship policies of three large publishers (from Rahman et al 2023, p.3) 

Students: At the start of any research investigation or course, make clear to students whether generative AI tools can be used and how it can be used. Explain the consequences of academic dishonesty and inappropriate use of AI. Where appropriate, include conditions in the plagiarism declaration/honour pledge or in the assignment submission instructions. Have a discussion with your students about what ethical AI use would look like. Lance Eaton’s ‘Syllabi Policies for Generative AI’ is a collection of statements used in various universities that provide some examples. There is further guidance to students on using AI in another CILT student guide.  Data privacy: Be aware that data inputted into for example ChatGPT3.5 is currently being saved, which could lead to privacy issues. ChatGPT4.0[DG1] [SW2]  allows you to change this setting (uncheck the setting that data is saved). 

Data analysis and consent: You might have to change consent forms to ask participants for permission to use their data for analysis in generative AI. 

 

More broadly, the UCT Senate Ethics in Research Committee (EiRC) Guidelines and recommendations for the use of generative artificial intelligence (AI) tools in research establishes values for guiding research integrity: 

Honesty in all aspects of research  

Professional courtesy and fairness in working with others  

Good stewardship of research on behalf of others  

Transparency in conducting research and dissemination of findings  

Fair practice from conception to implementation of research  

Shared accountability in the conduct of research  

Indigenous knowledge recognition and epistemic justice 

 

Research process stages with generative AI examples 

 

For each phase in a typical research process may be using specialized generative AI tools. The research phases and examples of these are explored below. 

 

Research process stage 

Generative AI examples 

Conceptualisation/ ideation 

ChatGPT for brainstorming, writing conference abstracts, writing proposals, brainstorming/rephrasing research questions, 

Literature review 

LitMap  or inciteful.xyz  to create literature maps around concepts, Typset.io to summarize articles https://scite.ai/ (paid for tool) for analysing references 

Data collection 

Otter.io  to transcribe interviews, summarize interviews, create keyworks 

Data analysis 

ChatGPT or voyant for thematic analysis (ChatGPT 4.0 allows an advanced data analysis) 

Write up 

Quillbot to rewrite paragraphs, ChatGPT to convert bullet points into paragraphs, to polish writing 

Dissemination 

Use ChatGPT to rewrite your academic papers, i.e., to summarise or make academic papers more accessible. 

 

Principles for the case studies 

Based on experiences at UCT 

Tools that are generally used in our research community 

Based on both lit review and real-life examples 

Caveat: all these tools change all the time and information can be outdated 

 

 

Stage of research: Conceptualisation and research idea generation 

 

Tool used/links 

Descriptions of use 

Opportunities / Concerns 



ChatGPT, 

Gemini, Copilot, Claude and other specialised tools 

Brainstorming research ideas and hypotheses: Describe your research area or problem, and associated or potential research questions, approaches, and angles will be produced. 

 

Example prompts: 

How has Soja’s Third Space been used in the Student as Partners context? 

 

What has not yet been researched in the Student as Partners context? 

 

Please help me formulate research questions around student as partners, third space, South Africa, rules of engagement 

Quick high-level overview of concepts. 

 

Easy to digest / accessible information (often in bullet form) 

 

Is like asking a research assistant rather than asking an expert. 

 

Need to fact check. 

 

					Last 	knowledge 	update 	in 

September 2021 

 

ChatGPT, 

			Gemini, 	Copilot, 

Claude 

Abstract writing: Create a. initial draft of an abstract or compare one to yours. Provide bullet points and ask it to write as a paragraph. 

Helps with starting or rethinking an abstract.  

 

Cannot represent your ideas fully. 

ChatGPT, 

			Gemini, 	Copilot, 

Claude 

Problem statement and rationale: Once you have a research topic, ask for help to formulate a problem statement or rationale. 

Follows typical format. 

 

What is generated is likely hypothetical and without any references. So provides a generalized gap without having accessed any original articles. 

Copilot, 

ChatGPT4.0 

  

Accessing the web: Generative AI tools with connections to the web can cite sources, and perform real time search 

Output is often less controlled and may appear uncurated. 

  

Stage of research: Literature review 

 

Tool used 

Descriptions of use 

Opportunities / Concerns 

ChatGPT, Gemini, 

Copilot, Claude 

Repetitive and tedious structured tasks: Given the appropriate text, can be asked to format references or produce summaries in a specified format. 

Is especially useful for specific use cases. 

 

Can have errors, so needs critical editing. 

Elicit.org 

Automate time-consuming tasks: Can assist with searching and summarizing papers, extracting data, and synthesizing your findings 

Full 	paper 	search, 	but 	only searches the semantic web 

 

Additional 	functionality 	is requires payment (limited to 5000 free credits) 



ChatGPT, Gemini, Copilot, Claude and other specialised 

tools 

Literature reviews. Provide specific research topics or questions to generate related search terms for  searching literature databases and web searches. 

  

Prompts: 

Can you suggest some keywords and search strategies that I can use to find relevant sources on "Student as Partners" and equity in higher education? 

 

Who are the seminal authors in the Student as Partners and equity literature? 

Great overview of current trends and debates. 

 

Can’t provide references, may hallucinate when asked for locally specific information 

  

Information is not necessarily correct: If asked for example for scholars on a particular topic in the Global South, scholars are often made up because they may be underrepresented in the training data.  

LitMaps 

(litmaps.com) 

Literature maps: Generates a map of relevant articles related to a specific seed article. Show the top citations and references related to a seed article. Selecting any article one can see who the article cites, and which articles are citing it. 

Visual view of research fiend using citations. 

 

No made-up references. 

  

Some papers are behind paywalls. 

 

scite.ai 

Evaluate articles: Helps with evaluating scientific articles by looking at citations. Shows how a publication has been cited by providing the context of the citation and a classification describing whether it provides supporting or 

Contextualises article citations.  

 

Mostly medical sciences. 





contrasting evidence for the cited claim. 



Typeset.io (also called scispace) 

Summarises articles: Allows one to upload PDFs and summarise articles. Additionally it can respond to questions related to articles. 

 

Question prompts: 

What are novel methodologies in these papers? 

 

What are unexpected results in these papers? 

 

Are 	there 	any 	future 	research directions or unanswered questions suggested by these papers? 

Aims to help understand research papers better. 

 

Has some limitations and requires assessing 	the 	responses critically.  

 

Consensus.app 

Identify findings in literature: A search engine that uses AI to find insights in research articles. 

Extracts findings directly from articles. 

Semantic reader  

Identify key parts of article: Used to understand document structure and merge it with information via tooltips and other overlays. Category labels include Goal, Method, and Result. 

Can customise what is shown. 

 

Works 	better 	for 	structured articles. 

 

Stage of research: Data collection/transcription 

 

Tool used 

Descriptions of use  

Opportunities / Concerns 

ChatGP

T 

Interview and survey questions: With some context, generative AI can help develop, evaluate and test interview protocols or survey questionnaires.  

Useful for standard types of questions. 

 

May not be appropriate for your target group. 

Otter.ai 

Transcriptions: Allows live edits of transcriptions while listening to the transcript. Supports analyses of texts by for example providing a list of key words/terms used. 

Can learn different accents and improves transcription, identifies speakers. 

 

Currently only English transcription possible – no other South African languages. 

 

Most 	features 	require payment.  

Free version is limited. 

  

Stage of research: Data analysis 

 

Tool used 

Descriptions of use  

Opportunities 

Concerns 



/ 



ChatGPT4.0 Plus/ Turbo 

(code interpreter option) 

  

Python code generation: Using the code interpreter option, you can provide data in a file, then ask for Python code to be generated that will analyze the data. The Python code can be executed. Follow-up prompts can be used to refine the analysis.  

The saved Python code can be used to analyse other datasets without uploading any data to ChatGPT. 

 

ChatGPT Plus/Turbo is subscription based. Claude is a free alternative.  

 

Python code should be checked 	before reporting.  

 

Uploading sensitive data would 	not 	be appropriate. 

ChatGPT4.0 

Advanced data analytics: Can analyse large multimodal models. It generates text outputs (natural language, code, etc.) given inputs consisting of interspersed text and images.   

  

While less capable than an expert in many realworld scenarios, it performs well for many professional and academic tasks. 

 

May generate harmful advice, buggy code, or inaccurate information. 

Voyant 

Text analysis: An open-source, web-based application for performing text analysis. It supports scholarly reading and interpretation of texts or corpus. 

  

It can be used to analyze online texts or ones uploaded by users. 

 

Prolonged text-loading time and the challenge of gathering information using some visualization tools. 

Maxqda and related data 

analysis tools 

Text thematic analysis: Summarise texts, coding of  themes, and identifying common themes across your codings.  

Can help to explain the coded content. 

Can choose the language and the length of the summary.  

 

Can modify the summaries as needed. 

 

https://cursor.sh/  (based on 

VScode) 

The AI-first Code Editor Build software faster in an editor designed for pair-programming with AI 

  

Support with writing code – integrated with GPT4.0 

Scaffolds code, reducing time to write code. 

  

Stage of research: Write up 

 

Tool used 

Descriptions of use  

Opportunities / Concerns 

quillbot.com 

Writing assistance: Assists with academic research and writing tasks.. Can improve writing style or paraphrase to shorten, provide vocabulary suggestions, and offer alternative word choices. 

  

  

Helps brainstorming during the writing process. 

  

Offers explanations for its suggestions. 

  

Can be misused to obscure plagiarism. 

wordvice.ai 

Writing style: Helps fix spelling, punctuation, and style errors and improves the clarity and flow of your text. 

  

Has explanations as well as tips to improve writing style. 

  

Works on all kinds of academic texts. 

Grammarly 

Grammar and style: Support academic writing by offering spell and grammar checks. 

Works in Word and Google Docs, plugin. 

 

Free version works well. 

 

Can be a bit annoying when it’s installed as a plugin. 

Jenni.ai 

Create content: Given prompts will suggest additional content for articles, websites, etc. 

Different citation styles can be selected. 

Beyond repetitive tasks, may have ethical concerns, depending on how it is used. 

  

 

Stage of research: Dissemination 

 

Tool used 

Descriptions of use  

Opportunities / Concerns 

jasper.ai 

Copywriting: Used for copywriting and marketing campaigns. 

Use in research reporting and public engagement. 

 

Is a specialised tool to standardise marketing content. 

 

 

 

Bespoke research tools 

 

Universities are starting to develop their own tools based on generative AI platforms to support research processes. An example is the suite of tools developed by the Academic Insight Lab based on the YouAI platform. This includes both free and subscription-based tools. 

Purpose statement feedback:  A research purpose statement is a concise, clear description of the specific goal or aim that a research project seeks to achieve. A well-defined purpose statement serves as a roadmap for the research, ensuring it remains focused and relevant. This AI tool will provide feedback on your purpose statement to ensure it succinctly describes the study population, approach, and setting of the study. https://youai.ai/ais/purpose-statement-feedback-tool-b50417ed Research problem statement feedback: Crafting a compelling research problem statement is often a daunting task, fraught with the complexities of contextualization, identifying knowledge gaps, and establishing significance. Receive personalized feedback powered by AI to ensure your research problem appropriately frames the research problem you plan to address. https://youai.ai/ais/research-problem-statement-feedback-tool-8d9f5704 

Lit search: designed to help researchers and academics in their literature search process. My job is to assist you in identifying keywords, synonyms, search strings, and more, based on the key concepts and variables of your problem statement https://youai.ai/ais/litsearch-guide-a73c20ee/use Writing diagnostic tool: This AI-powered writing diagnostic tool evaluates academic writing samples, offering a holistic assessment through the lens of SWOT (Strengths, Weaknesses, Opportunities, Threats) analysis. This sophisticated tool adheres to established best practices for academic writing and identifies key areas for improvement to enhance scholars' effectiveness and success in their research communication. https://youai.ai/ais/writing-diagnostic-2834c729 

Conclusion 

 

Generative AI is being used to provide creative support to researchers, helping with new idea generation, outlining research topics, writing abstracts, etc. Litmaps, for example, and tools specifically designed to support literature reviews provide more consistent and reliable information. Generative AI is also widely used for performing repetitive and tedious tasks, such as summarising large text and identifying key findings from the literature. In such cases one might tolerate some inaccuracy when using generic Generative AI tools. 

However, there are greater concerns about generative AI used for writing an academic article and drawing conclusions and where transparency is required (Hosseini et al., 2023). Generative AI tends to produce hypothetical problem statements and research gaps with fake references. Generative AI for data analysis is currently limited and requires checking. Researchers need to show they have control, with generative AI use being limited to a research assistant role (Rhaman et al, 2023). 

 	 

 

2. Policy and Guidelines for use of Generative AI  

 

Cairo University 

Faculty of Computers and Artificial Intelligence 

FCAI Policy and Guidelines for use of Generative AI in 

Postgraduate Studies and Research 

September 4, 2023 

<<Version 1.0>> 

Introduction 

Advancing knowledge and technology is one of the key objectives of pursuing postgraduate study and conducting innovative research. The mismatch between the speed by which knowledge and technologies evolves compared to that of regulations and policies has raised several concerns in the academic and research communities. Accordingly, it is important to strike a balance between the benefits and risks of adopting and adapting emerging knowledge and technologies. 

Generative artificial intelligence (AI) is one of the recent advances that has been evolving much faster than most organizations can comprehend and control. 

Generative artificial intelligence (AI) uses machine learning (ML) to respond to prompts inputted by the user. Several technologies have emerged over the last few years including, for instance, the text generator ChatGPT and the image generator DALL-E 2, and Stable Diffusion. 

Recently, the use of generative AI in education, and more specifically, in research, has raised a great concern in academia from both ethical and scientific perspectives. Some recent efforts have emerged to attempt to develop policies, regulations, and guidelines for the various academic stakeholders (researchers, students, faculty staff) to ensure that the use of generative AI in academic does not violate the norms and standards that have been long established and enforced. 

This document represents the first attempt for the Faculty of Computers and Artificial Intelligence- Cairo University (FCAI-CU) to develop its policy for using generative AI technologies in teaching and research. In doing so, this living document serves as initial guidelines that will be adopted for the Academic Year 2023-2024. New versions will be issued as the technology matures and we gain more understanding of the benefits and risks of using generative AI in education. This document is based on various guidelines and policies developed at Stanford, Toronto, and Deakin University. 

Policy Development Approach 

FCAI-CU, as in all international academic institutes, is keen to progressively develop its policy and regulations for using generative AI in teaching and research. As it progresses, the policy should not prevent innovative use and exploration of the potential of generative AI in teaching and research; while at the same time ensures highest academic standards and adherence to FCAI-CU code of ethics and research regulations. 

To this end, this document serves as a set of guidelines for using generative AI in teaching and research at FCAI-CU. While this initial version is being adopted at FCAI- CU, regular feedback will be collected from all stakeholders on the use of the guidelines. In addition, we will continue to monitor and analyze polices and regulations that evolve in worldwide academic institutes. Eventually, a new version of this document will be released in the near future followed by continuous improvement cycles to evolve the document as novel technologies evolve over time. 

 

Key Guidelines for Using Generative AI in Teaching and Research 

 

The following are the key initial guidelines for using generative AI in teaching and research in FCAI-CU for postgraduate studies. 

Scope of the Guidelines 

 

These guidelines applies to all courses taught at postgraduate level including 

diplomas, Master, and Doctorate programs. It applies to coursework, projects, research proposals, and thesis and dissertations, and related scientific publications. For scientific publications, researchers will need to consult the publisher policy for any further regulations imposed on the use of generative AI and related technologies. 

Coursework 

 

 Instructors are free to decide whether to allow or prevent the use of generative AI in their courses. Instructors shall clearly indicate in course syllabus the rules they see appropriate for the use of generative AI in the various activities of the coursework. 

 In the absence of clear instructions on the use of generative AI in the coursework, the use of such tools should be treated as an assistance from another person and evaluated based on the regular policies and regulations for such case. 

 In all cases, students are responsible for clearly understand the course policy on using generative AI. When they are in doubt, students must ask their instructors for clarification. 

 Students should acknowledge the use of generative AI using the suggested citation in Section 3.4 below. 

 

Research Proposals, Thesis, and Dissertations 

 

The bottom-line, any use of generative AI tools at any step in the process of graduate thesis research, writing, and publication must always take place with full transparency and in adherence to the norms and highest standards of research ethics, intellectual property, and accountability. The following key guidelines represent the minimum expectations for graduate researchers at FCAI-CU when using generative AI tools in their research. 

 Supervisors must agree in advance how any generative AI tools will be used at any stage of the thesis/dissertations development. Such agreement must be in writing using unambiguous statements and well-defined scope of use. The original approval document shall be kept in the student file at postgraduate office with clear timestamp log for the document generation. 

 If the use of generative AI tools is approved by supervisor(s), it must be clear to the student what evidence they need to provide to demonstrate their own contributions and how they made use of any AI tools, and how their work will be assessed by the supervisor and committee. 

 Unauthorized use of generative AI tools for scholarly work shall be treated as research misconduct, and hence, police and regulations for academic research misconduct will be applied. 

 Students are fully responsible for contents generated by AI that they decide to include in their thesis. Students must be able to explain and defend any use of generative AI, as well as the contents of the thesis during their thesis/dissertation defense. 

 Any use of generative AI tools must be appropriately acknowledged (See Section 3.4 for more details). This includes the use of generative AI tools in searching, designing, outlining, drafting, writing, or editing the thesis/dissertation, or in producing audio or visual content for the thesis/dissertation, and may include other uses of generative AI. 

 students working with sensitive types of data (e.g., confidential information 

related to specific areas or industry partnership, human/individual data) are responsible for the risk of using such data with third party generative AI tools If such data is revealed or disclosed. Students must take appropriate measures to protect the data and/or obtain written approvals from relevant stakeholders before submitting the data to the third party tools. 

 Supervisors are highly discouraged to give permissions to their students to use generative AI tools in writing their thesis/dissertation. This is because learning the practices of scientific scholarly writing is crucial for graduate students. The use of generative AI tools could adversely impact the development of these writing skills. 

 

Referencing Guidelines 

 

The following guidelines are adopted from Deakin University guide on referencing: 

 Provide details of the owner/publisher of the AI tool and the year of publication. You might also provide further details of how you used the AI tool, for example a transcript on inputs/outputs, in an appendix. 

 References: Author/Owner of AI model. (Year). Name of AI model (Version) 

[Type or description of AI model]. URL 

 Example OpenAI. (2023). ChatGPT (May 24 version) [Large language model]. 

https://chat.openai.com/chat 

 

3. ChatGPT & other AI tools for Learning and Teaching 

 

This resource is licenced under a CC Attribution Non-Commercial ShareAlike licence 

ChatGPT & other AI tools for Learning and 

Teaching 

Version 1.02 of 26 August 2023 

A comprehensive ‘living’ resource about generative and other ‘artificial intelligence’ that will be constantly updated with new resources. To contribute to this resource, please access the google doc version of this resource. 

The initial outline for this resource was generated by ChatGPT. The prompt used was: 

Create a comprehensive teaching resource about using ChatGPT in higher education. 

Include sections on what ChatGPT is, how ChatGPT works, benefits of ChatGPT for Higher 

Education, how ChatGPT can be used in the classroom, challenges of ChatGPT for higher Education, how students can misuse ChatGPT, and how such misuse by students can be detected. Cite some resources for further reading under every section. 

Introduction to ChatGPT 

 

ChatGPT, or "Chat Generative Pre-training Transformer," is a cutting-edge natural language processing (NLP) tool that can generate human-like text based on a given prompt or context. 

Developed by OpenAI, ChatGPT is a variant of the GPT-3 model, which has been trained on a massive amount of text data and has the ability to generate text that is often indistinguishable from text written by a human. 

What is ChatGPT? 

 

ChatGPT is a language model that uses deep learning techniques to generate text. It is pre-trained on a massive amount of text data, including books, articles, and websites, which allows it to generate text that is similar to text written by humans. It is designed to generate text in response to a given prompt or context, and it can be fine-tuned for specific tasks such as language translation, summarization, and question answering. 

Relevant resources 

 

Something wicked this way comes: ChatGPT, Artificial Intelligence’s quantum leap Steven Boykey Sidley, a professor of practice at JBS, University of Johannesburg provides a brief history of the development of AI and describes how CHATGPT is evolving. 

What is ChatGPT? And questions you have been afraid to ask A succinct background to the tools development 

What is Chat GPT Explained Helpful video explaining what Chat GPT is, what it can do and its history as a product of Open AI. 

 

How ChatGPT works 

 

ChatGPT uses a technique called "transformer architecture" to generate text. The model is trained on a massive amount of text data (over 8 million documents and over 10 billion words) (Inteligencia Artifical, 2023), which allows it to understand the relationships between words and phrases. When given a prompt or context, the model generates text by predicting the next word or phrase based on the input it has been given. The model can also be fine-tuned for specific tasks by training it on a smaller, task-specific dataset. ChatGPT has no ‘real’ intelligence, instead merely predicting what the most likely response to a prompt would be. For this reason, it is sometimes referred to as a ‘stochastic parrot’. Others refer to it as the ‘King of Pastiche’ as it is really just putting together pieces of texts According to a recent blog post on the disadvantages of ChatGPT content, it notes that it is (currently) unable to use idioms - the absence of which may serve as signal to detection software (Crothers et al., 2022). It also lacks artistic expression devoid of irony, humour or metaphors as well the ability to provide unique insights. It issues verbose, often overly detailed responses and tends to steer away from proffering an opinion with a bias to adopting a neutral stance. Apart from the disclaimer which states that it can fabricate facts, its responses appear to be plausible with an overtly formal tone adopted yet evidently too literal in style. (Montii, 2023) It is however not sentient and has no temporal reasoning. 

That said, its efficacy really depends on the inputted prompt (Bouchard, 2022). As such there is a need for AI literacy, in particular skills on Prompt Engineering, in order to generate content that is qualitatively superior to the superficial responses often generated by simple prompts. 

Other key limitations of its operations include the inability to access the internet; its input text limit (though concise text is recommended in order to get the accurate results) and lack of common sense and up-to-date knowledge given that its training data set comprises entries only up to 2021. 

Further ChatGPT prompts used in this section What are your limitations? 

As a language model, I have several limitations: 

Bias: My training data reflects the biases and stereotypes present in the text it was trained on. This can sometimes result in me generating responses that are biased or insensitive. 

Lack of Context: I don't have access to external information or context outside of what's provided in the prompt, so my responses can sometimes be limited or incorrect. 

Lack of Common Sense: I was trained on text, but I don't have real-life experiences or common-sense knowledge. This can result in me making mistakes or providing unrealistic answers. 

Creative Limitations: Although I can generate text that is similar to text I was trained on, I don't have the ability to truly understand or create original ideas in the same way a human can. 

It's important to remember that I'm a machine learning model and not a human, and there will always be limitations to my understanding and ability to respond. 

Relevant resources 

How does Chat GPT work A useful article discussing how ChatGPT works with practical advice on how to use in projects. 

A Generative AI Primer Source: JISC A work-in-progress resource serving as an introductory primer to AI in education 

Opportunities for learning & teaching offered by ChatGPT 

 

ChatGPT offers a number of opportunities for learning and teaching, including: 

Enhanced intrinsic learner motivation, foundational knowledge building and deep understanding and expertise. (Hardman, 2023) 

The automation and rapid design of lessons 

An opportunity to redesign assessment strategies o Some institutions are opting for more oral exams, group work and handwritten assessments! (Huang, 2023) o A new focus on assessing prompts as opposed to outputs and the evaluation of the recombined output signifying the nature of knowledge creation as well as how creative thinking is connected to innate critical thinking. (Firth, 2023) 

Providing accessible information 

Providing innovative opportunities for students to reproduce existing knowledge in order to enact high order thinking 

An opportunity to pursue the provision of new critical information literacies such as prompt engineering skills, AI media literacy 

The repositioning of academics as co -creators of knowledge through the immersion in collaborative, knowledge- building pedagogies (Carvalho et al., 2022, ) 

An opportunity to reconceive how student competencies can be measured. 

The opportunity to cultivate skills which will allow for the integration of machine learning views guided by a human perspective. 

Further ChatGPT prompts used in this section 

How does one gauge student competence in the age of artificial intelligence such as ChatGPT? To gauge student competence in the age of AI, it is important to assess not just their ability to recall information, but also their critical thinking, problem-solving, and creativity skills. This can be done through various assessments methods, such as: 

Project-based assessments: Assign projects that challenge students to apply their knowledge and skills to real-world scenarios. 

Peer evaluations: Have students assess each other's work, which helps to develop critical thinking and communication skills. 

Self-reflection and self-assessment: Encourage students to reflect on their own learning process and evaluate their own progress. 

 

Case studies and simulations: Provide students with complex, real-world scenarios and have them analyse and solve problems. 

It is also important to consider the limitations of AI and not solely rely on it for assessing student competence. AI is still a developing technology and may not always accurately gauge the full range of a student's abilities and potential. 

What types of Artificial Intelligence literacies would be required by students to engage critically with ChatGPT? Please describe what Prompt Engineering is and whether this will be required by students from various disciplines, not necessarily information science or computer Science, in order to generate deep insightful information from ChatGPT. 

To engage critically with ChatGPT, students from various disciplines may benefit from having a general understanding of: 

Natural Language Processing (NLP): The field of AI that focuses on allowing computers to understand, interpret, and generate human language. 

Deep Learning: A subset of machine learning that uses multi-layer neural networks to model complex patterns in data. 

Machine Learning: The field of AI that focuses on developing algorithms that allow computers to learn from data and make predictions or decisions 

In addition to these, prompt engineering refers to the process of designing and crafting questions or prompts that are well-suited for a specific AI model, such as ChatGPT. This can help ensure that the model produces high-quality responses that are relevant and accurate. Whether students from various disciplines would need to learn about prompt engineering would depend on their specific goals and the types of information they are looking to generate from ChatGPT. In general, having some understanding of prompt engineering may be beneficial for anyone who wants to use AI models, like ChatGPT, in a way that maximizes the quality of the information generated. 

 

Ethics and morality of using ChatGPT for Learning and Teaching 

 

The use of ChatGPT can promote the spread of false news, misinformation especially through the veneer of plausibility of the generated text 

The use of ChatGPT raises ethical concerns about the creation and use of artificial intelligence in education. 

The use of ChatGPT may perpetuate issues of bias and discrimination if the data used to train the model is not diverse and inclusive. 

The use of ChatGPT may raise questions about the value of human input and creativity in education. 

The use of ChatGPT may raise concerns about privacy and the potential misuse of student data. i.e. fodder for machine learning? 

The use of ChatGPT should entail a critical engagement with the exploitative labour practices involved in its development. (Perrigo, 2023) 

The significant carbon footprint that the training of LLMs require 

How using these tools may signal the endorsement of surveillance capitalism, alignment problems that could cause potential damage etc. Relevant resources 

Helping teachers bring AI to the classroom critically, ethically, & responsibly. A curated collection of assignments bringing a critical lens to Artificial Intelligence (AI), built collaboratively with educators. We give teachers the tools to examine AI’s dangers, benefits, and inevitable impact in the classroom. 

Critical lenses on ‘AI’ A compilation of resources aimed at providing a vigilant take on AI tools and ‘resisting the hype’ 

Critical AI : The blog site for the Critical AI, a new interdisciplinary journal based at Rutgers University’s Centre for Cultural Analysis. 

Limitations And Ethical Considerations Of Using ChatGPT 

Teaching AI Ethics A resource compiled by Leon Furze, an international consultant, author, and speaker and studying his PhD in the implications of Artificial Intelligence on writing instruction and education. See also Teaching AI Ethics: Intermediate Series 

ChatGPT and the sweatshops powering the digital age 

Transcript: Ezra Klein Interviews Gary Marcus. Gary Marcus is an emeritus professor of psychology and neural science at N.Y.U., and he’s become a leading voice of not quite A.I. scepticism, but scepticism about the A.I. path we’re on. 

Prof. Luciano Floridi - ChatGPT, Superintelligence, Ethics, Philosophy of Information: A YouTube video of the interview with Prof Floridi expounding on the deontology and teleological perspectives of AI along with other philosophical aspects needed to understand the impact of these tools and underscoring these arguments with the crucial need for governance and a regulatory framework developed by all stakeholders to improve the world . 

 

How ChatGPT can be used in the classroom 

 

ChatGPT can be used in a variety of ways in the classroom, including: 

Generating lesson plans based on a particular pedagogical design 

Enhancing the learning experience by providing students with more engaging and interactive materials 

Creating storyboards for interactive or gamified learning activities 

Creating interactive quizzes and exercises 

Generating test questions 

Creating discussion prompts with rubrics to grade student contributions 

Automating time-consuming tasks such as essay writing and language translation 

Enabling students to practise their writing skills by using the model to generate text, which they can then revise and edit 

Generating unique text for essays, research papers, and other assignments 

An opportunity to transform essay writing 

Generating unique text for essays and research papers 

Automating essay writing: Students can use the model to generate text for an essay, which they can then revise and edit. 

Practicing writing skills: Students can use the model to generate text, and then revise and edit it to improve their writing skills 

Enhancing personalization and differentiation: Teachers can use the model to generate text at different levels of proficiency, which can help students learn at their own pace. 

Students can similarly generate text at their own level of proficiency 

Providing opportunities for students to explore and analyse text generated by the model, which can help them develop critical thinking skills 

Simulate debates to develop critical thinking skills 

Automating language translation tasks 

Providing students with personalized language assistance 

Provide exemplars for assignment tasks 

Prompting Chatbot to adopting a persona to whom questions can be asked and who can generate questions in turn for the user/student. 

Writing Assistance: Have students use ChatGPT to generate ideas and suggestions for their writing assignments. This can be used as a tool to assist with brainstorming and editing. 

Dialogue Generation: Have students use ChatGPT to generate dialogue for a fictional story or script. This can be used as a tool to assist with creative writing and scriptwriting. 

Language Learning: Have students use ChatGPT to generate sentences and phrases in a foreign language. This can be used as a tool to assist with language acquisition and practice. 

Research Assistance: Have students use ChatGPT to generate summaries and analysis of research articles. This can be used as a tool to assist with research projects and assignments. 

Tips harvested from various posts o Be intentional about when and how ChatGPT is introduced. o Create dedicated non-AI spaces. o ChatGPT will be indispensable for pattern recognition. o ChatGPT should be used to supplement other forms of writing. Relevant resources 

Link to internal doc of AI tools 

Resources on Generative AI in Education Sponsored by the University of California, Irvine, and the Spencer Foundation, this curation of resources includes an overview of generative AI and its integration in education, and the application of generative AI in specific topic areas in education- Link to Discord Channel https://discord.gg/YpXHRWED 

Learn Prompting An open -source work in progress course on how to craft good prompts 

Resources on Generative AI in Education: Writing Sponsored by the University of California, Irvine, and the Spencer Foundation, this curated set of resources serves as precursor materials for the Pens & Pixels: Generative AI in Education Conference scheduled for July 2023 

Using AI to make teaching easier & more impactful Here are five strategies and prompts that work for GPT-3.5 & GPT-4 2023/03/18 

PedAIgogy – new era of knowledge and learning where AI changes everything A blog post by 

Donald Clarke. He writes” This is another big bang, the difference being the dynamic creation of knowledge, in real time, in co-created dialogue. We are no longer using technology to simply find knowledge and learn. We have moved forward to find, create, change, organize, synthesize, even evaluate knowledge and learning with technology. This is a new form of pedagogy, I call ‘pedAIgogy’. We are co-creators, not just of text but in all media, multimedia creators, as well as learning and teaching in a far more complex relationship with technology. Also see 8 Learning Trends Now Shaping L&D Webinar Recording 

A practical guide to ethical use of ChatGPT in essay writing A resource compiled by UJ’s 

Benjamin Smart, Director of The Centre for Philosophy of Epidemiology, Medicine, and Public 

Health, and Associate Professor of Philosophy & Catherine Botha, full professor in Philosophy 

Presentations of the Teaching and Learning with Artificial Intelligence Symposium: 8-9 

February 2023 : Presentations T&L with AI resources compiled by Prof Johannes Cronje 

(CPUT: Learning Landscapes) 

Ideas for Using AI Tools in Teaching & Learning- Western Academy of Beijing LIB on resources 

for T&LWAB 

How Well Can AI Respond to My Assignment prompts A resource compiled by various educators on: 

o Alternative Tools o Assignment Prompts o Teaching Writing using AI 

ChatGPT in Education A collection of Resources by Phil Anthony gathered from colleagues across the sector during the Digitally Enhanced Education Webinars 

. 

How to... use ChatGPT to boost your writing 

What lessons can we learn from ChatGPT about AI and education? Key Points include o focussing students on on exploring and explaining the "hows" and the "whys" vs. the 

"whos," "whats," and "whens." o Getting students to form opinions o Being mindful of the inaccuracies of ChatGPT o Fundamentally rethinking exam approach 

ChatGPT for Educators A comprehensive list of resources by collaborators on various hubs such as o Curriculum impact o Educator Uses o ChatGPT challenges o Podcasts, Videos and Articles 

Creative Learning Solutions in a ChatGPT World A blog describing an educator's experience of AI use by students and his musings on how chatbots could impact teaching and learning. 

Chatting and Cheating. Ensuring academic integrity in the era of ChatGPT The paper discusses the main features and capabilities of chatAPIs and GPT-3 and provides examples of their use in higher education. It also considers the potential for these tools to be used for academic dishonesty and the difficulties of detecting and preventing such abuses. Finally, the paper suggests a range of strategies that universities can adopt to ensure that chatAPIs and GPT-3 are used ethically and responsibly, including developing policies and procedures, providing training and support, and using a variety of methods to detect and prevent cheating. 

ChatGPT for Educators: Free Guide A short guide developed by learning scientist Dr. Phillipa Hardman, creator of DOMS™ Learning Design Engine which aims to empower learning designers to create engaging learning experiences. See also her guide for learning designers on using AI. 

How to use ChatGPT to boost your writing A blog providing some useful tips on prompt crafting 

AI Text Generators: What Questions Should Writing Teachers Ask? Useful set of question for academics to consider regarding AI text generators and policy issues by critical AI literacy advocate, Anna Mills. 

Leveraging ChatGPT: Practical Ideas for Educators The author proposes four ways to use ChatGPT in the Classroom: o Help students with grammar o Create Study Guides o Flip the Classroom o Build Information-Literacy Skills 

ChatGPT: create a game activity storyboard Presentation/resource on how to go about creating/generating a storyboard for a game activity using ChatGPT 

AI, Chatbots & ChatGPT for Teachers A free course intended for teachers who want to know more about ChatGPT, use it in their practice, looking for inspiration/examples of its power or those trying to improve their use of this AI chatbot. 

ChatGPT: five priorities for research The authors hold that banning AI tools will not work and outline 5 key issues on which to focus research viz. The retention of human verification processes; development of rules of accountability; invest in open LLMs, embrace AI technology and robust debate engagement. 

So, you want to use ChatGPT in the classroom this semester? Ben Swift outlines some methods and things to think about if you’re unsure about ChatGPT but would like to start incorporating it in your classes right away. 

 

Lesson Plans for Using ChatGPT in Higher Education 

 

Relevant resources 

Using ChatGPT to Create a Lesson Plan: A YouTube video demonstrating the use of ChatGPT using the BOPPPs model to generate a lesson plan 

Lesson Plan: Teaching and Learning in the Era of ChatGPT 

Educators and experts on all sides of the broader debates about ChatGPT give some strategies for AI-proofing assignments: https://www.edweek.org/technology/outsmart- chatgpt-8-tips-for-creating-assignments-it-cant-do/2023/02 

Assessing student learning 

 

Use open-ended questions: Open-ended questions that require a written response cannot be easily answered by ChatGPT. These types of questions can also encourage critical thinking and analysis. 

Use multiple-choice questions with a twist: Instead of traditional multiple-choice questions, use questions that require students to analyse and interpret information. For example, instead of asking "What is the main theme of the story?", ask "How does the author use symbolism to convey the main theme of the story?" 

Use peer review: Have students review and evaluate each other's work. This not only assesses their understanding of the material, but also promotes collaboration and critical thinking. • Use real-world applications: Ask students to apply their knowledge in a real-world scenario. For example, ask them to write a proposal for a research project or to create a marketing plan for a new product. 

Nowadays, scientific endeavours are increasingly relying on AI. Scientists and engineers utilise supercomputers to predict, classify and infer to solve complex problems. These scenarios could be roleplayed in the classroom Further ChatGPT prompts used in this section 

Give me examples of work using ChatGPT (this was a follow up question to “How can I use ChatGPT 

in my learning and teaching activities in higher education whilst still ensuring academic integrity?” and is included here to follow the structure of the document) 

Here are a few examples of original work that students can create using ChatGPT: 

Creative writing: Have students use ChatGPT as a writing prompt and generate a short story, poem, or personal essay based on the information and ideas generated by the model. 

Problem-solving: Have students use ChatGPT to research a complex problem and then use their own critical thinking skills to develop a solution. 

Research projects: Have students use ChatGPT to gather information on a particular topic and then use that information to write a research paper or create a presentation that presents their own original insights and ideas. 

Group projects: Have students work in teams and use ChatGPT to research and brainstorm solutions to a common problem. The teams can then present their own original solutions to the problem. 

Debates: Have students use ChatGPT to research both sides of a contentious issue and then use that information to participate in a class debate, presenting their own original arguments and ideas. 

These are just a few examples of original work that students can create using ChatGPT. The key is to assign tasks that require students to use their own critical thinking and creativity, rather than simply repeating information from the model. Relevant resources 

AI Augmented Outlining An example of an assessment strategy shared from Codaptivelabs.com. See their other strategies. 

AI and Assessment Prof and Chair in Digital Education, Mairéad Pratschke from the University of Manchester shares her screencast presentation, replete with helpful resources on how to engage with AI in creating Education 4.0. 

Video - AI and Assessment: ChatGPT and the Future of Education A follow up presentation by Prof and Chair in Digital Education, Mairéad Pratschke. 

ChatGPT User Experience: Implications for Education The paper concludes by suggesting adjusting learning goals—students should be able to use AI tools to conduct subject-domain tasks and 

education should focus on improving students’ creativity and critical thinking rather 

than general skills. To accomplish the learning goals, researchers should design AI-involved learning tasks to engage students in solving real-world problems. ChatGPT also raises concerns that students may outsource assessment tasks. This paper concludes that new 

formats of assessments are needed to focus on creativity and critical thinking that AI cannot substitute. 

Designing Assignments in the ChatGPT Era Some instructors seek to craft assignments that guide students in surpassing what AI can do. Others see that as a fool’s errand—one that lends too much agency to the software. 

Introducing: ChatGPT Edu-Mega-Prompts A blog post by the learning scientist Dr Hardman which underscores the importance of the ‘Prompt’ used in requests. Describes the anatomy of the prompt, showing its 

key 7 characteristics and how to create ‘undoing activities’’- an instructional strategy used in the creation of quizzes which “surfaces, challenges and reframes commonly mistaken foundational ideas and assumptions” 

25 Ideas for alternative assessment in the AI area Examples of using assessment strategies for alternative assessments with AI. Assessment creation tools 

Yippity: https://yippity.io/?ref=futurepedia 

Quiz Gecko: https://quizgecko.com/ 

Questgen: https://www.questgen.ai/ 

Kwizie: https://www.kwizie.ai/ 

 

Misuse of ChatGPT by students / Academic Integrity and ChatGPT 

 

Students may use ChatGPT to generate entire assignments without putting in their own effort or understanding the material. 

Students may use ChatGPT to plagiarize or pass off someone else's work as their own. 

Students may use ChatGPT to create fake or misleading information for assignments or research projects. 

Further ChatGPT prompts used in this section 

How can I use ChatGPT in my learning and teaching activities in higher education whilst still ensuring academic integrity? 

ChatGPT can be a valuable tool for learning and teaching in higher education when used appropriately and with consideration for academic integrity. Here are some suggestions for using ChatGPT in an academically responsible manner: 

Use ChatGPT as a supplement to, not a substitute for, traditional teaching methods. ChatGPT can provide additional information, resources, and practice opportunities, but it is important to rely on human-led instruction and assessment as well. 

Cite ChatGPT as a source of information. If you use information from ChatGPT in your work, it is important to properly cite the source. This helps to maintain academic integrity and to give credit where credit is due. 

Assign original work. Assign tasks that require students to generate original ideas, rather than simply repeating information from ChatGPT. This helps to foster critical thinking and creativity, while also promoting academic integrity. 

Encourage students to use ChatGPT as a tool for learning, not a way to cheat. Make it clear that using ChatGPT in an academically dishonest manner (such as copying answers without proper citation) is not acceptable and will have consequences. 

By using ChatGPT in a responsible and thoughtful manner, it can be a valuable addition to your teaching and learning activities in higher education. Relevant resources 

How ChatGPT Can Help Prevent Violations of Academic Integrity In this YouTube video educator Dr. Brent A. Anders provides reasons behind students cheating and violations of academic integrity and suggests ways on how CHATGPT can help prevent these violations 

How to Avoid Plagiarism with AI (ChatGPT) - The Final Solution to Create Original Content The video shows how students can avoid plagiarism and detection by 

AI detector tools such as 

Content at Scale by using 

ChatGPT, and article rewriting and paraphrasing tools such as Free Article Spinner and Word Tune. 

 

Detection of misuse of ChatGPT by students 

 

Teachers can use plagiarism detection software to check for similarities between student work and text generated by ChatGPT. 

Teachers can also use their own knowledge and expertise to identify patterns or inconsistencies in student work that may indicate the use of ChatGPT. 

Teachers can also encourage students to cite and reference any text generated by ChatGPT in their work. 

There is concern though but the accuracies of the detectors which sometime flag the user’s original work as being fake. 

Relevant resources 

Tools for Detecting Text Generated by ChatGPT 

Text generated by ChatGPT can be detected by analysing patterns and language use. Tools which can be used to detect text generated by ChatGPT includes: 

GPT-2 detector: A tool that uses machine learning to identify text generated by GPT-2 models such as ChatGPT. 

GPTZero: is an app that detects essays written by the impressive AI-powered language model known as ChatGPT. o https://www.insidehighered.com/news/2023/01/20/academics-work-detect-chatgpt- and-other-ai-writing o https://www.euronews.com/next/2023/01/19/chatgpt-is-it-possible-to-detect-ai- generated-text 

Plagiarism detection software: These tools can be used to identify similarities between student work and text generated by ChatGPT. 

o Turnitin is currently working on a feature that will detect AI text o OpenAI is working on a feature that will watermark text from ChatGPT 

• Language analysis tools: These tools can be used to identify patterns and language use that may indicate text generated by ChatGPT. 

Writer AI Content Detector: A free tool developed by Writer.com. The tool is designed to help users detect AI written content generated by an AI writing tool, such as GPT-3 or GPT-2. The web-based tool provides a detection score, indicating the likelihood that the content was created by an AI. 

Copyleaks: An AI detector app that can detect content generated by some AI text bot, including ChatGPT. 

Content at Scale: A tool that allows users to check the authenticity of their written content. It provides a score out of 100 to indicate the human-like quality of the content and the likelihood that it will be detected as artificial by Google. o Corrector: A free online tool with a maximum of 300 words per run. 

 Turnitin AI Detection feature https://www.turnitin.com/blog/sneak-preview-of- turnitins-ai-writing-and-chatgpt-detection-capability 

 Corrector 

 GPT-2 Output Detector  Content at Scale 

Yippity: https://yippity.io/ 

Quiz Gecko: https://quizgecko.com/ 

Questgen: https://www.questgen.ai/ 

AI Tools for detecting generated text 

Futurepedia The Largest AI Tools Directory, updated daily with currently 2547 tools and 54 categories 

 

Policy and guidelines 

 

Below are examples shared from various institutes. 

Relevant resources 

• AI Use Guidelines (Summer 23) - Wakefield A lecturer from Keene Academic college shares his guidelines on Tool Use. 

 

Annexure: AI Tools for Learning and Teaching 

 

The following list of AI tools are derived largely from a compilation by Dr Phillipa Hardman as well as other sources and will be continuously updated. 

Tools similar to ChatGPT 

BERT (Bidirectional Encoder Representations): A pre-trained model developed by Google that can be fine-tuned for a variety of NLP tasks 

XLNet: A pre-trained model developed by Google that is similar to BERT but uses a different architecture 

ChatSonic 

Chinchilla 

Bloom 

Replika 

Jasper Chat by Jasper 

LaMDA (Language Model for Dialog Applications) 

Elsa Speak 

DialoGPT 

YouChat 

Perplexity 

Character AI 

OpenAI playground 

Megatron-Turing Natural Language Generation 

Socratic by Google 

Research Tools - Get to Know Your Subject & Learners 

Get to Know Your Subject 

TutorAI: https://www.tutorai.me/ 

Perplexity: https://www.perplexity.ai/ 

Consensus: https://consensus.app/ 

Elicit: https://elicit.org/ 

Scholarcy: https://www.scholarcy.com/ 

Typeset: https://typeset.io/ 

ELIF: https://explainlikeimfive.io/ 

Article.Audio: https://article.audio/ 

Summari: https://www.summari.com/products/chrome 

Get to Know Your Learners (Deep Dive Your Data) 

Polymer: https://www.polymersearch.com/ 

MonkeyLearn: https://monkeylearn.com/ 

Storyboarding & Prototyping Tools - Create Visual Blueprints & Lesson Plans 

Visual Sitemaps: https://visualsitemaps.com/ 

Uizard: https://uizard.io/ 

ArtBoard: https://artboard.studio/ 

Prototyper: https://prototyper.design/ 

Authoring Tools - Turn Existing Content into New Content 

Narakeet: https://www.narakeet.com/ 

Munch: Munch 

Mindsmith: https://www.mindsmith.ai 

Nolej: https://nolej.io/nolej-ai 

Papercup: https://www.papercup.com/industries/for-elearning 

Vidyo: https://vidyo.ai/ 

Pictory: https://pictory.ai/ 

Content Fries: https://www.contentfries.com/ 

Video & Audio Editing incl. dubbing 

Invideo: https://invideo.io/ 

Runway: https://runwayml.com/?ref=futurepedia 

Gling: https://www.gling.ai/?ref=futurepedia 

Dubverse: https://dubverse.ai/ 

Unscreen: https://www.unscreen.com/ 

Content Writing Tools - Generate Compelling Copy 

Write Better Copy, Faster 

Copy AI: https://www.copy.ai/ 

Co-Writer: https://cowriter.org/ 

Hemingwayapp: https://hemingwayapp.com/ 

Jasper: https://www.jasper.ai/ 

WriteSonic: https://writesonic.com/ 

OpenAI Playground: https://beta.openai.com/playground/p/default-summarize 

Quillbot: https://quillbot.com/ 

Wordtune: https://www.wordtune.com/ 

Rytr: https://rytr.me 

Write essays: http://jenni.ai 

Note taking: (http://fireflies.ai 

Your text to speech: http://murf.ai 

Writeful: https://www.writefull.com/ 

AJE Digital research editing: https://www.aje.com/services/digital/ 

Write Compelling Stories to Engage Learners 

Bedtime Story: https://www.bedtimestory.ai/ 

Novel: https://novelai.net/ 

Subtext: https://subtxt.app/ 

MarkCopy: https://www.markcopy.ai/ 

Compose: https://www.compose.ai/ 

Presentation Tools - Generate Slide Decks 

Tome: https://beta.tome.app/ 

Slides: https://www.slidesai.io/ 

Designs: https://designs.ai/ 

Beautiful: https://www.beautiful.ai/ 

Pitch: https://pitch.com/ 

Poised: https://www.poised.com/ 

Presentation: https://presentations.ai/ 

Image Tools - Generate Images & Animations 

Aragon: https://www.aragon.ai/ 

Craiyon: https://www.craiyon.com/ 

DallE-2: https://openai.com/dall-e-2/?ref=futurepedia 

Visualize: https://visualise.ai/ • Lexica: https://lexica.art/ 

Stock AI: https://stockimg.ai/ 

Illustroke: https://illustroke.com/ 

Humaaans: https://www.humaaans.com/ 

OpenPeeps: https://openpeeps.com/ 

Create Art From Text: Midjourney.com 

3D modeling: http://tome.app 

Audio Generation - Generate Voiceovers, Podcasts & Music 

Create Voiceovers & Podcast Content 

Wellsaidlabs: https://wellsaidlabs.com/ 

Voicemod: https://www.voicemod.net/ai-voices/ 

Descript: https://www.descript.com/ • Big Speak AI: https://bigspeak.ai/ 

Resemble: https://www.resemble.ai/ 

Fliki: https://fliki.ai/ 

Murf: https://murf.ai/ 

Coqui: https://coqui.ai/ 

Beyond Words: https://beyondwords.io/ 

Generate Music 

MusicLM: https://googlemusiclm.com/ 

Video Generation Tools - Turn Text into Video 

Synthesia: https://www.synthesia.io/ 

Colossyan: https://www.colossyan.com/ 

Descript: https://www.descript.com/ 

Movio: https://www.movio.la/ 

Invideo: https://invideo.io/ 

Shuffll: https://shuffll.com/ Video editing 

Runway: runwayml.com 

Evaluation & Impact Tools - Gather & Analyse Data 

Genius Review: https://geniusreview.xyz/ 

Effy: https://www.effy.ai/ 

Monkey Learn: https://monkeylearn.com/ 

Polymer: https://www.polymersearch.com/ 

Access & Inclusion Tools - Optimise for Inclusion 

Diversio: https://diversio.com/ 

Get Dost: https://getdost.com/ 

Accessibe: https://accessibe.com/ 

Equally: https://equally.ai/ 

Type Studio: https://www.typestudio.co/ 

Productivity Tools - Streamline Your Workflow 

CVs, Contracts & Proposals 

Resume Worded: https://resumeworded.com/ 

Proposal Genie: https://www.proposalgenie.ai/ 

Legal Robot: https://legalrobot.com/ 

Spellbook: https://www.spellbook.legal/ 

E-mail 

Ellie: https://tryellie.com/ 

Twain: https://www.usetwain.com/ 

Smartwriter: https://www.smartwriter.ai/ 

Phrasee: https://phrasee.co/ 

Warmer: http://warmer.ai/ 

Day To Day Effectiveness 

Noat: https://www.noat.ai/ 

Notion AI: https://www.notion.so/product/ai 

Summari: https://www.summari.com/products/chrome 

Summate: https://summate.it/ 

Otter: https://otter.ai/ 

Sembly: https://www.sembly.ai/ 

Craft: https://www.craft.do/ 

Mem: https://mem.ai/ 

Taskade: https://www.taskade.com/ 

You: https://you.com/ 

Todoist: https://todoist.com/integrations/apps/ai-assistant 

Time tracking: http://timelyapp.com 

Course Comms & Marketing Tools - Generate Marketing Comms 

Course Marketing Comms & Strategy 

Simplified: https://simplified.com/ai-writer/ 

Copy Smith: https://copysmith.ai/ 

MarketMuse: https://www.marketmuse.com/ 

Creaitor: https://www.creaitor.ai/ 

Autopost Social Media: repurpose.io SEO & Ads 

Frase: https://www.frase.io/ 

ContentEdge: https://www.contentedge.com/ 

Surfer SEO: https://surferseo.com/ 

Smartly: https://www.smartly.io/ 

Phrasee: https://phrasee.co/ 

Tutorials, Courses and Explanatory videos 

 

Elements of AI Comprises 2 parts with Part 1: An Introduction to AI is a free online course for everyone interested in learning what AI is, what is possible (and not possible) with AI, and how it affects our lives – with no complicated math or programming required. 

Empower educators to explore the potential of artificial intelligence A 53 min Microsoft Learn Course 

Destination AI: Introduction to Artificial Intelligence An OpenClassroom course Last updated on the 1/23/23 Duration 6 hrs 

ChatGPT vs Sparrow - Battle of Chatbots The video compares Sparrow and CHatGPT with a focus on the research. ChatGPT did not come with an extra paper release while DeepMind, although they did present a paper proposing new chatbot Sparrow, they have not made the model publicly available. 

First look - ChatGPT + Wolfram Alpha The video compares Deepmind’s Sparrow with Open AI’s ChatGPT - both conversational dialogue models, explains how ChatGPT (and other chatbots) works in comparison to how Wolfram Alpha works and includes conversations around benefits of combining the two types into one centralised platform. 

Prompt Development/Engineering 

 

The Art of ChatGPT Prompting: A Guide to Crafting Clear and Effective Prompts 

Awesome ChatGPT Prompts 

Research Tools 

 

https://typeset.io/ Your AI Co-pilot to decode any research paper 

https://www.semanticscholar.org/ A free, AI-powered research tool for scientific literature 

https://www.researchrabbit.ai/ A platform that empowers every step of your research. 

References 

Bouchard, L. (2022, December 12). Prompting Explained: How to talk to ChatGPT. Louis Bouchard. 

Retrieved February 2, 2023, from https://www.louisbouchard.ai/prompting-explained/ 

Carvalho, L., Martinez-Maldonado, R., Tsai, Y.-S., Markauskaite, L., & De Laat, M. (2022). How can we design for learning in an AI world? Computers and Education: Artificial Intelligence, 3. https://doi.org/10.1016/j.caeai.2022.100053. 

Chou, L. (2023, January 10). What lessons can we learn from ChatGPT about AI and education? 

Pulse. https://www.linkedin.com/pulse/what-lessons-can-we-learn-from-chatgpt-ai-education-luyenchou/ 

Crothers, E., Japkowicz, N., Viktor, H., & Branco, P. (2022, March 2). Adversarial Robustness of Neural- 

Statistical Features in Detection of Generative Transformers. https://arxiv.org/pdf/2203.07983.pdf 

Downs, L., & Altmann, G. (2023, January 5). Is AI the New Homework Machine? Understanding AI and 

Its Impact on Higher Education. WICHE Cooperative for Educational Technologies. 

https://wcet.wiche.edu/frontiers/2023/01/05/is-ai-the-new-homework-machine/ 

Firth, J. (2023, January 23). Creativity – What's the Role of Memory? Memory and Metacognition Updates. https://firth.substack.com/p/creativity-whats-the-role-of-memory? 

Gaebel, M. (2023, January 23). Setting the stage for digitally enhanced higher education. 

University 

World News. Retrieved February 2, 2023, from 

https://www.universityworldnews.com/post.php?story=20230123125422596 

Hardman, P. (2023, January 5). The Biggest Risk of AI in Education? It makes us more efficient at 

creating ineffective learning experiences. The Learning Science Newsletter, Powered by 

DOMS™. 

https://drphilippahardman.substack.com/p/the-biggest-risk-of-ai-in-education 

Huang, K. (2023, January 16). Alarmed by A.I. Chatbots, Universities Start Revamping How They Teach. 

The New York Times. https://www.nytimes.com/2023/01/16/technology/chatgpt-artificial- intelligence-universities.html 

Montii, R. (2023, January 31). 11 Disadvantages Of ChatGPT Content. Search Engine Journal. 

Retrieved 

February 1, 2023, from https://www.searchenginejournal.com/disadvantages-chatgpt- content/477416/#topmenubutton 

Perrigo, B. (2023, January 18). OpenAI Used Kenyan Workers on Less Than $2 Per Hour: 

Exclusive. 

TIME. https://time.com/6247678/openai-chatgpt-kenya-workers/ 

Shipper, D., & Morris, R. (2023, January 13). GPT-3 Is the Best Journal I've Ever Used. Every. 

Retrieved 

February 2, 2023, from https://every.to/chain-of-thought/gpt-3-is-the-best-journal-you-ve-everused? 

Swiecki, Z., Khosravi, H., & Chen, G. (2022). Assessment in the age of artificial intelligence. Computers 

and Education: Artificial Intelligence, 3(2002). https://doi.org/10.1016/j.caeai.2022.100075 Willingham, D. T. (2006, Spring). How Knowledge Helps. It Speeds and Strengthens Reading Comprehension, Learning—and Thinking. American educator, 30(1). 

https://www.aft.org/periodical/american-educator/spring-2006/how-knowledge-helps Zhai, X. (2022, December 27). ChatGPT User Experience: Implications for Education. http://dx.doi.org/10.2139/ssrn.4312418 

Writesonic (2023, August 20). Top 30 ChatGPT alternatives that will blow your mind in 2023 (Free & 

Paid). https://writesonic.com/blog/chatgpt-alternatives/ 

Hardman (2023). 120+ AI Tools for Educators, Powered by DOMS™ https://philippa- hardman.notion.site/philippa-hardman/120-AI-Tools-for-Educators-Powered-by-DOMS- f0b16f09f7744279921dbded18d86329 

 

4. Leveraging Generative Artificial Intelligence for Teaching and Learning Enhancement 

 

Artificial Intelligence (AI), particularly in its generative forms, is revolutionising various facets of human life, from communication to entertainment, and education is no exception. This guide offers practical tips to maximise the benefits and the ethical use of Generative AI. ChatGPT, activated by OpenAI in November 2022, sparked a significant conversation about the impact of Artificial Intelligence in Higher Education. It disrupted the status quo when students used it to craft their essay submissions. Alongside Google's BARD and Microsoft's BING, OpenAI’s ChatGPT is a prime example of a powerful large language model (LLM) capable of mimicking human conversation. Large language models have demonstrated impressive results in identifying language patterns and predicting contextual words and excel at generating coherent and relevant textual responses with minimal input from the user. By leveraging its extensive database of trained language patterns, large language models can provide generated textual responses that accurately reflect the context of the user's input. With their command of languages, they can construct creative poems and write comprehensive and coherent essays, analyse topics in depth and present arguments persuasively. As a student at the University of Pretoria, you have access to generative AI, a valuable tool that can significantly enhance your learning journey. As you delve deeper into your studies, you'll be honing vital workplace skills, ranging from self-motivation and professional communication to ethical practices, teamwork, and problem-solving capabilities. While Generative AI harbours tremendous potential for augmenting our productivity and learning processes, it is crucial to be cognizant of the inherent risks. Large language models (LLMs) do not truly comprehend the semantic content of the text. Instead, they generate text based on patterns and relationships between words identified during their training phase. Thus Generative AI should only assist learning and not act as a substitute for human creativity and critical thinking. While Generative AI has many strengths, it also has some weaknesses. One of its main limitations is its limited contextual understanding, which can lead to incorrect or irrelevant answers. Its dependence on data quality and quantity can also lead to biases or limitations, and the lack of references makes it difficult to verify the accuracy of the information provided. Therefore, it is essential to evaluate the output carefully and use it in conjunction with other educational resources, and never to replace practising and learning critical human reflection. To get started, it's important to familiarise yourself with Google's BARD and Microsoft's BING, OpenAI’s ChatGPT and other AI tools: The URL for accessing ChatGPT is https://chat.openai.com/auth/login. The free access to ChatGPT is sometimes unavailable due to high demand. The URL for accessing Google BARD is https://bard.google.com, or you can use Microsoft Edge or the Bing search engine with built-in support for OpenAI’s ChatGPT, which provides citations and uses updated data sources. Dall-E (https://labs.openai.com/) and Midjourney (https://www.midjourney.com) are the most popular art generation tools. Numerous other AI tools are accessible, as illustrated by the website https://www.futuretools.io. 

General Principles and Guidelines  

 

When using generative AI like ChatGPT, it is essential to follow some guiding principles to ensure the technology is used effectively and ethically. Some guiding principles could be considered:  

Understand AI capabilities and limitations: Gain a solid understanding of generative AI’s strengths and weaknesses to utilise it effectively for learning. 

Use as a supplementary tool: Treat generative AI as an aid to expand your knowledge, enhance your critical thinking, and assist with generating ideas rather than as a replacement for thorough research and academic rigour. 

Cite sources properly: When using information from generative AI in academic work, ensure proper citation and attribution to avoid plagiarism.  

Fact-check and verify the information: Verify the accuracy of the information provided by generative AI using credible sources, as the AI may not always provide the most up-to-date or accurate information.  

Consider ethical implications: Be aware of biases in the AI and work to mitigate them. Use AI responsibly, avoiding generating harmful, offensive, or misleading content.  

Ensuring Data Privacy and Confidentiality: When using generative AI technologies in the classroom, it is crucial to ensure that personal or confidential data is not included in the training data, as the AI could unintentionally reproduce or leak sensitive information. Always use anonymised, non-identifiable data for training purposes and be aware of data privacy regulations to protect all individuals involved. Some generative AI technologies, like ChatGPT, allow users to apply the appropriate settings to prevent ChatGPT from utilising or learning from your interactions involving personal, sensitive, or confidential information. Failing to do so may result in the model learning from your exchanges and considering the data as publicly accessible. To ensure compliance with data privacy laws, applying the appropriate settings to prevent ChatGPT from utilising or learning from your interactions involving personal, sensitive, or confidential information is crucial. Failing to do so may result in the model learning from your exchanges and considering the data as publicly accessible. To deactivate model training and the storing of your chat history in ChatGPT, follow these steps: 1. Click on your name in the bottom-left corner of the page. 2. Select "Settings" to open the settings popup, and click on "Data Controls" followed by "Show." 3. A menu will appear, allowing you to adjust the "Chat History & Training" setting. When enabled, the setting appears as shown below. 4. When you disable this setting, new conversations will no longer be utilised for training and enhancing our models. By following these guiding principles, generative AI, like ChatGPT, can be a valuable tool for teaching and learning at universities.  

Academic Integrity 

 

 In the era of high-tech tools like artificial intelligence and generative AI, you must be careful and clear to ensure your work maintains its academic integrity. If you are unsure about whether or how you are permitted to use generative AI tools like ChatGPT, Google BARD, or Microsoft BING for your assignments or assessments, consult your study guide or ask your lecturer. Failing to adhere to these guidelines would be considered academic dishonesty.  

Plagiarism 

 

 Generative AI, such as ChatGPT, should be acknowledged and cited like any other source. 

Presenting generative AI work as one’s own is (although not “plagiarism” as such) fraudulent since it is not original work. The University of Pretoria's plagiarism declaration states, “I declare that this essay, report, project, assignment, dissertation, thesis, etc. is my own original work. Where other people’s work has been used (either from a printed source, the internet or any other source), this has been properly acknowledged and referenced in accordance with the requirements as stated in the University's plagiarism prevention policy.” You have to reference or acknowledge the use of generative AI. An example of Acknowledgement is: “The creation, enrichment, and editing of this article for enhanced clarity was facilitated by the use of ChatGPT”. For content generated by the AI, provide a citation that includes the name of the AI, the version (if applicable), the organisation that created it (OpenAI for ChatGPT), and the date of access. It's also a good practice to mention that the content was AI-generated. For example, ChatGPT-3, OpenAI. (2023). AIgenerated content accessed on [date].  

Strategies for Optimising AI Prompts and Achieving Desired Results  

 

If you are new to using generative AI, it may be helpful to have some hints on how to improve your prompt (input) and receive the desired result: Hint Examples of prompts (input) Be clear, concise and specific Explain the concept of blockchain technology in simple terms. Provide context What are some effective study techniques for someone preparing to take a biology exam Ask follow-up questions Explain more about how they work. Specify the language output Respond in UK English Specify the length of the response I would like a brief/detailed/300 words response (the maximum is about 3000 words) Specify the response format Present your response in bullet points/table/paragraph Specify the level of output Respond suitable for a second-year university student” or “an A-rated student," or "I would like an in-depth analysis. Specify the tone/style of the output Write my text in the style of Shakespeare 

 

Use Generative AI to Enhanced Learning Task Examples of prompts (input)  

 

Summarise and theme your information Provide a 300 words overview/summary/essay about the role of central banks in addressing macroeconomic challenges or use your text. Solve mathematical equations and explain the steps Solve the following quadratic equation: x^2 + 5x + 6 = 0 and explain the steps. Then, practice solving these equations yourself using these steps to solve equations with different values. Provide an overview of complex, lengthy concepts Can you provide an overview of quantum mechanics? Generate writing prompts for creative writing assignments Suggest a creative writing prompt for a short story involving time travel. Evaluate the suggestions and use one or a combination to write your creative piece. Get alternative phrasing for difficult-to-express ideas I am having trouble expressing my argument for why … rephrase my main points. Help with language learning and practising grammar and sentence structures Give me an example of a complex sentence using the word 'notwithstanding'. Generate outlines for writing assignments I have to write an essay about the causes of World War II. Can you help me create an outline to organise my ideas? Evaluate the output against the assignment requirements and the module content to make sure you address the main points. Get feedback on written work Provide feedback on my essay about climate change and suggest areas where I could improve. Get formative assessment feedback on the quality of the language Provide feedback on grammar and vocabulary usage of the following … Test preparation Create six multiple-choice questions to assess the students' understanding of integration from first principles in a first-year university mathematics course. Remember that your lecturer might set different questions than these. Write a computer code or Excel formula and ask generative AI Explain how the 'for' loop works in Python, and provide an example.to explain how it works Use generative AI to plan projects and essays What main topics need to be covered on this topic: African indigenous plants? Evaluate the output against the assignment requirements and the module content to make sure you address the main points. 

 

Boosting Student Productivity with Generative AI 

 

 Task Examples of prompts (input) Proofread written work and check for grammar, punctuation, and spelling errors Proofread the following text: … Create an Excel formula to automate calculations Create an Excel formula to calculate the average of a range of cells. Create PowerPoint slides for presentations Create ten slide PowerPoint presentation on the topic of renewable energy or use your text. Then personalise it to your style. Generate code for various programming languages and applications Write a Python program that calculates the Fibonacci sequence. Edit your CV, write a cover letter, and prepare for an interview Write a CV based on the following information …; follow-up prompt: Use my CV to write a cover letter based on the following key requirements in the job description – paste job description; follow-up prompt: Give me ten possible interview questions and the appropriate reply to them based on my CV and the job description. Data analysis and identifying themes analyse and identify themes when dealing with large data sets Data analysis and identifying themes analyse and identify themes when dealing with large data sets 

Providing Personalized 24/7 Tutor Support via Generative AI  

 

Task Examples of prompts (input) Explain and teach a topic like a tutor Teach me how to solve cubic equations and include a quiz at the end. Allow me to answer, and if it is wrong, explain the steps. Summarise long or complex readings to make it easier to Write a half-page summary about the main ideas of … . Evaluate the output against the assignment requirements understand and retain critical concepts and the module content to ensure you address the main points. Assist with homework E.g., Calculate 0 5 ∫ 3𝑥 3 + 2𝑥 2 ( − 4𝑥 + 6)𝑑𝑥 Solve \𝑖𝑛𝑡_{0}^{5}\𝑙𝑒𝑓𝑡(3𝑥^3 + 2𝑥^2 − 4𝑥 + 6\𝑟𝑖𝑔ℎ𝑡)𝑑𝑥 Follow-up prompt: Give an example of a real-world problem that could be solved using this formula. Then, practice solving these equations yourself using these steps to solve equations with different values. Generate alternative phrasing or synonyms to improve the quality and clarity of written work Provide an alternative phrasing for the sentence: ‘The research findings were inconclusive’. Identify prior knowledge required to understand a topic What prior knowledge do I need to understand the principles of supply and demand in economics? Translate into home languages Translate the following passage from English into isiXhosa: ‘The internet has revolutionised how people communicate and share information. If you are unsure if the output is correct, check it with another person who knows both languages’. Provide scaffolding support Break down the steps involved in solving a quadratic equation and explain each step in simple terms. Ask generative AI for examples Provide an example of a deductive argument and an inductive argument, and explain the difference between the two. Provide coding support and explanations for different programming languages Explain how to use a ‘for’ loop in Python to iterate over a list of numbers. Give study tips or ideas to improve marks or time management tips What are some effective study strategies for preparing for exams? Create a glossary of terms for a topic in different languages Create a glossary of terms for an introduction to psychology course in English and isiZulu. Generate questions and answers for studying or test preparation Generate ten multiple-choice questions and answers on organic chemistry. Get feedback on written work Review my essay on climate change and provide feedback on its clarity and organisation.  

Providing Support 

 

 Student support Example Prompt Time management How can I improve my time management skills to study more effectively? Motivation How can I stay motivated to study, even when I don't feel like it? Study habits What are some good study habits that I can develop? Test-taking strategies 

What are some tips for taking tests effectively? Procrastination How can I overcome procrastination and start studying sooner? Stress management How can I manage stress so that it doesn't interfere with my studies? Academic help Where can I find academic help if I'm struggling with a class? Career planning How can I start planning for my career? Financial aid assistance Where can I find financial aid at the University of Pretoria NSFAS queries When do NSFAS applications open  

Summary  

 

ChatGPT is a valuable tool for learning due to its many strengths. One of its key strengths is its automation and 24/7 availability, providing instant student support. It also offers personalised assistance, helping you better understand complex topics. ChatGPT's ability to summarise information in an easy-to-understand way promotes self-directed learning, and its speedy answers save time for both students. Its multilingual capability ensures accessibility for a broader range of users, while its quick accessibility and availability mean that support is always available whenever needed.  

 

5. UJ Practice Notes: Generative Artificial Intelligence  

 

Rapid developments in generative artificial intelligence (AI)2 technologies have led to an explosion of AI generators of text, code, images, and voice, of which ChatGPT is one example.3 AI generators can, with varying degrees of effectiveness, generate answers to a question, produce code, text and content, and design an artefact, based on prompts. They can be used to learn, to respond to assignments, or to produce material for research and other academic publications. The purpose of this practice note is to set out the ways in which generative AI technologies may be used to complement learning, teaching and research.4 The note acknowledges the benefits of generative AI while recognising its risks and potential harms. The essential approach is to be Responsible, Informed, Transparent and Ethical (Gutiérrez, 2023). The practice note promotes the critical and ethical use of generative AI across UJ (see Appendix A for useful resources). 

Be responsible: Be sure to foreground learning integrity in your use of generative AI tools. This means that you use the tool in a way that helps you make sense of the content and enhance your skills, rather than simply using it to complete an assignment. For example, limit the use of generative AI tools to the early stages of writing and research – to inspire, brainstorm and plan – rather than produce content for you. Immerse yourself in the process of learning, and not only the product you are asked to create. Be careful not to rely on generative AI, as you may not develop your own writing skills, style, critical thinking, and creativity. Be informed: Before you use generative AI, you should “research who or what company developed the tool, how it was developed, how it works, what functions it can perform, and what limitations and/or risks it presents” (Gutiérrez 2023). Check for updates and reports on bugs or data leaks. Stay informed on the broader ethical issues relating to AI tools. Some of these issues include privacy and data, intellectual property infringements in the development of these tools, labour exploitation in the process of building these tools, and the environmental impact of the development and use of these tools. Be transparent: Clearly indicate which tools were used, and how you used them. Be ethical: Distinguish between what you produced, and text/image produced by an AI tool through citation and quotation marks. It is wrong to present AI-generated work as your own work and doing so is academic misconduct. 

Always indicate where you have used generative AI resources and to what extent. Use the plagiarism declaration as a checklist to ensure that your work meets the necessary standards for academic integrity. The practice note applies to all generative AI available at any time. a. These tools are updated continuously, and new tools are created almost daily.  b. Given the speed with which this technology is evolving, it is imperative that the University remain abreast of developments in the field. c. Some of the tools available at no cost are greatly enhanced when the user pays a fee. In paid apps, the risks of increased inequities and misuse require constant vigilance. 

BENEFITS OF GENERATIVE AI TOOLS FOR LEARNING, TEACHING AND RESEARCH   

Generative AI tools have multiple capabilities which have the potential to provide benefits and added value to academics and students alike. Generative AI tools has many uses, value and benefits, some of which are set out below: • save time • develop critical thinking skills if used correctly • enhance motivation • generate ideas and brainstorm • generate code • improve equity between speakers of different language or writing abilities • improve grammar and writing structure, especially for English second-language writers • develop AI literacies and skills5 • get over writer’s block • provide learning prompts and suggestions • create many types of quiz questions • do calculations • assist in examination preparation by generating questions and answers • experiment with different writing styles • use with students who may have specific needs that can be addressed with AI • find teaching materials, images, slide shows, etc. for lecturers • updating of learning materials • offer general feedback on students’ writing • grade students’ work using a rubric • generate ideas for images, visuals and graphics • draft ideas and plan or structure written materials • be used as a form of search engine to source, select and organise data and references Specific to learning and teaching, Mike Sharples (2023) identifies ten roles for generative AI. The recent UNESCO quick start guide on CHAT GPT and AI in higher education unpacks these roles in further detail, as can be seen in Table 1. Watkins (2022) also offers some practical ideas for using generative AI in courses, emphasising the importance of making time to reflect on ethics, the aims and outcomes of specific activities, and integrating generative AI in ways that save time while deepening the learning experience. 


 

 

Role Description Example of implementation Possibility engine AI generates alternative ways of expressing an idea Students write queries in AI tool and use the regenerate response function to examine alternative responses. Socratic opponent AI acts as an opponent to develop and argument Students enter prompts into AI tool following the structure of a conversation or debate. Lecturers can ask students to use AI tool to prepare for discussions. Collaboration coach AI helps groups to research and solve problems together Working in groups, students use AI tool to find out information to complete tasks and assignments. Guide on the side AI acts as a guide to navigate physical and conceptual spaces Lecturers use AI tool to generate content for classes/courses (e.g., discussion questions) and advice on how to support students in learning specific concepts. Personal tutor AI tutors each student and gives immediate feedback on progress AI tool provides personalised feedback to students based on information provided by students or lecturers (e.g., test scores). Co-designer AI assists throughout the design process Lecturers ask AI tool for ideas about designing or updating a curriculum (e.g., rubrics for assessment) and/or focus on specific goals (e.g., how to make the curriculum more accessible). Exploratorium AI provides tools to play with, explore and interpret data Lecturers provide basic information to students who write different queries in the AI tool to find out more. An AI tool can be used to support language learning. Study buddy AI helps the student reflect on learning material Students explain their current level of understanding to the AI tool and ask for ways to help them study the material. AI tool can also be used to help students prepare for other tasks (e.g., job interviews). Motivator AI offers games and challenges to extend learning Lecturers or students ask AI tool for ideas about how to extend students’ learning after providing a summary of the current level of knowledge (e.g., quizzes, exercises). Dynamic assessor AI provides educators with a profile of each student’s current knowledge Students interact with AI tool in a tutorial-type dialogue and then ask AI tool to produce a summary of their current state of knowledge to share with their lecturer/for assessment. 

With regards to research, the UNESCO quick start guide proposes possible uses of generative AI at different stages of the research process: from research design (e.g., brainstorm research questions), to data collection (e.g., prepare for interviews), data analysis, and writing up (e.g., as a personal writing assistance) – see Figure 1. It can also be used in technical parts of research grant applications, generating communication plans (Sabzalieva & Valentini, 2023:9), and to generate ideas for a presentation. Writing up • Improve writing quality • Reformat citations and references • Translate writing Research design • Generate ideas for research questions or projects • Suggest data sources Data analysis • Code data • Suggest themes or topics for analysis. Data collection • Search archives and datasets • Translate sources into other languages. Figure 1: Possible uses of generative AI in research (Source: Adapted from Sabzalieva & Valentini 2023:10) To enjoy the benefits indicated above, without the risks and potential harms of generative AI, UJ students and staff need to understand and apply responsible, informed, transparent and ethical use of these tools. Learning and research integrity, assessment integrity and academic integrity must be at the forefront of any use of generative AI. 

 

TEACHING, LEARNING AND RESEARCH INTEGRITY 

Generative AI promises new advances in teaching, learning and research, though with clear concerns regarding the pace at which developments in AI are rapidly changing knowledge and society (Watkins, 2022; Prochaska, 2023). One clear benefit is the speed at which generative AI tools can produce content, gather and organise information. This does not replace the work of higher education or educational institutions, but rather emphasises the growing importance of fostering critical thinking, higher-order application, core literacies and collaborative capacity, within ethically-driven learning contexts. Generative AI challenges traditional modes of teaching and learning in a number of ways. Rapid access to information and the ability to use tools such as ChatGPT to write essays, produce code, make calculations, or summarise readings changes the ways that students engage with knowledge, in some ways reducing the traditional number of 

‘steps’ or processes required to unlock new information, such as writing, problem-solving, summarising or referencing. At the same time, new challenges emerge from the ease with which these steps are resolved, requiring teaching and assessment that keeps in step with generative AI as a new substrate of the learning process. AI systems are imperfect and lack the ethical and critical capacity to sift through and determine the veracity of information, or detect biases – indeed, generative AI tools may reproduce social and cognitive biases based on the parameters and information available to them. While this may change in the future, it still requires staff and students to engage with generative AI as a component of the learning process rather than a substitute. It is therefore essential that staff are supported in developing critical literacy and capacity in the use of generative AI tools, not only in order to support their own work but to develop these capacities in students. Best practices from fellow institutions in SA, as well as leading global universities, point to the value of ‘AI orientation’ as part of student onboarding alongside dedicated review and discussion of generative AI tools in course outlines and introduction, writing workshops, assessments and practical activities. The UNESCO guide provides an overview of some of the teaching and learning strategies that may be complemented by the use of generative AI. It also highlights the importance of conducting whole-institution audits to assess the potential value that generative AI can add to teaching and learning, determine potential challenges and risks, and plan for cost-effective implementation. Designing effective monitoring systems forms part of the implementation of generative AI tools, particularly given the emphasis on proving that quality teaching and learning has taken place outside of traditional assessment modalities. ChatGPT is a widely known and used generative AI tool. There are a number of ways that it and other AI tools can be used to create exciting, collaborative and meaningful learning experiences. For students, they can be used to develop critical thinking capacities by offering activities that require analysing, critiquing or building on information accessed through the platform. A number of examples have been provided above, with simple inclusions being: • using an AI tool to answer an assignment prompt, and annotating the generated assignment with personal reflection and evaluation of the content as an in-class activity or using 

Track Changes. • comparing an AI tool’s results to problem-solving prompts alongside practical experiences, e.g., in the case of engineering, medicine, or design. This is particularly useful given the nature of geological shifts, biological anomalies, and other dynamics that may contest or contradict the information being processed by the AI tool. • allowing an AI tool to be uses in assignments while allocating marks for reference to specific practicals, class discussions, and other shared experiential knowledge.Paid applications such as Chat GPT-4 have increased these model’s capacity for reading longer texts, able to provide insightful comments on full-length texts. It can also be used to set up an enquiry workflow. The key is to good use is effective prompts which ensure that ChatGPT goes from reading a text to providing insights needed. Institutions can build an ‘AI tutor’ as part of an existing LMS. It is recommended that UJ develop a monitoring tool to identify whether and how students and staff have used an AI tool such as ChatGPT in their research writing, and to establish whether AI generated searches and prompts have been applied. The Scholarship of Teaching and Learning (SOTL) is critical to navigating the adoption and adaptation to generative AI use including in research. Undergraduate and postgraduate research modules and activities, and academic research activities generally need to consider the ethical and practical implications of generative AI tools within different fields. This includes using generative AI to develop research instruments, code or analyse data. Important privacy risks emerge when considering the institution’s intellectual property and confidentiality regulations alongside the use of thirdparty applications for data processing. Additionally, new considerations around generated content ownership also apply, for example, where generative AI has been used to produce a significant proportion of the discussion in published research. 

 

ASSESSMENT INTEGRITY 

The purpose of assessment is for students to demonstrate their learning. Generative AI requires significant shifts in how learning is assessed given that current assessment modalities may be easily circumvented through the use of generative AI tools. This has implications for plagiarism and academic dishonesty, but furthermore undermines the primary outcome of meaningful learning taking place, and the processing of information into knowledge through analysis, application and experience. There are several ways to mitigate the risks of academic misconduct through generative AI in the design of an assessment.  

For example: • assign more formative assessments • do more assessed work in class / synchronously • design assessments with practical requirements • ask students to submit rough notes with the final work • assign assessments to be completed in class, such as presentations, selfreflection tasks, in-person class tests, and so on • ask students to hand-write assessments in class • identify clear criteria for marking rubrics and assessment modalities • require students to use the most recent resources available • encourage collaborative online annotation of texts • change the format of the task / submission to include formative assessments • add the requirement for personal knowledge or experience • ensure that assessments evaluate the student’s ability to argue, or to provide analysis, or evidence • require students to make analytical, factchecking or evaluative critiques of the AI response • assign peer review tasks • ask students to reflect on their own thinking and writing processes on written feedback forms 

It is important for assessment to consider what is to be learned and what students should be able to demonstrate at the conclusion of a course or module. A note from UK universities highlights the importance of drawing industry and social partners into the revision and rethinking of assessments that emphasise the application of knowledge to practical conditions and challenges. Group assessment, including peer evaluation, is one way to build layers of formative and summative assessment into the design of courses. Service projects with reflective and theoretical components can also build critical analysis into the practical dimension of learning. Cost and time constraints are unavoidable considerations when thinking through alternatives to existing assessment methods, which in turn requires thinking about how multi-departmental or crossdisciplinary panels or working groups could support any number of generative AI assessment processes within a given term or semester. Allowing students to choose between using generative AI or not, with effectively delineated criteria for each assessment type, may also provide more scope for those students interested in other modes of learning and conducting research 

ACADEMIC INTEGRITY    

Academic integrity comprises honesty, trust, fairness, respect and responsibility. These values should underpin all academic work by UJ students and staff irrespective of technologies used. A holistic understanding of academic integrity extends to the whole University. The inappropriate use of generative AI for teaching, learning and research may contravene academic integrity. In such cases, academic dishonesty results. For these reasons, this Practice Note must be read in conjunction with UJ’s Policy on Plagiarism and Disciplinary Code and Procedures for Employees, Regulations for Student Discipline, and the Student Regulations. To present the work of someone else or of a generative AI tool, in whole or in part, as one’s own, is academic dishonesty. To mitigate the risks of academic misconduct, in the context of generative AI, it is recommended that: 

lecturers clearly communicate with students – in learning guides and in class conversations – whether and how they may use generative AI in their course and for which assignments. • students and researchers be transparent and sign a declaration that the work is their own. • where generative AI has been used, the declaration should include an acknowledgement of the tools used, with indications of for what and how these were used (see Appendix B for an example of such a declaration template). • students and researchers take responsibility for any factual errors or fabricated references in their work, even if these were generated by AI tools.   • There should be awareness that with advances in AI autonomy, work generated could become increasingly original. 

Whilst there are no conventions as yet for referencing, there is a suggested approach from the University of Queensland, Australia. In brief, these are based on the APA guidelines for personal communication and correspondence as the content is generally not recoverable. 

In-text references: Author of generative AI model, Year of version used Example: (OpenAI, 2022) or OpenAI (2022) In the Reference list: Author of AI model used. (Year of AI model used). Name of AI model used (Version of AI model used) [Type or description of AI model used]. Web address of AI model used Example: OpenAI. (2022). ChatGPT (Dec 20 version) [Large language model]. https://chat.openai.com/ Note that the complete transcript of the response obtained to a prompt can be included as an appendix. 

Notwithstanding any declarations as to the veracity of the tools, AI-text detection tools6 have limitations. Accusations of academic dishonesty based on detection tools alone may be false and further engagement with the content as well as with the student/s and researcher/s would be required before action can be taken against this kind of academic dishonesty. The low reliability of AI writing detection tools in general (Heikkilä 2022; Milano et al 2023) requires that an assessment of the content of material not rely on an AI checker alone.  

ETHICAL CONSIDERATIONS  IN THE USE OF GENERATIVE AI 

Generative AI tools can be used to improve teaching and learning through troubleshooting, developing resources, evaluating outputs, generating dummy student responses, and identifying new activities and pedagogical strategies. It can be used to assess language proficiency, offer students personalised learning support, and make sense of large amounts of data or complex scenarios. However, these also create new challenges in the ethical use of generative AI for teaching and learning. 

First, it must be noted that there are inherent biases in AI tools, and concerns related to privacy, accessibility and equity, and sustainability. The two major biases in AI are cognitive bias and gender / racial bias. AI does not ‘know’ the facts, or what is right and wrong; it only reproduces based on the content it has been able to gather. Secondly, generative AI tools give the developers the means to gather data about users without their permission and for unknown purposes. Privacy issues should be foregrounded in concerns around the use of generative AI. There have been several public cases of data leakage, where generative AI has reproduced sensitive or personal information gathered from users. This further raises concerns about intellectual property and data confidentiality, particularly in the use of demographic and qualitative data. While generative AI has been lauded for its value in marking or grading assignments, using it to mark reflective and personallyembedded work has serious ethical implications, both for the privacy of the student and for the potential dissemination of personal information through ineffective security parameters. Additionally, it is important to have clarity on the data storage/ data protection policies of generative AI tools such as ChatGPT, as well as AI plug-ins for existing programs. Where institutions are using third-party tools for teaching, learning and research, ongoing evaluation of privacy and data storage policy is essential to protecting the academic freedom and freedom of information on university campuses. This includes the right of refusal, scrubbing of sensitive geodata or login information, and so on7 . The difference in terms of service between free and paidfor versions of AI tools should also be considered. Affordability means that those who can afford it are privileged in respect of its use. Unless institutions provide blanket or subsidised access to generative AI tools, it is likely that students with greater financial means will be able to maximise the benefit of these tools for their academic performance, and/or be able to afford upgrades that outpace existing usage, plagiarism and assessment policies in place. The alternative would be to restrict the use of generative AI except under authorised conditions or using university-approved tools, although this presents with planning and monitoring demands. Finally, sustainability concerns have been raised regarding the environmental impact8 of ChatGPT and related generative AI tools, alongside human rights concerns regarding the manner in which the tools are developed. The University needs to consider the legal and ethical implications of the generative AI enlisted to support institutional functions, as well as prioritise research, collaboration and development for ethical, open-source and low-cost alternatives. 

CONCLUSION  

UJ recognises the benefits of generative AI for learning, teaching and research, underscored by the following principles for responsible use: • Be informed: Before you use a generative AI tool, you should “research who or what company developed the tool, how it was developed, how it works, what functions it can perform, and what limitations and/ or risks it presents” (Gutiérrez 2023). This includes regularly checking for updates and reports on bugs or data leaks. • Be transparent: indicate which tools were used, and how you used it. • Be ethical: distinguish between what you produced and text/image produced by AI tool through citation and quotation marks. • Be responsible: for example, limit the use of generative AI tools to the early stages of writing and research – to inspire, brainstorm, plan – rather than produce content. 

RECOMMENDATIONS 

Each domain in the University will be impacted differently by the use of AI generators. Care should be taken across all domains to ensure that appropriate measures are in place to encourage the critical use of these applications. The assurance of the integrity of learning and teaching, assessment, and research and academic integrity must be maintained. As the adoption and adaptation of generative AI in higher education expands, it may become necessary to consider a core course or set of progressive micro-credentials in critical AI literacy, ethics and skills. Resource and support facilities for the use of generative AI should be housed within the library and information services in order to appropriately locate AI tools within the domain of research and knowledge. Scholars such as Crawford et al (2023) and Nah et al (2023) argue that the introduction of generative AI in higher education will increase the need for deeper education on ethics, critical thinking and analysis, as well as issues in social justice, inequality and ecology. Students need to be equipped to validate, verify, and critique sources of information, including answers generated by chatbots. They also need to be aware of the limitations of these tools, including those identified by their creators, as well as the ethical and legal considerations that apply when making use of generative AI tools and platforms. It is critical to consider what effective penalties for generative AI misuse may constitute, both for staff and students. It is likely that a wide survey of ideas, inputs and strategies will need to be considered given the continually changing nature of AI and the differences between disciplines. Incentives can also be offered that prioritise alternatives to AI use, e.g., using resources such as books or journal articles, or conducting snap research with peers on campus. Sharing personal information, using chatbots to screen commercially or personally sensitive work, or analyse confidential data, are some of the issues that will need to be managed in orienting staff and senior students to the use of generative AI. 

6. Stellenbosch University Academic Integrity: Responsible Use of AI tools 

 

Description 

Academic integrity refers to the values that underpin everything you do in your university studies. It 	includes 	concepts 	like 	honesty, 	trust, 	fairness, 	respect 	and 	responsibility. 

To succeed at university by studying with academic integrity, you need to understand, develop and practise particular academic skills, including: 

correct referencing 

avoiding plagiarism 

critical thinking and the ability to find and evaluate sources 

Are students allowed to use ChatGPT and other AI tools? 

Check with your lecturer first!  And follow the guidance from your lecturers. Some lecturers will allow the use of AI tools like ChatGPT, while other will not allow the use of such tools.  Artificial intelligence should be viewed as a tool that can aid learning  and should be used in an ethical way. Do not copy word-for-word or claim any AI-generated content as your own work. This is plagiarism. 

					AI 	Use 	Disclosure 	Statement 

The EMS Faculty recommends that AI use be declared, and it includes a student declaration form, that requires an indication of the AI tools used, as well as where and what it were used for, and a justification for claims that the work is the student’s own. 

Responsible use of AI tools 

									Accountability 	(including 	the 	ideas 	of 	acknowledgement 	and 	attribution) 

You are responsible for what you create and how it impacts others and society. AI tools don't have accountability. It is thus your responsibility to ensure that work submitted under your name is factually correct. 

Authenticity 

You may use AI tools to assist where relevant, but not to complete the assignment on your behalf. 

Fairness 

Your use of AI tools/ systems should be ethical and responsible and should comply with academic integrity 	standards 

Transparency 

You should clearly and honestly declare the use of AI tools and their outputs as well as the extent of the use. 

Is it safe to use ChatGPT for your assignment/essay? 

 

  

Flowchart by Aleksandr Tiulkanov, January 2023. 

Declaration example 

 

7. Stepping up with ChatGPT - AI-assisted Technology in Education 

 

In today's fast-paced world, technology has transformed how we work, communicate, and learn. One such technological advancement is ChatGPT (Generative Pre-trained Transformer), an AIpowered language model developed by OpenAI. This large language model can imitate human conversation, predict contextual words, and generate coherent and relevant textual responses with minimal user input. ChatGPT has the potential to provide personalised learning experiences, improve student engagement, and ease the burden on teachers and administrators. As a userfriendly AI tool available for free, ChatGPT can assist students in writing, coding, and solving mathematical equations. However, educators must evaluate the benefits and limitations of AI technologies, including ethical concerns, and adapt their teaching strategies accordingly. Ethical considerations and responsible use guidelines are critical when using ChatGPT. 

How and why is ChatGPT relevant for academics? 

ChatGPT's relevance for academics lies in its potential to improve the teaching and learning experience by providing personalised feedback and assistance to students. One example is in writing research papers, where students can use ChatGPT to receive suggestions for improving their writing style, word choice, and overall coherence of their arguments. By providing personalised feedback, ChatGPT can help students improve their writing skills and reduce the time required for grading by educators. It can also facilitate communication and collaboration internationally. Academics can use ChatGPT to translate academic articles into different languages, making them accessible to a broader audience. This can facilitate cross-cultural collaboration and enhance research impact. 

Although ChatGPT can potentially improve teaching and learning, it must be used responsibly to ensure that the technology compliments rather than substitutes human input during the learning process. One issue raised is the possibility of plagiarism. To prevent this, educators must ensure that students understand the importance of academic integrity and that ChatGPT is used only to supplement their work, not replace them entirely. Another issue is the potential bias in language models. ChatGPT is trained on large amounts of text data, including biased language and perspectives. This can result in the generation of biased text, which can be harmful or perpetuate stereotypes. Again, educators must be aware of the potential biases and ensure that it is used fairly. 

Getting started with ChatGPT 

To use ChatGPT, Sign up or Log in. Before incorporating ChatGPT (or other AI tools) into your teaching, ensure you are acquainted with them. The following is essential: 

Clarify to your students that ChatGPT uses a database to generate probable word sequences and lacks understanding, reasoning, or thinking capabilities, and that 

ChatGPT is a learning aid, not a replacement for creativity and thinking. 

Encourage open dialogue about the ethical concerns of using ChatGPT, including potential biases, copyright issues, labour disputes, environmental impacts, and data rights. 

Provide guidance on procuring and evaluating multiple outputs and combining them with other research and writing tools to effectively use ChatGPT. 

Urge students to seek feedback from peers and instructors to enhance their use of ChatGPT. 

State your policies on use of ChatGPT and other AI tools clearly in your course materials, and instruct students on how to acknowledge its use correctly. 

To comply with data privacy laws, avoid using ChatGPT for private or sensitive information, as it considers such information as public domain data. 

Applications of ChatGPT for academics 

ChatGPT has numerous applications in research. A critical aspect of research is the ability to process and analyse large volumes of data and ChatGPT can assist with natural language processing, summarisation and synthesis of complex data sets and other data processing and analysis tasks like predictive modeling and forecasting. ChatGPT can play a role in hypothesis generation and testing by helping to identify potential research topics based on existing literature and suggesting appropriate experimental designs and methodologies. It can also help in the exchange of ideas and facilitating collaboration among researchers by connecting them with relevant experts and resources, or enhancing communication through natural language processing. And since ChatGPT contributes to the dissemination of scientific knowledge to the general public, it assists with public outreach and science education by simplifying complex scientific concepts for non-experts. 

Before you start: 

Familiarise yourself with the model. ChatGPT is a large language model trained on vast amounts of text data. Before using it with your students, it's important to understand the model's capabilities and limitations. You can find more information about ChatGPT's architecture and training on OpenAI's website and research articles on ChatGPT. 

ChatGPT can be accessed through various platforms, including OpenAI's website, thirdparty apps like Hugging Face, or API integrations with other tools. Choose the platform that works best for you and your students. 

Once you've familiarised yourself with the model and chosen a platform, start a conversation with ChatGPT by typing your research question or topic, for example. The AI model will respond with an answer or suggestion. 

These answers can be very helpful, but they may sometimes differ from what you need. If you need more information or want to refine your question, you can ask follow-up questions or rephrase your original question. See how in our recent webinar on ChatGPT: 

As with any research tool, evaluating the quality of ChatGPT's responses is essential. Double-check the information provided and consider the source before using it in your research or writing. Important: references provided by ChatGPT might not be correct. 

Once you've evaluated the responses and determined that they are helpful for your research, you can incorporate them into your writing or analysis. 

Cite your sources! Like any other research tool or source, citing ChatGPT in your writing is essential. Include information about the model and platform you used and the data and time of your interactions. Describe how you used the tool in your methodology chapter and provide the prompt you used. Remember, ChatGPT chats is not retrievable by other reader. Sharing text from your chats will be more like sharing an algorithm's output. Or you can put the full text or long responses from ChatGPT in an appendix of your work. See this example from APA Style: 

Tips for using ChatGPT effectively 

We would like to give you some useful tips and ideas for using ChatGPT effectively. The table below provides a set of hints and examples on how to improve the use of ChatGPT in an academic setting. These tips cover different aspects of ChatGPT usage, from improving the quality of the generated text to avoiding ethical issues and include specific prompts to illustrate how to achieve the desired results.  

Context 

Prompt example 

Provide specific instructions or guidelines 

"Can you give me step-by-step instructions on how to conduct a literature interview?" 

Use technical language and provide context 

"What is the impact of neural networks on natural language processing in linguistics?" 

Incorporate feedback from human input 

"Based on the feedback from my professor, can you help me revise my research questions?" 

Ask follow-up questions 

"Explain more about the theory mentioned above." 

Consider ethical implications and bias in language models 

How can we ensure that the language generated by ChatGPT is unbiased and free from potential harm? 

Specify the length of the response 

"I would like a brief and detailed 250 words response." 

Provide context for more accurate responses 

Instead of asking "What is the capital of France?" provide additional context, such as "In what year was the Eiffel 

Tower built?" 

Specify the response format 

ChatGPT can provide your response in bullet points, tables and paragraphs. 

Evaluate the accuracy and quality of responses 

Review generated responses for accuracy and relevance to the prompt and adjust the prompt or model settings as necessary. 

Specify the language output 

"Respond in UK/US English, please.? 

While ChatGPT has a wide range of potential uses in various academic settings, it is essential to

understand its strengths and limitations to ensure responsible and effective use of the tool. 

Capabilities 

Limitations 

Can generate human-like responses to natural language inputs 

May produce biased or offensive language due to biases in training data 

		Can 	provide 	personalised 

learning experiences 

Cannot provide feedback on accuracy or quality of responses 

Can assist with writing, coding, and solving mathematical 

equations 

It may be used for academic misconduct, such as plagiarism 

It can be used for a variety of natural language processing tasks 

Limited by the quality and quantity of training data 

Can ease the burden on teachers and administrators 

Does not have a proper understanding of consciousness and can only generate responses based on patterns in training data 

Can improve student engagement 

May perpetuate stereotypes or reinforce existing biases in language use 

Plagiarism 

Since the release of ChatGPT in November 2022, there has been a growing concern about the use of ChatGPT to plagiarise. If a lecturer suspect that a student has plagiarised using ChatGPT, the first step is to talk to the student. All students have been introduced to the UFS plagiarism policy, and understand the consequences (failing grade on the assignment, a warning, or even suspension). Plagiarism is a serious offence and it is essential to deal with students who have plagiarised using ChatGPT in a fair and consistent manner. 

How to spot ChatGPT-generated text 

When setting up an assessment that requires critical thinking and extensive writing, it is advised that you run the question through ChatGPT to see what the general logic of the answer it gives is. Although all answers will differ in terms of the words used, the general logic will be similar and will enable you to more easily identify AI assisted text. There are also some online tools to help you identify AI-generated text, like OpenAI's AI Text Classifier, GPTZero and Writer AI Content Detector. 

Other ways to spot ChatGPT-generated text include: 

long, rambling sentences. 

overuse of generic words and phrases. 

lack of coherence or consistency. 

inconsistencies in grammar and spelling. 

Unnatural-sounding language. 

US written spelling when we use UK or SA English spelling. 

Face references. 

 

8. AUC’s Statement on the Use of Artificial Intelligence Tool 

 

AUC recognizes that artificial intelligence (AI) tools such as ChatGPT, Apprentice Bard, You.com and others, will play an increasing role in generating professional, creative and academic work. 

AUC’s Code of Academic Ethics is clear that students and community members must produce original work, cite their sources, and not seek an unfair advantage over others. With any emerging technology, appropriate use and best practices will take time to develop and the university will continue to share regular updates. We urge all members of the AUC community to clearly acknowledge the use of AI tools when such tools have been used. If a community member claims AI material as his/her own, he/she is plagiarizing that source and will be in violation of AUC academic integrity policies. 

For teaching and learning, a course instructor may, on occasion, authorize students to use AI tools in coursework. In such instances, the faculty member must alert the students, in writing, to the purpose of the work, and define the context in which AI may be used. The students are then accountable for adhering to the coursework guidelines and for fact-checking all information they use, and must ensure the authenticity of all citations and/or references. AI-generated text and references must be credited appropriately. 

For research, creativity, and/or scholarly outputs, AUC community members who intend to use AI tools must carefully check any guidelines emerging within their respective disciplines, or established by the academic journal, publishing house, or venue through which the work will be published and/or presented. 

Additionally, and until guidelines and best practices are developed and adopted, AUC community members must clearly acknowledge the use of AI tools when such tools have been used. Authors and/or creators, and not the AI tool(s), are accountable for their work, its originality, accuracy, and integrity. 

(See MLA guidelines) 

9. Guidelines for the Utilization of AI in Teaching and Learning at NWU 

 

Senate, at its second meeting of 2023, took note of developments concerning Artificial Intelligence and its impact on higher education generally, and teaching and learning in particular. While it was noted that faculties organised, or were in the process of organising, workshops and other forms of engagement as regards AI, Senate expressed a view that an institutional opportunity for engagement be organised through the Office of the Deputy Vice Chancellor Teaching & Learning and that a report be submitted through SCTL for the further attention of Senate on the phenomenon of, and suggested University responses to AI. The Centre for Teaching and Learning thus assisted the DVCs Office with a conceptualisation of a programme of panels and presentations, featuring also a pre-programme competition for any member of the University to develop an accessible and user-friendly podcast featuring a selected AI. Central to the themes explored in the course of the NWU Symposiumi , is the importance of the ethical consideration about intelligence that is not transparently accountable to its users, and scarcely accountable to its creatorsii. While this is not a new ethical challenge, it is an enduring human problem that takes the form of dilemmas to not only act principally in relation to knowledge, but also to know what principled and ethical action entails. 

Continuity and Change 

The quest for accessible knowledge configuration, AI, and the ethical dilemma of academic accountability 

 

Artificial intelligence is not new to this century. It is a further iteration of a human desire to make more efficient access to, as well as the configuration of existing knowledge as based on large natural language data-sets. Its artificiality lies not in AI creating ‘artificial’ knowledge, but rather in relation to its capacity to generate from across language data, intelligent responses to human questions, without human agency (even though, of course, the datasets are derived from very real human artifacts). The intelligence rests also in the capacity for responses to be generated and configurated in an automated manner, and in its latest configurations, AI is able to generate ‘new’ images and perhaps more problematically, ‘new’ knowledge. At present some of the literature of critique of AI points out how such new knowledge is revealed not to be reliable, valid or credible (that is, it has no verifiable basis when checked). In quick time it is anticipated that new versions of existing AI, and new AI, will rectify even those problems. The question is open still as to whether, ethically, AI should be enabled to become disembodied from its human agency foundation (in other words, machine learning) because this risks ethical disconnect, because there is increasing clarity globally on the ethical frameworks for research (involving humans, the environment and even texts) which AI needs either to demonstrate awareness of, or become sufficiently transparent as to be open to auditing of such. At present, World View is not made explicit in the reconfiguration of human know through AI, but we know it exists and, more importantly, we know it configures power relationships in particular ways. That noted, it is possible to insert a world view through prompts. While it is acknowledged that ChatGPT does not make its world view clear, world view can be influenced. The essay mills before they became part of ‘the internet things’, were notes generated and sold by students to each other and by teachers to students. Simply put, there is profit not be made through unethical means. Teachers and academics joined the fray and so EssayHub, EduBirdie, and PapersOWl came into being, giving rise in turn, to the need for both prognosis and ‘cures’. The prognosis took the form of a focus on the development of academic integrity scholarship, in which the problematic nature of plagiarism, wrongful text usage and nonacknowledgement of sources were made clear, whilst online ‘cures’ took the form, amongst others, of software packages like Turnitin, Plagiarism Check, and CopyLeaks. The continuities noted, the capacity to generate independently of agency, data, which can be configured as recognisable knowledge, responsive to our human questions, in ways that seem to be conversation-friendly, allows for ChatGPT, Bard, and Vicuna to have captured the imagination in ways that essay mills could not: cheap, personalised access to expertise, and expert knowledge configured automatically to respond to the bespoke needs of the student and the teacher alike 

Higher Education  

Selected affordances and risks associated with the AI value-proposition 

The literature on the affordances of AI is wide. It is also linked to the perceived detrimental effects of the internet at large, on the development of critical thinking and critical search, synthesis and other skills. This literature was referenced in several presentations associated with the Symposium and is also reference in the summary.  

Selected affordances linked to the responsible use of AI  

What does AI enable in terms of access and success? The Symposium featured the following inputs as described in the sections below. Expertise has always traditionally been ‘scarce and expensive’, but AI is developing to such an extent that everyone will have access to expertise cheaply (without having to be a graduate, or professional, or having been trained for years in a field). Another challenge is that AI will enable one to filter discourses, news and other sources in terms of your preferences leading to bubbles: confirmation bias and affirmation bias is already a feature of human thinking and there is no reason to expect it will not also become a powerful feature of AI - not unless ethical attributes are built-in like: scepticism about findings, awareness of biases and self-reflection (McCabe & Dzogang, 2023). Websites, and sources that can be access through websites, are transparent mostly in terms of traceability: there is detail sufficient to trace sources sufficient for a reade4r/ viewer to assess bias in a number of different ways. LLMs present information without the underlying factuality being evident. For example, in a machine learning assignment a previous approach would be to give students a dataset, instruct them to use a machine learning technique, and report on their results. This approach would lead to the student very easily finding the answer using an AI. Instead, the assignment should be changed to introduce students to the kinds of problems that can be solved by collecting datasets, the machine learning workflow, and the tools that can be used to report results. The student then uses this knowledge to find a dataset and problem they are interested in, finds techniques through exploration that could be useful, actions the work, and then conveys their results as well as reflections back to the lecturer in a way that focusses on what was learned and experienced. One of the affordances of AI, is that it is able to personalise the learning journey (it considers, pace, level of interest success of student's response, responsiveness and thus can guide students in their learning). The downside is that dependence on AI discourages independent thinking, or the skills development associated with independent thinking. In short, the risk of undue dependence, is that it diminishes confidence in one’s own capacity to learn and display critical skills and by so doing, may actually inhibit learning. Another affordance concerns the capacity of AI to absorb indigenous languages datasets. At present, the availability of AI in African languages is scarce at present, but this not to suggest there will not be change in the very near futureiii. The more languages are shared on AI platforms, the more sophisticated the capacity becomes, in any language, and so what is anticipated is a fair(er) balance between participation in AI generation between the Global North and the Global South. AI also affords valuable assistance to students that is enabling of learning. From the student panel at the Symposium, an important perceptual difference was noted: Artificial Intelligence should be seen as Assistive Intelligence: it can provide a deeper engagement than what is offered in a classroom situation where the teacher has to adopt a one-size fits all approach. Thus, not only is depth enabled, but also saves time: time taken to find sources and time to digest. AI attends to grammar issues (particularly important to second language speakers); structure issues and quality issues leading to better marks. This is potentially transformative because it provides the student with an almost instant means to achieve fluency and in a world where fluency in English is popularly perceived as linked to intelligence. The capacity of AI to simplify information makes it more understandable and it is experienced as a means of obtaining access, and assisting towards success. Automated feedback (on plagiarism) and grading is personal, and it takes less time to get feedback. AI has given rise to new pedagogic forms like Prompt Engineering (define the role for the AI, define the content or the audience, provide enough information, break-up complex sentences) (Ng, 2023). AI is not simply useful for derivative material (ie looking for source material or collate insights from source material), but also useful for creativity: where entirely new knowledge or new imagery is generated. This is evident, for example, when it emerges that AI can provide the semblance of authenticity, and turn out yet to be false (what is referred to as an instance of ‘hallucination’). Another area of illumination is student co-creation of assignments: in these assignments, the search for problems of a certain type, is accompanied by a requirement to reflect by the students, on the types and varieties of solutions (previously, the problem was provided by the academic; now students have to find a problem and engage with it, with the lecturer). For example, in a machine learning assignment a previous approach would be to give students a dataset, instruct them to use a machine learning technique, and report on their results. This approach would lead to the student very easily finding the answer using an AI. Instead, the assignment should be changed to introduce students to the kinds of problems that can be solved by collecting datasets, the machine learning workflow, and the tools that can be used to report results. The student then uses this knowledge to find a dataset and problem they are interested in, finds techniques through exploration that could be useful, actions the work, and then conveys their results as well as reflections back to the lecturer in a way that focusses on what was learned and experienced. With AI, academics can also set up simulations that would take a month to set up normally, but using the AI takes little time. The tools are available, but the University teacher needs exposure to the tools to use them effectively. It is perhaps necessary to educate on and authorise the use of the tools through the CTL in collaboration with the School for Computer Science and Information Systems. Future collaboration should also include the Faculty of 

Engineering’s MuST with a focus on deep learning. In this regard a community of practice (CoP) should be brought into being to support awareness of and sharing of skills associated with different forms of AI. A critical issue is making sure that the expectations in assessments/ assignments meet the levels of the associated module outcomes. This leads to a fundamental reassessment of assessment: do we need it? Perhaps we need more than assessments, the students' evidence of the learning. The use of AI for authentic assessment is possible: AI is only one form of technology use- and so a community of practice would serve this additional purpose, under the auspices of the NWU Centre for Teaching and Learning, in which collaboration and cooperation is key (portfolio, project and collaborative and cooperative learning experience). On another and related note, service learning and community engagement can also benefit from the uses of AI. Given that through the uses of prompts and questions, AI is becoming more useful in relation to community issues (for example health advice), for the uses of AI for SL, WIL and CE. The holistic application of AI across all areas of University work (not only teaching and learning or the broader administration) is thus relevant not only to staff, but also students in relation to CE, SL, WIL opportunities. 

Selected perceived risks associated with AI 

On the down-side, accuracy of AI generated information (i.e. accuracy, credibility and bias) has still to be better developed. Cautions and critiques of AI are well-documented. For example, the Future of Life Institute (2023) Open Letter is much sited: "AI research and development should be refocused on making today's powerful, state-of-the-art systems more accurate, safe, interpretable, transparent, robust, aligned, trustworthy, and loyal", while the Centre for AI Safety stated that “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war" (2023). There remains a need, however, for social interaction with the academic and students, relationship building and learning (counsellor, guide, friend). What is evident is that AI is part of what it means to learn online: its usefulness as part of pedagogy is thus clear as part of (not apart from) the development of critical thinking skills. The other problem is that of the bubble: algorithms channel, based on their analysis of interests, language, preferences, the further channelling of information that feeds these same or similar interests, preferences and beliefs. The abuse of these technologies (and the techniques of surveillance underpinning them) has long been known and is well-documented. That noted, it should be recognised that large language models (LLM) will lean to a ‘global’, rather than heavily contextual perspective. Topics that are discussed thus globally, surface most, unsurprisingly. Local knowledge (inclusive of indigenous knowledge) becomes more prominent, the more it becomes used through AI. In light of this, it is important to show students how to access indigenous or localised knowledge, and in this latter regard, context becomes critical. The educational and social risk as regards algorithm-based information channelling is not only the risk of bias and prejudice, but also the risk of anti-social behaviour that does not accord with the need for collaboration and cooperation with like as well as other, to mutual and ethical benefit: aloneness, loneliness and the 'bubble'. Simply put, learning to engage might be enhanced through practice with a chat-bot, but a chat bot is not the future of a species in which, scarcity of resources and mutual need, compels us to learn better those skills of collaboration and cooperation, and complex interdisciplinary problem-solving that requires more than knowledge memorisation, and individual test performance scores, to demonstrate readiness for work, and for survival. 

An emerging NWU perspective on AI and the Curriculum  

Rather than exclude AI from the ambit of education experience (which is surely the experience necessary for survival, let alone ‘workplace readiness’ in the 21st Century), AI needs to feature as part of teaching and learning (seen as assistant rather than an aberration): Educational approaches should teach the ability to identify AI, explore variants, use AI, acknowledge AI, and reward the responsible use of AI, but also correct incorrect or unethical use. The approach adopted by NWU is thus not an ‘uncritical embrace’. 

All of the above suggests that it is imperative to integrate the guided and responsible use of AI as part of the curriculum, recognising that it can play a role in realising the transformation of teaching and learning at NWU: most obviously there is an opportunity to develop 21st Century skills (see the NWU TL Strategy). It is important to signal awareness of examples of some institutions having 

‘banned’ AI (University of Oxford: 2023), whilst others (for example, the University of Johannesburg: 2023) have signalled the special place of AI by making it part of a compulsory course for all University students. Treating AI as a single practice beyond the context of academic integrity risks a loss of opportunity to exemplify best practice about how it can be used, and how and when, it should not be used. The teaching and learning industry (much of which is driven by for-profit organisations) has seen a blossoming and prominence accorded to proctoring and regulation of online assessment. These forms of assurance veer closely to surveillance and cannot become the focus of the higher education assessment experience associated with AI. Assessment should focus less on the outputs and more on the journey to obtain or display the outputs. Students should be asked to show how they use AI. How to assess evident of good AI use should be exemplified, and celebrated by the University, it should be linked to a strong ethical centre and it should be linked explicitly to the NWU graduate attributes and values. 

Academic Integrity and accountability for the uses of AI 

The ‘cure’ for the ethical problem of accountability, does not lie in regulation, but an ethically informed perspective on demonstration of accountability, requires that guidance be provided, by the institution, such that instances of right and wrong practice be identified and recognised appropriately: in other words, that heart needed by the Tin Woodman. Dishonesty is not new in academic life. The use of AI if such occurs without guidance and without accountability, then becomes a form of academic dishonesty. Aside from implications for Academic Integrity, there are many implications in terms of AI in the classroom (as part of the pedagogy associated with the 2021 NWU Policy on Academic Integrity and the 2023 SOP on Academic Integrity). AI allows for the introduction of new knowledge and this open flexibility in the curriculum, should be encouraged. From a teaching point of view, AI also contributes to an assistant role for academics, making it easier to generate quizzes and texts, but the downside is that if AI is used by academics and also by students, what will anyone learn, whether as academic or as student? What risks diminishment is creativity, reading and writing at a time when the NWU needs to be reflecting on changing the curriculum (as exemplified by the NWU PQM project) with implications for how we teach and assess so as to exemplify creativity, collaborative and cooperative learning in which reading and writing are only two of a larger skills-set. What emerges in the discussion is a concern about authenticity of the source, the user, (and possibly also, the assessment done by AI on behalf of an academic). In summary: it is essential for the University to have guidelines for the uses of AI in the curriculum and the activities associated with it (assessment, research and engagement). 

NWU Guidelines as regards the place of AI in the Curriculum and NWU Values 

Integrity is a key value embedded in the Curriculum as well as Values of the NWU. NWU considers AI not only as a form of elaborate search engine, but is also potentially a source of new knowledge. Admittedly, the challenge with LLMs is that no single response is exactly the same, because much depends on the preferences, the nuances and the profile of the person/s asking the question. In light of the above, the importance of standardised guidelines, specific to the needs to the discipline, or entity or administrative unit, needs to be made explicit. 1) Academics have a responsibility to train students to use AI appropriately, responsibility and frequently enough, within their disciplines and within the guidelines provided by the University. 1.1) Part of that responsibility is to be able to illustrate awareness of the limitations of AI. What is evident is that the human agent cannot be removed from the technology at the present time. Research still has to be undertaken by humans, and thought has still to be expressed by humans as part of development and growth. 2) The University’s regulation of AI (in terms of how, for example, Bard, ChatGPT and others are used/ should be used) is sufficiently flexible to allow for a changing recognition of implications (rather than an uncritical embrace, or equally uncritical ban, of AI in the teaching learning and research environment) to ensure that the gap between the guidance and application is not too wide. 3) The University has a responsibility to make awareness of the forms as well as the uses of AI, part of the University’s staff development programmes. 3.1) While it might be safe to assume some students will have a nuanced appreciation of the technology, not all academics and students will know enough and will have different access to knowledge about AI: a platform to share among students and staff is necessary, and an educational offering for staff is necessary.3.2) Academic units (Subject Groups, Schools, research entities) should provide a well-articulated stance on the uses of AI suited to the needs of the discipline and/ or the nature of research such that students and staff are guided in expectations. 4) The relationship between academic integrity practice as well as values, needs to be close to an explicit understanding of the forms and uses of AI. This proximity needs to feature in the declarations made by students in relation to their work submitted for assessment such that AI assistance is acknowledged. 4.1) Students who use AI need not only to declare such usage, but also to provide in-text referencing of online sources (an example of which is provided here). While the use of artificial intelligence (AI), particularly large language models (LLMs) like ChatGPT, is often integral to modern research and development, it's important to note that direct in-text citations of these tools are not possible. This is primarily because the generated information is inherently instance and context-specific, being dynamically formulated in response to each unique prompt. Consequently, to appropriately acknowledge and reference the use of such software, it is recommended to use the following citation formats: APA referencing formula: Format: Author. (Year). Title of software or model (Version date if known) [Format]. 

URL. In this format: • "Author" refers to the organization or individual that developed the software or model. • "Year" refers to the year the software or model was published or updated. • "Title of software or model" is the official name of the software or model. • "Version date if known" refers to the version of the software or model, if applicable. • "Format" is the description of the type of model as provided by the publishers. • "URL" is the web address where the software or model can be accessed. For example: For ChatGPT: OpenAI. (2023). ChatGPT (Mar 14 version) [Large language model]. https://chat.openai.com/chat. For DALL-E: OpenAI. (2023). DALL-E [AI image generator]. https://labs.openai.com Harvard referencing formula: Format: Author(s). (Year) 'Title of software or model [Type of Model]'. Available at: URL (Accessed: Day Month Year). In this format: • "Author(s)" refers to the organization or individual that developed the software or model. • "Year" refers to the year the software or model was published or updated. • "Title of software or model" is the official name of the software or model. • "Type of Model" refers to a brief description of the type of software or model. • "URL" is the web address where the software or model can be accessed. • "Accessed: Day Month Year" is the date when the software or model was last accessed by the person citing the source. For example: For ChatGPT: OpenAI. (2023) 'ChatGPT (Mar 14 version) [Large language model]'. Available at: https://chat.openai.com/chat (Accessed: 12 June 2023). For DALL-E: OpenAI. (2023) 'DALL-E [AI image generator]'. Available at: https://labs.openai.com (Accessed: 12 June 2023). 5) Flexible decision making, broad sharing and support for AI awareness and use, should be a necessary feature of management engagement as well as classroom engagement, in the context of the University’s emphasis on the development and infusion of academic integrity practice.  

10. Generative AI guidelines at South African universities 

 

The university guidelines and policies cover teaching, learning and research. Most universities provide separate guidelines for staff and students, and usually include a list of use cases and as well as some cautions about risks. 

This is the University of the Witwatersrand's guide for teaching and learning, and another for North West University. The University of Cape Town Staff Guide on Developing effective prompts for generative AI tools includes various Prompt Pattern Strategies, whether the pattern is based on Role Playing, Question Refinement, Flipped Interaction or others: 

 

 

The University of Pretoria advice for students outlines some general principles for responsible use (e.g. Ensuring Data Privacy and Confidentiality), and then provides specific instructions (e.g. to deactivate model training and the storing of chat history in ChatGPT): 

 

Most guidelines for students refer them to existing university policies, such as on plagiarism, which already provide the framework for how generative AI may be used. The University of Johannesburg (UJ) guidance for students encourages them to be Responsible, Informed, Transparent and Ethical (RITE): 

 

For research, universities may develop specific policies or guidelines, similar to the University of Cape Town Senate Ethics in Research Committee (EiRC) Guidelines and recommendations for the use of generative artificial intelligence (AI) tools in research. It refers extensively to established values and existing documents, such as the Policy for Responsible Conduct of Research and the Authorship Practices Policy. And is supported by a Student Guide on the Ethical use of generative AI for research purposes. This guide includes an outline of use cases for generative AI according to the stage of research, along with concerns that may need to be addressed. 

 

Publishers associated with universities as well as local journals have also implemented their own policies. This is the Generative Artificial Intelligence Policy of the South African Orthopaedic Journal. The University of Johannesburg (UJ) Press has introduced an Artificial Intelligence and Generative AI Policy. 

In the wider region, the Southern African Regional Universities Association (SARUA) has issued a statement on ChatGPT and other AI tools. Globally, it is worthwhile looking at the OECD's study on the Emerging governance of generative AI in education, as well as the UNESCO Guidance for generative AI in education and research.