39. International AI Cooperation and Governance Forum 2022 

 

International AI Cooperation and Governance Forum 2022 

Theme: AI Governance and International Cooperation for a Resilient Future Date: December 9th - 10th, 2022 

 

Form: Online 

 

Host: Tsinghua University 

 

Organizer: Institute for AI International Governance of Tsinghua University (I-AIIG) 

 

Supporting Partners: 

 

United Nations Development Programme 

 

United Nations Educational, Scientific and Cultural Organization 

 

UN Women 

 

International Labour Organization 

 

Institute for Ethics in Artificial Intelligence, Technical University of Munich 

 

Center for Humanitarian Dialogue; 

 

International Research Center for AI Ethics and Governance, Institute of Automation, Chinese Academy of Sciences 

 

The Chinese Institute of New Generation Artificial Intelligence Development Strategies 

 

China Academy of Industrial Internet 

 

Institute of Artificial Intelligence, Tsinghua University 

 

Institute for AI Industry Research, Tsinghua University 

 

Center for International Security and Strategy, Tsinghua University 

 

Center for AI Governance (Beijing) 

 

China Institute for Science and Technology Policy, Tsinghua University 

 

Center for Science & Technology Development and Governance, Tsinghua University 

 

Tsinghua University Latin America Center 

 

Tsinghua Southeast Asia Center 

 

SPARK UNDP SDG Innovation Lab | Chengdu 

 

National Communication Center for Science and Technology, CAST 

 

Background and Objective 

In recent years, artificial intelligence (AI) represented by super large-scale pre-training model grows by leaps and bounds with more resources of data and computing power, injecting intelligent impetus to research in life science, mathematics, space science among other fields. Meanwhile, expanded application scenarios also nourish the development of AI, driving traditional industries to go intelligent. In particular, against the urgent needs for global economic recovery in the postpandemic era, AI plays a more prominent role in empowering scientific research and innovation and industrial development, and underpins improvement of capacity of risk prediction, crisis response and recovery, adding to the resilience of the social and economic development. 

However, as AI technologies are more deeply embedded in economic and social life, transforming our means of production and lifestyle, it also elicits more prominent challenges in security, privacy and equity. Over the past year, governments, international organizations and industrial communities have rolled out a series of norms and regulations, policies and standards of AI governance, making AI governance one of the most important agendas in global governance. 

 

At the just-concluded 17th G20 Leaders’ Summit, China’s President Xi Jinping proposed an initiative aimed at making global development more resilient. The Global Development Initiative that China proposed is an innovation-driven approach. The historic opportunity of recent revolutions in science and technology, and industrial changes should be seized to accelerate the transformation of these technological achievements to productivity. It is important to foster an open, fair, just, and non-discriminatory environment for science and technology development. At the same time, cultivate new momentum for economic growth to pursue leapfrog development together. 

China has recently formally submitted its Position Paper on Strengthening Ethical Governance of Artificial Intelligence (AI) to a meeting of the States Parties to the UN Convention on Certain Conventional Weapons. Based on the implementation of the policies on technology ethics in China and useful international experience, the Paper highlighted the priority of ethics in AI governance, and proposed systematic recommendations for strengthening the ethical governance of AI, with emphasis on promoting the establishment of an international framework and standards for AI governance based on broad consensus through international exchange and collaboration. 

In this context, the International AI Cooperation and Governance Forum 2022 will be convened under the theme of “AI Governance and International Cooperation for a Resilient Future”. Focusing on regulation, R&D, utilization and international cooperation of AI, it explores the establishment of a governance system appropriate for the sound development of AI; development of governance technologies and tools to guarantee responsible use of AI; and the best practices in AI governance of the political, industrial, academic and research communities in different countries and regions. The forum aims to promote AI to provide new momentum for and unleash potential of scientific innovation and industrial development, so as to make global growth more inclusive, resilient and sustainable for the common well-being of humanity, and for a community with a shared future for mankind. 

 

40. Responsible Use of AI – Guidance from a Singapore Regulatory Perspective 

 

Responsible Use of AI – Guidance from a Singapore Regulatory Perspective 

I.   Introduction 

Artificial intelligence ("AI") is no longer a mere concept of the future. Recent developments in AI technology have opened the doors to a wide range of practical use cases. This has been swiftly adopted by the commercial world across a variety of business functions, with the accelerating uptake rate indicating that AI systems are set to become ever more prevalent in our daily lives. As with any newly adopted technology, AI brings with it certain issues and concerns, which are further exacerbated by a general lack of familiarity. These risks have been brought to the forefront in light of the recent popularity of AI solutions, including issues of ethics, mistakes and hallucinations, privacy and confidentiality, disinformation and cyber-threats, and intellectual property. 

A common theme across AI adoption is the responsible use of AI – how should AI solutions be implemented, what forms of testing are available for AI systems, and what are the best practices when using AI? In the absence of established standards and practices, businesses have been looking to industry regulators for guidance. 

In this regard, Singapore regulators have demonstrated their awareness of and proficiency with AI and its related risks. In recent months, Singapore regulators have provided guidance on the responsible use of AI for businesses in various industries. These assist businesses utilising AI tools or seeking to implement such tools, and provide an indication of how AI regulations may be structured when established. 

In this article, we take a look at some of these initiatives in the Singapore context: 

The launch of the AI Verify Foundation, which aims to develop the AI Verify testing tool for the responsible use of AI; 

The public consultation on the Proposed Advisory Guidelines on Use of Personal Data in AI 

Recommendation and Decision Systems; and 

The Veritas Toolkit version 2.0 for the responsible use of AI in the financial sector developed by the Monetary Authority of Singapore ("MAS"). 

II.   AI Verify 

On 7 June 2023, the Infocomm Media Development Authority ("IMDA") announced the launch of the AI Verify Foundation ("Foundation"), which has the aim of harnessing the collective contributions of the global open-source community to develop the AI Verify testing tool for the responsible use of AI. The Foundation will look to boost AI testing capabilities and assurance to meet the needs of companies and regulators globally. 

The Foundation will: 

Foster a community to contribute to the use and development of AI testing frameworks, code base, standards, and best practices; 

Create a neutral platform for open collaboration and idea-sharing on testing and governing AI; and Nurture a network of advocates for AI and drive broad adoption of AI testing through education and outreach. 

AI Verify provides organisations with an AI Governance Testing Framework and Toolkit to help validate the performance of their AI systems. Furthermore, AI Verify is extensible so that additional toolkits, such as sector-specific governance frameworks, can be built on top of it. 

AI Verify is a single integrated software toolkit that operates within the user organisation's enterprise environment, facilitating the conduct of technical tests on the user's AI models and the recording of process checks. AI Verify's testing processes comprise technical tests on three principles: fairness, explainability, and robustness. Process checks are applied to the identified principles. In recognition of global compliance requirements, the testing framework is consistent with internationally recognised AI governance principles, such as those from the EU, OECD and Singapore. 

The development of AI Verify and the launch of the Foundation indicate the Government's recognition of the importance of tools that are able to adequately test the performance of AI systems. Organisations using AI in their businesses require more reliable and standardised test systems, which will then allow them to make provisions for protection from the resulting risks. 

 

III.   Advisory Guidelines  

The Personal Data Protection Commission ("PDPC") has launched a public consultation ("Consultation") seeking views on the Proposed Advisory Guidelines on Use of Personal Data in AI Recommendation and Decision Systems ("Guidelines"). The Consultation has ended on 31 August 2023. 

The aim of these Guidelines is to: 

Clarify how the Personal Data Protection Act ("PDPA") applies to the collection and use of personal data by organisations to develop and deploy systems that embed machine learning models ("AI Systems") which are used to make decisions autonomously or to assist a human decisionmaker through recommendations and predictions; and 

Provide baseline guidance and best practices for organisations on how to be transparent about whether and how their AI Systems use personal data to make recommendations, predictions, or decisions. 

The use of personal data in AI Systems raises important issues of privacy and confidentiality. Personal data may be used in the training of various AI Systems, including AI recommendation and decision systems in e-commerce to recommend and personalise products or content to users, and AI tools to predict product demand. While such data may be essential to the training process, organisations must be aware of how it interacts with their data protection obligations under the PDPA. The breach of such obligations may lead to the imposition of potentially onerous penalties and fines, as well as reputational damage. The Guidelines will thus be a vital source of guidance in this regard. 

 

IV.   Responsible use of AI in the financial sector 

 

On 26 June 2023, MAS announced the release of the Veritas Toolkit version 2.0, an open-source toolkit to enable the responsible use of AI in the financial industry, by helping financial institutions ("FIs") carry out the assessment methodologies for the Fairness, Ethics, Accountability and Transparency ("FEAT") principles. This is part of the MAS’ Veritas Initiative which was first announced in November 2019. The Veritas Toolkit version 2.0 builds on the earlier Veritas Toolkit version 1.0 which had been released in February 2022 that focused on the assessment methodology for fairness. The Veritas Toolkit version 2.0 features an improved fairness assessment methodology and new assessment methodologies for ethics, accountability and transparency. The FEAT principles provide guidance to firms offering financial products and services on the responsible use of AI and data analytics. The Veritas Toolkit is the first responsible AI toolkit developed specifically for the financial industry. 

In addition, the consortium behind the development of the Veritas Toolkit has published a white paper setting out the key lessons learnt by seven FIs which piloted the integration of Veritas methodology with their internal governance framework, including the importance of: 

a consistent and robust responsible AI framework that spans geographies; a risk-based approach to determine the governance required for the AI use cases; responsible AI practices and training for the new generation of AI professionals in the financial sector. 

The MAS also announced additional use cases which the consortium had developed to demonstrate how the toolkit could be applied, including the application of transparency assessment methodology to predictive AI-based policy underwriting for insurers as well as application of the FEAT assessment methodology to fraudulent payment detection systems. 

MAS has stated that the consortium will focus on training in the area of responsible AI and facilitate the adoption of the Veritas Methodologies and Toolkit by more FIs. 

In line with MAS' focus on responsible use of AI, on 31 May 2023, MAS and Google Cloud signed a Memorandum of Understanding ("MoU") to collaborate on generative AI solutions grounded on responsible AI practices. The MoU provides a framework for cooperation in technology and industry best practices in three areas: 

 

Identifying potential use cases, conducting technical pilots, and co-creating solutionsin responsible generative AI for MAS' internal and industry-facing digital services; 

Cooperating on responsible generative AI technology application development and test-bedding of AI products for business functions and operations; and 

Supporting the technical competency development on responsible generative AI and deep AI skillsets for MAS technologists. 

V.   Concluding Remarks 

Singapore regulators such as IMDA, PDPC and MAS have demonstrated themselves to be deeply involved in issues of AI deployment and development and how they apply to their respective industries. This can be seen by their efforts at developing toolkits and guidance papers for organisations and businesses on the responsible use of AI. 

Currently, it remains to be seen whether specific AI legislation or regulations will be developed to impose binding obligations on AI users. In the meantime, the guidance offered by the regulators in the initiatives highlighted above may provide a shape of things to come. 

41. Regarding the Use of Generative AI 

 

Regarding the Use of Generative AI 

To All Students, 

  

Generative AI such as ChatGPT has been developing rapidly in recent years, and the use of generative AI, such as those that generate language, and even images and voice, is expanding throughout all of society. Nagoya University's views on generative AI are described in "The Use of Generative Artificial Intelligence Technology (Generative AI) in Education and Research". 

However, we ask all students to pay special attention to the following. 

 

Please think about the effects and negative aspects that the use of such AI may have on your own learning, and deal with generative AI with the sincere intention of deepening your own learning. 

Please follow the guidance of your instructors regarding the use of generative AI in classes. 

 

						Please 	remember 	the 	following 	points. 

There is a possibility that information provided by generative AI may contain errors, and the use of such misinformation may result in disadvantages for the user. Therefore, it is necessary for you to examine the accuracy of the provided information yourself. 

 

Even if the provided information is correct, it may cause copyright infringement or plagiarism issues. Therefore, information provided by AI should only be used as a reference for your writing. Please do not use the provided information as is, even only partially. Penalties may be imposed in such cases. 

 

Information entered as questions when using generative AI has a risk of being leaked, so you must not enter information that should be kept confidential, such as personal information. 

42. Guidelines for Instructors Regarding AI in University Education  

 

Background  

ChatGPT, an AI (artificial intelligence) text generation system developed by OpenAI, was released in November 2022. It can answer questions in fluent natural language based on a vast amount of learning data, and can also create summaries and outlines in addition to generating text. It is widely accessible on the web and can be used in a conversational format, leading to explosive growth in its usage and having a significant impact on university education. This “Guideline” aims to provide a broad guideline for the use of AI in educational settings at this university, taking into account machine translation tools such as DeepL as well as text generation AI such as Bing Chat, with a focus on ChatGPT and similar text generation AI. Please note that the contents of this “Guideline” reflect the current situation, taking into consideration that ChatGPT is still under development and various services that incorporate ChatGPT or other conversational text generation AI (such as Bing Chat) have been released. It is also important to note that this “Guideline” is not intended to provide guidance for academic evaluation purposes. 

How AI Generates Text AI text generators work based on large language models (LLM)  

LLMs are trained on a massive amount of natural language text using deep learning, which predicts the most likely words to follow a given sequence of words as input. This input is called a prompt, and if a partial sentence is input as a prompt, the AI can complete the sentence by predicting the most likely words to follow. It is also possible to input a question asking for an explanation of something, and the AI can output a highly probable sentence that answers the question. However, even with the same question, the output answer may differ due to subtle differences in the prompt, such as the position of a comma. It is also known that the accuracy of the answer can vary depending on the prompt, and prompt engineering, which is a method for obtaining highly accurate answers, is attracting attention. However, the text generated by AI is based on the results of machine learning from given language data, so it is not necessarily accurate all the time. It has also been pointed out that undesirable expressions may be included in the output. Therefore, in new AI systems, machine learning (reinforcement learning based on human feedback) has been introduced to encourage the selection of more desirable responses. Based on human evaluation according to the 3H criteria (helpful, honest, harmless), the multiple candidate responses that the system is attempting to output are ranked in the order of desirability. With these improvements, the overall accuracy of text generation AI is improving every day, but since it is not necessarily possible to obtain complete answers or avoid mistakes, users need to be mindful of appropriate use. 

Limitations of AI Text Generation  

There are several limitations to AI text generation that are known: 

1) AI may provide incorrect answers, even if they are different from the facts. It is always necessary to check the accuracy of the information by returning to reliable sources when considering AI responses. Additionally, AI may have difficulty in certain fields, such as providing inaccurate answers to mathematical problems. 2) AI responses may contain potential biases or errors. Since AI is trained based on data found on the internet, there is a possibility that biases and errors found on the internet may be inherited by AI responses. Additionally, the unconscious biases of evaluators may also affect AI responses during the reinforcement learning process. 3) In the case of ChatGPT, its knowledge is based on data learned from the internet up until September 2021, and it cannot answer questions about events that have occurred since then. However, Bing Chat is connected to the internet and therefore, can provide answers about the latest events. 4) ChatGPT cannot display the sources used for its responses, whereas Bing Chat can display the internet sources used for its responses. 

Guidelines for the use of AI in university education  

AI is undoubtedly a powerful tool for assisting students in writing, despite its limitations mentioned above. ChatGPT (or various other AIs that may emerge in the future) seems to have become a tool that students will be expected to master when they enter society. Therefore, in universities, it is necessary to educate students on appropriate usage and ways of thinking in the context of learning, rather than limiting their use. It is important to provide a balance between the philosophy and practice of educating students on the appropriate and effective use of AI while ensuring that AI use does not deviate from the primary purpose of university education, and that it helps to enhance students’ critical thinking skills. As for the use of AI in individual classes, the instructor should be allowed to determine whether to prohibit, restrict or actively utilize it, depending on the characteristics of the course. However, regardless of how it is used, the following points should be considered when implementing AI in the classroom:  Understanding of AI: Instructors must have a basic understanding of AI. If they have not yet tried using AI, they should try it immediately. Especially when it comes to assignments that are planned to be presented in class, it is desirable to confirm in advance what kind of answer AI will provide.  Shared understanding with students: At the beginning of the semester, instructors should explain to students their own thoughts on the use of AI in the class and engage in ongoing discussions with them on how AI can be involved as a rule in achieving the purpose of the course and its process.  Clear rules: At the same time, instructors should establish clear rules for the use of AI in the course for their students. In particular, when presenting assignments during the semester, it is recommended to reconfirm the rules with the students.  Fairness of rules: When establishing rules for the use of AI in class, please be aware of ensuring fairness among students. Some students may not be good at using computers while for other students it may be indispensable to use them (due to disabilities, for example). Please give sufficient consideration to the characteristics of each student.  Ethical use of AI detection services: There are services that can detect whether an article was generated by AI or not, but please be aware that there are cases of false positives (misidentifying articles written by humans as AI-generated articles) and false negatives (misidentifying AI-generated articles as human-written articles). Therefore, it is not recommended to fully rely on the results of these services.  Use of AI and personal information:When using AI for questions and assignments, instructors should take measures to ensure that students' personal information is protected. It is important not to ask questions that include personal information because information included in questions addressed to AI will be incorporated in the AI database and may be used later to answer questions by a third party 

Resources for Understanding and Using Article Generation AI   

The website of OpenAI that developed ChatGPT. You can register here to use ChatGPT. https://openai.com/  Bing Chat, a search engine incorporating ChatGPT provided by Microsoft. To use this service, you need to register using Microsoft’s browser, Edge. https://www.bing.com/  “ChatGPT: AI 

Education-related Information Summary” by Professor Rui Yoshida of the University of Tokyo, which summarizes the latest education-related information in Japanese. https://edulab.t.u-tokyo.ac.jp/chatgpt-airesources/ In particular, Professor Yoshida’s video “Let’s talk about using ChatGPT in education” is a useful reference for educators considering using ChatGPT in the classroom. https://edulab.t.utokyo.ac.jp/2023-02-11-report-event-chatgpt/  “The Evolution of AI and Japan’s Strategy” by Professor Yutaka Matsuo of the University of Tokyo, provides a concise summary of the history of AI development leading up to ChatGPT and how AI works. https://note.com/api/v2/attachments/download/a29a2e6b5b35b75baf42a8025d68c175 

43. Use of Artificial Intelligence Tools in Teaching, Learning and Assessments 

  

Artificial intelligence (AI) is sweeping the globe, and generative AI in particular has been hotly discussed because of its potential to revolutionize the way we teach and learn. The University believes that it is crucial for teachers and students to embrace and become acquainted with AI in order to optimize its potential in education. Students should learn to make sensible use of AI tools, not only for their studies, but also for their future professional development and advancement in order to thrive in this AI era. Like any other educational resources, teachers and students should approach AI tools critically, recognising their limitations in an honest and authentic manner and how these tools could be incorporated into teaching and learning in order to attain the desired learning outcomes. To optimize the use of AI in education, the University has prepared for teachers the “Guidelines on the Use of Artificial Intelligence Tools in Teaching, Learning and Assessments” (Guidelines) to i) set out how the University may integrate AI tools in its teaching and learning while upholding academic honesty, integrity and quality; ii) recommend some possible approaches in adopting AI tools in teaching and learning; iii) make it clear and explicit that improper/unauthorized use of AI tools in assignments/assessments constitute acts of academic dishonesty which will be handled in accordance with the University’s existing guidelines and procedures; and iv) provide some readily available references and resources for supporting the adoption of AI tools in teaching and learning.   

Students should take note of the following salient points extracted from the Guidelines and follow strictly the instruction and/or permission given in the course outline by the teachers regarding the use of AI tools in teaching, learning and assessments. The Guidelines will be reviewed and updated as needed to reflect changes in technology, best practices, and other relevant developments.  

There are different types of AI tools, for instance generative AI tools (e.g. Chat GPT) which can be easily instructed using ordinary human language to generate various formats of texts. Some AI tools facilitate the creation of ‘original’ artwork (e.g. DALL·E 2), translated text (e.g. Google Translate), formulas (e.g. Sheet+), and computer code (e.g. OpenAI Codex), etc. applicable to a great variety of use. While teachers and students are encouraged to explore and take advantage of the benefits of adopting appropriate AI tools to enhance their teaching and learning activities, decisions on which AI tools to adopt and how to use them in teaching and learning should be made cautiously and thoroughly.  

The availability and accessibility of AI tools to students will be carefully evaluated before adopting AI tools into any teaching and learning activities. AI is a double-edged sword; we should use but not abuse it, use it as a research but not cheating tool, and most importantly, use AI to think with you, but not for you. 

Where applicable and permitted, approaches to the use of AI tools in different disciplines will be worked out taking into consideration the needs of different disciplines, their pedagogical approaches and assessment means. When adopting AI tools in teaching and learning, teachers and students should be cautious of their accuracy and reliability and bear the responsibility of using the educational resources and references obtained through these tools. 

As a general principle,students are prohibited from using any AI tools to complete their assignments, assessments and any other works that count towards their final grade of the course or attainment of the desired learning outcomes, unless explicitly permitted 

Depending on the learning outcomes, pedagogical design, and assessment scheme of different courses, the following are some possible approaches to adopt AI tools in teaching and learning. Relevant details will be spelt out clearly in the course outline and/or the instruction of the assignments. Students shall follow the instruction and permission strictly and seek clarification from the course teacher if in doubt. Students are also expected to understand the limits and appropriate uses of these tools. 

i. Approach 1 (by default) - Prohibit all use of AI tools In assessing the level of achievement of learning outcomes and students’ performance, students are expected to produce their own work independently without any collaboration or the use of AI tools. That says students are prohibited from using any AI tools in their assignments and assessments that count towards students’ final grade of the course, or for evaluating their attainment of the desired learning outcomes. ii. Approach 2 - Use only with prior permission In some courses, it may be appropriate to use AI tools in some in-class exercises or assignments. Where applicable and permitted, students will be clearly and explicitly informed of when and how they can use these tools which shall be cited or acknowledged in their work. Details will be spelt out clearly in the course outline and/or the instruction of the assignments. Students shall follow the instruction and permission strictly and are expected to understand the limits and appropriate uses of these tools. iii. Approach 3 - Use only with explicit acknowledgement In courses where students are allowed or expected to collaborate with or use AI tools, students may use these tools for in-class learning activities, exercises or assignments as long as they explicitly cite or acknowledge the use of these tools. Details will be spelt out clearly in the course outline and/or the instructions of the assignments. Students shall follow the instruction strictly and are expected to understand the limits and appropriate uses of these tools. iv. Approach 4 - Use is freely permitted with no acknowledgement In courses where students are allowed or expected to frequently collaborate with or use AI tools, students may use these tools for in-class learning activities, exercises or assignments without citing or acknowledging the use of these tools. In these classes, it is critical that students understand the limits and appropriate uses of these tools. Details on which AI tools are to be used will be spelt out clearly in the course outline and/or the instruction of the assignments. Students shall follow the instruction strictly and are expected to understand the limits and appropriate uses of these tools f) The adoption of permitted use of AI tools in courses are subject to regular review by the course teacher(s) and the programme concerned. It is the responsibility of students to study the course outline, assessment scheme and instruction of individual assignments in detail to ensure that they follow the instruction and permission strictly. Improper/unauthorized use of AI tools in learning 3 activities and assessments constitute acts of academic dishonesty which will be handled in accordance with the University’s Procedures for Handling Cases of Academic Dishonesty. 

As a general principle, students are expected to complete assignments/assessments on their own without any external assistance, unless otherwise specified. If AI tools are permitted for use in the course, students should pay attention to the following for proper use of these tools: i. students should learn and use these tools responsibly and ethically, and be aware of their limitations; ii. the quality of output of some generative AI tools correlates directly to the quality of input, students should master “prompt engineering” by refining their prompts in order to get good outcomes; iii. students should fact-check all outputs of AI tools by cross-checking the claims with reliable sources and are responsible for any errors or omissions, if any, when using these tools; iv. like any other tools and references, permitted use of AI tools should be acknowledged unless otherwise specified; specific and detailed information on the AI tools used, including prompts used if applicable, for completing the assignments/assessments should be provided in the work concerned and, if deemed necessary, the output of generative AI should be included as an appendix of the work submitted by students. 

As a general principle, students are expected to complete all coursework, formative and summative assessments independently without the use of AI tools or other forms of unauthorized assistance, unless specifically permitted. Improper and unauthorized use of AI tools not only jeopardize the quality and efficacy of teaching and learning, but they also constitute acts of academic dishonesty. Students should be cautious of the following which may result in improper/unauthorized use of AI tools in learning: i. using AI tools in completing assignments/assessments without prior permission; ii. handing in an AI-generated work as one’s own; iii. using AI tools to cheat in a course; iv. using AI tools that are not up to date and result in the use of outdated and inaccurate resources; and v. using AI tools in an unethical and irresponsible manner.  

If the use of AI tools is not permitted in an assignment/assessment, and a student is later found to have used such a tool in the assignment/assessment, the case should be handled in accordance with the University’s Procedures for Handling Cases of Academic Dishonesty 

Similar to the submission of other assignments, students are required to declare and assure that the works submitted are their original works except for source material explicitly acknowledged, and the permitted use of AI tools in the assignment(s), if applicable. The academic honesty declaration statement is updated accordingly in the VeriGuide System. 

While appropriate enhancement would be implemented to the VeriGuide system for detecting cases of improper/unauthorized use of AI tools, the University will explore and devise other appropriate measures in detecting students’ submissions and assessments. All identified cases will be handled in accordance with the University’s Procedures for Handling Cases of Academic Dishonesty.   

Similar to other serious cases of academic dishonesty, penalties for improper/unauthorized use of AI tools in assignments/assessments may include reviewable/permanent demerit(s), failure grade for the course concerned, suspension from the University, lowering the degree classification, and termination of studies at the University.  

For cases in which improper/unauthorized use of AI tools in assignments/assessments was committed by a person when s/he was still a student of the University studying for the award in question (but only came to light after graduation) may also constitute good cause under which the 

University may revoke his/her academic award in accordance with the University’s procedure for revoking an academic award 

The educational needs of students in the use of AI tools will be reviewed. 

University will provide professional development opportunities and support to teachers to enhance their AI literacy so as to help enhance sensible and critical use of AI tools among students. p) Guidelines and policies on the use and application of AI tools in teaching and learning will be regularly reviewed and updated to reflect changes in technology, best practices, and other relevant developments.  

44. Seoul National University AI Policy Initative 

 

Introduction Past Activities Seoul AI Policy Conference 2017–2020 2017 Conference 2018 Conference 2019 Conference 2020 Conference (Virtual) 2020 COVID-19 Webinar SAPI Book Publishing Event – Data Ownership: Who Owns My Data? SAPI Issue Paper Seminars AI and Future Society Media Algorithm and Democracy Data Privacy Law Amendments: 

Pseudonymization, Research Utilization, Data Transaction 04 08 16 18 20 Other Academic Events 

Book Publication DAIG (Data & AI Governance) Magazine Publication Issue Paper Publication 

24 30 28 32 Table of Contents Current Research Activities: Projects Other Activities 34 38 

Introduction: Various policy issues are being raised due to the rapid development of artificial intelligence technology and social changes resulting from its adoption. SNU AI Policy Initiative (SAPI) reviews and analyzes social challenges that the data-driven artificial intelligence technology will bring. SAPI aims to address these issues through interdisciplinary research by combining disciplines such as technology, humanities, social science, and law. SAPI launched in 

April 2017 with the vision of becoming a ‘Social Lab’, a research platform for various disciplines within the University. SAPI is leading research in the field of artificial intelligence & law and is actively engaged in joint research and cooperation with domestic and international experts in fields related to data and artificial intelligence. 

Seoul AI Policy Conference 2017–2020:At the 1st Seoul AI Policy Conference in 2017, the panel discussed the algorithm technology and privacy policy. The opening session introduced major policy issues regarding artificial intelligence, focusing on algorithm technology and privacy issues. Session 1 panels discussed policy issues of artificial intelligence and big data in the context of competition, and Session 2 panels discussed policy issues pertaining to the algorithm technology. Session 3 panels focused on the policy issues regarding privacy and data protection.In 2018, the panels discussed the theme of accountability and regulation in the era of artificial intelligence. The first session mainly focused on the regulatory issues and discussed the issue of establishing proper data governance. The second session focused on accountability and discussed the growing ethical concerns regarding the proliferation of automated decision-making. The third session focused on other technical issues such as blockchain and discussed the proper governance of the new technologies. In 2019, the conference theme was ‘the implementation of trust and fairness in the age of artificial intelligence’. In the first session, the panels discussed the reliability of artificial intelligence and the governance framework necessary to gain public trust. In the second session, the panels discussed what it means for the machine to be “fair” and discussed the approaches taken to implement fairness in artificial intelligence. Unlike in the previous years, the 2020 conference was held virtually due to the COVID-19 pandemic. Accordingly, SAPI expanded the number of sessions to eight and arranged the sessions on different days so that sufficient discussions can take place. Despite the change of format, the invited presenters of all sessions gave insightful presentations. For instance, Professor Cynthia Dwork delivered the keynote lecture on current state of Differential Privacy. Despite being an online event that spanned over several weeks, hundreds of scholars attended every session. 

2020 COVID-19 Webinar: Data, AI Governance, and COVID-19: Medium and Long-Term 

Perspectives for Asia SAPI, jointly with Singapore Management University and University of 

Tokyo held the conference based on the “Data, AI Governance, and COVID-19: Medium and 

Long-Term Perspectives for Asia” report published in September 2020. Researchers from Korea, China, Japan, and Singapore discussed the initial COVID-19 response of these Asian countries in terms of data and AI governance. Researchers further discussed how COVID-19 responses will transform our societies. The research was conducted as a part of SMU-Microsoft Asian Dialogue on AI Governance. (https://caidg.smu.edu.sg/smu-microsoft-asiandialogue-ai-governance/events) SAPI Book Publishing Event: Data Ownership: Who Owns My Data? To commemorate the publication of ‘Data Ownership’, SAPI organized a book publishing event on April 29, 2019 with the authors. The data economy and artificial intelligence technology all stem from data. The question that is constantly being asked is, ‘Who owns this data?’ The event was a place for discussion to organize various thoughts on this question and seek policy answers. AI and Future Society At this event held on May 16, 2019, panels discussed how artificial intelligence affects economic growth, what implications the transition to the data economy has on market competition, what changes are happening in the labor market. Panels further evaluated the efforts being made in Korea to establish AI principles that deal with issues such as fairness and discrimination. 

SAPI Issue Paper Seminars Media Algorithm and Democracy At the event, held on November 17th, 2019, panels discussed how algorithms or user profiling work and how they are affecting democratic decision-making process. Panels evaluated phenomena often referred to as the echo chamber effect or filter bubble and how to approach algorithmic transparency and explainability with respect to algorithms affecting public discourse. Panels further analyzed the concept of search or internet ‘neutrality’. Data Privacy Law Amendments: Pseudonymization, Research Utilization, Data Transaction At the event, held on May 7, 2020, panels discussed various issues relating to the recent amendments to Korea’s Data Privacy Laws1. The introduction of the ‘pseudonymization’ concept in the laws was extensively discussed in the broader context of deidentification techniques such as differential privacy. The concept of ‘research utilization’ newly introduced in the laws was also heavily discussed as it defines the scope of utilization of pseudonymized personal information. Panels also discussed the market design of data transaction. 

Feb. 2020 [Co-hosted with Korean Association for Artificial Intelligence and Law] ‘AI and Data 

Privacy Laws Amendment’ Seminar Various expectations and concerns coexisted with the “Three Data Act” amendment on January 9, 2020. Panels discussed the expectation that an environment in which data can be better utilized to serve artificial intelligence technology versus the concern that fundamental human rights such as right to privacy may be jeopardized. Panels further discussed the necessary elements of the followup enforcement decrees and the appropriate actualization of the ideals of the amendments. Apr. 2020 ‘Personal Information Governance in the AI Era’ Webinar The Personal Information Protection Act, amended in January 2020, went into effect in August after a procedure for establishing enforcement decrees. Various expectations and concerns coexisted over the amended law. In this webinar, panels discussed what changes will occur in the governance of personal information, including changes to the regulatory framework due to the amendment. The Personal Information Protection Committee, which newly launched, was given powerful investigation and law enforcement powers. Panels reviewed the law enforcement system that the amended Act envisioned and discussed implications from other existing “committee” experiences and implications from overseas cases. 

DAIG (Data & AI Governance) Magazine Publication: In December 2020, SAPI launched the DAIG Magazine, a magazine specializing in data and artificial intelligence legal policy. The first issue was planned with the theme of “Data Governance in the Digital Era”. DAIG was envisioned to serve as a platform for discussion regarding issues of data and artificial intelligence. DAIG wishes to bridge the gap between the academia and the industry. The following articles were published in the DAIG’s first issue. [SAPI: The original articles are in Korean and the English translation of the titles below are provided by SAPI and not confirmed by the authors.] Data Governance in the Digital Era - Data Valuation – Byoung-Pil Kim - Data Collection: Methods and the Current State – Jong Yoon Kim, Haksoo Ko, Byoung-Pil Kim - E-commerce and Personal Information – Doil Son - Use of Medical Data: Issues After the Data Privacy Amendments – Ho Sang Yoon - Collection and Sharing of Financial Data: Changes Under the New Credit Information Act – Joon Young Kim, Bomi Chen, Jee Young Park - Major Issues and Improvement Directions of Data Legislation for AI Industry Development – Hwan Kyoung Ko, Il Shin Lee, Sanghoo Lee Fundamentals of Data and AI Governance - Practical Algorithms – Bonhyo Koo, Byoung-Pil Kim Platform Proliferation - Regulating Online Platforms: Global Trends – Yong Lim, Soojin Lee, 

Haesung Lee et al. SAPI also held a webinar to commemorate the publication of DAIG on December 22, 2020. Authors presented their papers and held panel discussions in the first half of the event. In the second half, students who participated in the 2020 Summer Research Assistantship Program presented their research. ‘Data Economy’ is a summary of legal, economic, and social issues related to the paradigm shift in the data-driven economy. Various issues such as artificial intelligence, autonomous vehicles, fintech, personal information, internet certificate system, data deidentification, big data and competition laws were reviewed through the lens of data economy, ‘Data ownership’ starts with the recognition that it is difficult to endow ownership of data in a strict legal sense. The book analyzes certain important characteristics of data, and discusses newly emerging legal issues. The book contains the authors’ thoughts on what kind of legal rights can be established for data. Since 2019, SAPI has been publishing issue papers on major research topics regarding artificial intelligence and data.2 [SAPI: The original articles are in Korean and the English translation of titles below are provided by SAPI and not confirmed by the authors. 

Current Research Activities: Projects: 1 Financial Artificial Intelligence Policy & Ethics Guidelines We investigate use cases of artificial intelligence in the financial sector, discover cases where laws and other regulations related to the financial industry hinder the use of artificial intelligence, and propose regulatory improvement measures. We also review specific policy frameworks to encourage broader adoption of artificial intelligence and propose ethical guidelines for use of AI in financial sector by surveying foreign AI ethics principles. 2 Utilization of Medical Data and Privacy Medicine is an area where artificial intelligence can make a huge difference. Improving data usability is the biggest hurdle for the industry. Privacy consideration based on the special nature of medical data is crucial in balancing data usability and medical privacy. We review issues related to use of medical data and propose a balanced approach. 3 Artificial Intelligence in Court Legal documents including court rulings are mostly in text and thus can be utilized using natural language processing. However, many obstacles exist in implementing AI in judicial proceeding. We survey foreign precedents and recommend policy direction to Korean Courts. 4 Legal Prediction AI We review whether implementation of a legal prediction algorithm in damages claims is feasible. We review and confirm the accuracy of the prediction algorithm. 5 Algorithmic Accountability and Governance We review how the opacity of artificial intelligence leads to controversy over fairness and accountability. In this study we pursue an integrated review of technical, medical, ethical, and legal perspectives. 6 Explainable AI While algorithmic decisionmaking is proliferating, the difficulty to explain AI’s decision hinders trust in the technology. Through this research we survey legal and technical discussions around algorithmic explainability and interpretability. 7 Artificial Intelligence Ethics Principle Decisions by AI may not be fair and may exacerbate social bias. Algorithmic fairness has become a central issue in AI research, both normatively and technically. We survey discussions on algorithmic fairness and propose guidelines grounded in domestic situation. 8 Algorithms and Competition Law here are various perspectives on how algorithmic decision affects market competition. We review and organize various views on AI from the competition law perspective. 9 De-identification and Pseudonymization of Personal Information With the amendment of Korean data privacy laws, pseudonymization of personal information is a hot research topic involving various technical and procedural challenges. We review practical pseudonymization techniques and propose policy design. 10 Legal DB and AI Utilization We are building pilot legal database to confirm possibility of implementing AI prediction models in judicial proceedings. 

45. Note on the Use of Generative AI in Education at Kyushu University  

 

 In the "Basic Stance on the Use of Generative AI in Education at Kyushu University" 

(hereinafter referred to as the "Basic Stance on Generative AI") published in August 2023, Kyushu University has established a basic stance on the use of generative AI in education. In the "Basic Stance on the Utilization of Generative AI in Education at Kyushu University" (hereinafter referred to as "Basic Stance on Generative AI") released in August 2023, the University states that it will provide the necessary education so that students will be willing to learn about new technologies such as Generative AI, correctly understand their mechanisms, origins, characteristics, and limitations, and will have the qualities and abilities to utilize them appropriately. 

 In this direction, the use of generative AI is basically recommended in the education of the University. On the other hand, it is also true that there are some points that require caution, such as the possibility of violating laws and regulations depending on how generative AI is used.  For this reason, while taking into account the basic stance of generative AI, the following points of caution for the use of generative AI for faculty members in education at the University are presented. For students, a separate document summarizing the points to be considered will be made available, so please refer to that document as appropriate. 

 In this document, "Generative AI" refers to "AI that generates sentences, images, etc. in response to questions, work instructions (prompt input), etc.". As of September 2023, services such as ChatGPT, Bing AI, Bard, Stable Diffusion, and Midjourney are available. 

 Please note that these precautions are current as of September 2023, and may be revised in the future in light of changes in social conditions surrounding AI and its operation within the university. 

  

(Rules and precautions for the use of generative AI in education) 

Consideration of the possibility of utilizing AI to generate 

In deciding whether or not to use generated AI, the decision will be made after clarifying how the use of generated AI or not allowing students to use generated AI will contribute to their learning and personal growth, in light of the basic stance of generated AI, the educational objectives of degree programs and other programs, and the objectives and achievement goals of each class.  In doing so, the possibility of use should be considered on a case-by-case basis, rather than uniformly judging whether or not to use it for the entire class. For example, effective use can be expected in situations such as brainstorming, identifying issues, and verifying the programming code created by the student. 

Clarification of specific rules and penalties for use in the class 

 (1) Whether or not to allow the use of generated AI decided in (1) should be clearly stated in the syllabus, etc. so that students are aware of it. In cases where the use of AI is permitted, the syllabus should clearly state the specific purpose, scope, and method of use, rather than simply stating so in the syllabus, etc. 

 When clearly indicated in the syllabus, please also refer to the attached typology as appropriate.  If penalties for violating the rules of use are to be established, reference should be made to university regulations, etc., and such penalties should also be clearly stated in the syllabus, etc. 

＜Attachment＞Rules for using AI to be described in syllabus 

Accessibility considerations for generated AI services 

 When using AI generation tools in class, try to select tools that students can access free of charge, as some services are only available in paid versions. When using paid AI generation tools, efforts should be made to reduce the cost burden on students. 

In addition, we will strive to ensure fairness by establishing grading criteria that do not directly affect the quality or differences in the output of the tools used to determine the grade.  

Fostering preparedness for the use of generated AI 

 Please be advised that it is you who decide whether or not to use the output of the generated AI in your submission, and that if you decide to use the output of the generated AI in your submission, you will be fully responsible for the entire content of your submission, even if you did not create it by your own hands. You will be fully instructed that you are responsible for the entire content of your submission, even if you did not create it yourself. 

We also remind students that the essence and significance of learning at universities lies in learning on one's own initiative, and that creating reports and other deliverables without one's own initiative, such as using the output of generated AI as-is, does not deepen one's own learning. 

Protection of personal and confidential information 

 When utilizing the generated AI in the classroom, care should be taken to ensure that it does not contain personal or sensitive information. The same care should be taken with data input by students, and appropriate guidance should be given. 

Respect for originality and copyright 

 When allowing students to use the generated AI in their report writing, etc., the method of questions should be devised to encourage students to combine the output results with their own original thoughts and ideas, rather than using the results as is. 

 In addition, remind students in a timely manner that the output results of the generated AI may infringe on copyright depending on its content and usage. 

Explicitly state the use of generated AI 

 If students are allowed to use the generated AI, they should be instructed to clearly indicate the part of the report in which they cite the output of the generated AI and the name and version of the generated AI service when they use the generated AI in their reports or other documents. Depending on the contents of the class, students may be asked to submit instructions (prompts) to the generated AI and the results of output in response to them (or a series of processes in the case of multiple interactions). 

Ensure accuracy of information 

 Recognize that the user is responsible for checking the accuracy and reliability of the output information without relying on the output of the generated AI, and make sure that students fully understand this. 

 Guidance should also be provided bearing in mind that the output of the generated AI may not always reflect the most up-to-date information and may include social and cultural bias and discrimination. 

Devices in the preparation of assignments and examination questions and in the grading of grades 

Consideration will be given to making class assignments and exam questions in a form that requires critical thinking and individual interpretation by the examinee, avoiding as much as possible a form that can be easily solved by a generative AI. 

 When grading, consider using methods (e.g., oral examinations) that accurately assess how much each student understands on an individual basis, in addition to reports and other artifacts. 

  (10)Possibility of false detection by AI writing detection software 

 As of September 2023, there is no way to reliably detect whether a sentence was created by an AI. If AI writing is suspected, the student should be given an opportunity to explain the situation and a detailed investigation should be conducted before a decision is made. 

(Other) 

 It is recommended that teachers receive regular training and incorporate up-to-date knowledge on the evolution of generative AI technology, the social conditions surrounding generative AI, and how to effectively utilize generative AI in education. Please also refer to the "Reference Materials" that follow, as appropriate. 

46. About the Use of Generative Arificial Intelligence (ChatGPT, etc.) 

About the Use of Generative Artificial Intelligence (ChatGPT, etc.) 

Intellectual resilience and flexible sensitivity 

 

Waseda University has been asking students to train themselves to develop “intellectual resilience” so that they can think thoroughly about problems with no correct answer and come up with their own answers, and to foster “flexible sensitivity” that allows them to work together with a variety of people of different races, nationalities, religions, ethnic groups, languages, genders, and sexual orientations in order to solve various problems with respect and sympathy for one another. In today’s world, where we face major issues such as pandemics, wars, and progressing technological innovation, which can be said to be turning points in society, the importance of “intellectual resilience” and “flexible sensitivity” is increasing. 

 

For example, the development of new technology will change the way we live, work, and the state of society. It’s an unavoidable reality that scientific progress and technological innovation will always have positive and negative sides, advantages and disadvantages. It depends on how humans use technology, and on national policies and institutions that promote or regulate these technological innovations. For those of you who aim to strengthen your “intellectual resilience”, nurture your “flexible sensitivity”, and contribute to society, realizing the correct use of new technology is an extremely important issue. It will also be an important task to conduct research on measures to mitigate the social impact and disseminate the results, with a “flexible sensitivity” that sympathizes with those who are negatively affected by new technology. 

 

Fundamental Attitudes towards Generative AI 

Generative artificial intelligence (hereinafter referred to as generative AI) such as ChatGPT (OpenAI), Bard (Google), and Bing (Microsoft), which have become a hot topic in recent years, are advancing their performance at an accelerated pace. It has been pointed out that they have the potential to bring about major changes in our society. For this reason, interactive automated response services based on generative AI are not only tested around the world but also discussed at educational institutions as to how they should be utilized and regulated. 

Those who advocate “intellectual resilience” need to be familiar with the correct usage of generative AI. To that end, we must have sufficient knowledge of generative AI and cultivate an attitude of keeping pace with technological progress and continuing to innovate our knowledge. Because then you can masterfully use the technology instead of being the one used by it. 

 

In addition, it is imperative to have an accurate understanding of the impact that generative AI will have on society and people, and the issues that arise around the formation process, when we consider the issues of whether to stop the development or regulate the use of generative AI, all of which are in the midst of debate. This is because in the development of new technologies and the production of products and services based on them, a great impact on various people is observed not only after development and production but also before. 

 

Characteristics of Generative AI 

Generative AI learns by itself based on the vast amount of data on the Internet, and can instantly generate response sentences in a natural language dialogue format for various questions and requests in a wide range of fields. Also, even if you ask the same question, the answer (sentence) that is returned will change each time. The following tasks that were previously performed by humans can now be handled by generative AI. 

 

Generation of new sentences based on given strings and keywords (creation of reports, impressions, etc.) 

Generating answers for tests (fill–in–the–blank questions, multiple–choice questions, open–ended questions, etc.) (3) Brainstorming, creation of ideas 

Summarization, translation and proofreading of existing texts and web pages 

Data analysis 

Easy programming 

Lyrics, composition 

Searching for documents and information 

If you can use generative AI with these functions well, you will be able to save a lot of your work time, and many people will get the benefit of being able to concentrate on other important tasks. 

 

On the other hand, the following flaws and difficulties have also been pointed out. There are many things that students need to be careful about. 

 

First, generative AI does not always output accurate information. Currently, for example, there are quite a few cases where answers are generated using non–existent universities or companies, incorrect numerical data, or wrong names. It has also been observed often to fabricate bibliographies of titles and author names that do not exist. 

 

Second, it has been pointed out that reports generated by generative AI are (currently) logically correct as text, but the content is shallow and there is a tendency for a repetition of plausible and obvious things. If you use the results of the generative AI without examining the content, the report will be lacking in originality. 

 

Third, if you submit the thesis created by the generative AI without carefully examining it, the thesis will be evaluated as it is, even if there are incompleteness or fatal errors in the content. You may also be subject to disciplinary action if plagiarism, inappropriate citation, or fabrication is confirmed in the submitted thesis, even if you did not intend to do so. Of course, if you submit a thesis created by the generative AI as it is, it will be punished as a fraudulent act similar to cheating. 

 

Fourth, careless use of generative AI may lead to the leakage of confidential information within the university or company, and questions that include your name, etc. may lead to the leakage of personal information. It has also been pointed out that the disorderly use of generative AI can lead to discrimination, human rights violations, and criminal behavior. Freedom of action must be guaranteed for technological progress, but no one has the freedom to infringe on human rights. “Intellectual resilience” must also pay attention to the tension between technology and society. 

 

Usage and Limitations of Generative AI 

Surely you might be able to complete a report quickly with generative AI, but you’re giving up the opportunity to improve your abilities. Reports are created by gathering a large amount of information from documents and materials, classifying, analyzing, and summarizing them to create the most appropriate answer to the task. Writing a report is the most important exercise in developing “intellectual resilience”. As a result of neglecting this task and prioritizing short–term profits, in serious situations such as entrance exams and work in the real world, you will notice the fact that you have learned nothing. 

 

On the other hand, for those working as business creators who envision unprecedented products and services, the use of generative AI will lead to the realization of effective work. In the process of collecting, classifying, summarizing, and analyzing vast amounts of information about similar past cases to generate new ideas, the partial use of generative AI could save time, and you could spend more of your time generating important new ideas. This effective use assumes that you know firsthand how much work is needed and what quality is required at each stage in the process of making a report. That way, you can easily determine the merits of substituting that part with generative AI, as well as discrepancies and mistakes in the responses shown by AI, and you can use it in a suitable manner. It is important to train your 

“intellectual resilience” daily so that you can use generative AI appropriately according to the time and situation. 

 

In addition, there are reservations about generative AI in terms of “flexible sensitivity”. To be able to work together to solve social problems while respecting the diverse attributes and backgrounds of various people, it is necessary to build mutual trust. It requires both mutual understanding and sympathy. A certain kind of expression is also required in exchange of messages, but it seems difficult for generative AI to appropriately provide expressions that show fine–grained correspondence and persuasive power. 

 

Future Action 

 

You will continue to utilize a variety of products and services developed based on new technologies. Before using them, or while using them, you should repeatedly think about whether they are necessary for you, whether they are beneficial to you, and what kind of impact they have on society. What is beneficial to you now may only have a negative effect on your future self. Some people get more benefits than disadvantages, others do not. Think objectively and with an altruistic spirit. Waseda University’s students, faculty, and staff, as well as all concerned parties, should not forget this way of thinking. 

 

“Intellectual resilience” applies to all matters in the world. To fully understand the multi– faceted impact of new technologies, how to curb the negative aspects, and to further expand the positive aspects, we (not only individuals, but also governments, industries, communities, etc.) must think carefully about what we should do. 

 

47. A Guide to the Use of Generative AI 

 

Preface  

Thanks to the advancements in artificial intelligence technology, generative AI can now perform tasks once thought exclusive to humans. This includes ChatGPT, which has recently garnered significant attention. Generative AI can solve complex problems, create works of art, and both understand and generate language. These amazing abilities of generative AI make us rethink about originality and creativity, which we have long regarded as one of the core values of research and education. 'Does using generative AI in research undermine the originality of the research?' 'Will using generative AI in education hinder the development of students' learning and creativity?' It is hard to give a clear answer to these questions. However, it is certain that the advent of generative AI will somehow influence our thinking and learning methods. The UNIST Education Innovation Task Force has recognized these issues and conducted a survey of faculty, students, and researchers to understand the impact of generative AI on their education, learning, and research activities. We also considered ways to minimize side effects and effectively utilize Generative AI. The result of these deliberations is this guidebook. This guidebook includes a brief introduction to generative AI technology (pp.4-9), guidelines for using generative AI for faculty, students, and researchers (pp.10-15), and tips for using generative AI (pp.17-40). Also, the appendix (pp.43-50) includes the results of a survey on the usage and perception of generative AI targeted at UNIST's faculty, students, and researchers. Artificial intelligence technology is progressing at a tremendous speed. We must continue to analyze the impact of rapidly changing artificial intelligence technology on research and educational activities, and take appropriate action in response to any ensuing challenges. The UNIST Education Innovation Task Force will continue to make efforts to develop policies and guidelines necessary to utilize the advantages of artificial intelligence while minimizing side effects and maintaining and improving the quality of research and education.  

What is Generative AI?  

The Diversity of Generative AI “Generative artificial intelligence or generative AI is artificial intelligence capable of generating text, images, or other media in response to prompts” (“Generative artificial intelligence,” 2023). Generative AI can be classified in various ways, depending on what it creates. • Text Generative AI: This type of AI uses natural language processing technology to generate text. It can write novels, news articles, scripts, and poetry, and generate answers to specific questions. Notable examples include ChatGPT, Bing, and Bard. • Image Generative AI: Image generative AI can generate images according to given descriptions or improve existing images. DALL-E, Midjourney, and Stable Diffusion are some representative examples. • Voice Generative AI: Voice generative AI can convert text to speech or transform one voice into another. Examples include Meta Platforms' VoiceBox and Google's Tacotron. • Music Generative AI: Generative AI can also generate music. Google's MusicLM is a notable example. 

• Video Generative AI: Video Generative AI can generate videos based on text or image input, or modify existing videos. Examples include RunwayML's Gen2 and Meta Platforms' Make-AVideo."  

Generative AI vs Discriminative AI Generative AI produces new content, but it does not create something from nothing. Generative AI learns the distribution of data from the provided input and probabilistically generates new content corresponding to input values. For example, a model that generates text creates sentences that are likely to follow the input sentence, based on the probability distribution of the pre-trained data. To boil it down, generative AI generates new sentences based on learning that certain phrases are likely to follow certain other phrases.Generative AI typically undergoes pre-training based on a vast amount of unlabeled data.1 In contrast, discriminative AI, unlike generative AI, generally learns from pre-labeled data. It then outputs labels corresponding to input values based on this learning. Such discriminative AI is used for classification or prediction. 

Capabilities of Generative AI Discriminative AI is chiefly utilized for tasks such as classification or prediction. However, generative AI is also capable of executing these tasks. It is both conceptually and technically possible to employ generative AI in these roles. Firstly, from a conceptual standpoint, if we instruct the generative AI to generate classification or prediction results, it's possible to perform these tasks using generative AI.Secondly, while generative AI does not explicitly learn from labeled data for specific classification or prediction tasks, it learns from a vast amount of data and naturally becomes capable of carrying out classification or prediction tasks. As the performance of generative AI improves, its ability to handle a more diverse and comprehensive range of tasks also increases. According to Narang and Chowdhery (2022) of Google Research, “as the scale of the model increases, the performance improves across tasks while also unlocking new capabilities,” as follows: The emergence of transformer technology has made it possible for generative AI models to scale in such a way.2 Thanks to this transformer technology, we have been able to handle vast amounts of data in the field of Natural Language Processing (NLP), leading to the emergence of Large Language Models (LLMs).3 These LLMs, trained on a massive scale of data, have begun to demonstrate a range of abilities beyond simple language processing. Now, generative AI trained on a massive amount of data can perform various tasks such as not only translating text, but also logical reasoning, problem-solving, summarizing text, writing code, recognizing patterns, and composing text. With the ability to process language, it has become possible to associate text with various types of data, such as images, voices, and videos, for combined learning. Artificial intelligence capable of understanding and processing various media types is referred to as multimodal generative AI. Although not yet publicly released, OpenAI's GPT-4 is reportedly capable of understanding photos or graphs and of providing logical reasoning or problemsolving capabilities (OpenAI, 2023). Artificial intelligence technology continues to evolve. With the increase in computing power and the improvement of AI algorithms, generative AI is gradually approaching Artificial General Intelligence (AGI), which has the potential to perform any intellectual task that a human can do. 

Limitations of Generative AI Generative AI still has its limitations. A prime example is 'hallucination.' Hallucination refers to the phenomenon where generative AI provides answers that are not factual, treating them as if they were true. This occurrence of hallucination arises because generative AI does not generate the absolute correct answer, but instead produces the response that is most likely to be correct. Various methods are being explored to overcome this phenomenon of hallucination. These include approaches like post-processing, which filters the generated answers, or fine-tuning to enhance the model. Additionally, augmenting the volume and quality of the training data used by generative AI can help to mitigate the occurrence of hallucinations. However, completely overcoming the issue of hallucination in generative AI is a significant challenge. As a result, it is crucial for users to scrutinize and validate the responses from generative AI carefully. Another limitation lies in the potential for generative AI to generate biased content. Since generative AI learns patterns from its training data, biases or inclinations present in that data may be mirrored in the model. As a result, the responses produced by the AI could exhibit bias or unfairness. This means biases concerning specific races, genders, or societal issues could be reflected, posing substantial ethical concerns. Therefore, it's crucial for users to maintain a critical perspect 

Guidelines on Using Generative AI For Faculty 

Education Try using generative AI yourself: Whether you decide to allow generative AI in your course, it is helpful to test them to understand how they respond to your assignments and how students might use them. This will give you insight into the strengths and limitations of Generative AI, and you may discover ways to incorporate them into your teaching. Make a course-level decision on the use of generative AI: There is no institution-wide prohibition on using generative AI for teaching and learning purposes. You may choose to incorporate them into your course or prohibit them. The decision to utilize generative AI should be made at the course level autonomously by the instructor, based on the characteristics of each course. Update the syllabus: Include your course policy regarding the use of generative AI in the syllabus, and make sure to announce it. Use various forms of assessment: Evaluating students based solely on one final project or assignment can increase the possibility of academic dishonesty. It can be beneficial to allocate scores for a sequence of tasks such as proposing ideas, improving them, and reflecting on their learning. Furthermore, oral exams or unexpected questions can be effective ways to assess whether students thoroughly understand their submitted work and if they have completed it on their own. Require citation in assignments: Merely requiring students to strictly cite sources in their assignments prompts them to be more cautious when using generative AI. Consider using an AI detector: If you are concerned about students submitting essays generated by AI tools, you can use AI detectors to identify them. However, it's important to note that identifications should not rely solely on these detection tools. Content should still be carefully reviewed for the final decision. Discerning the use of generative AI can be challenging 

Research Check the policy on AI tools of the academic journal or conference: Academic journals or conferences may have different policies regarding the use of generative AI. It's necessary to check in advance if there are specific guidelines about the use of generative AI in the journal you plan to submit to or the conference you plan to participate in. Cite generative AI tools: Cite generative AI tools to acknowledge their contribution to your research. Verify the source: Generative AI learns from existing data to generate new content. When using generative AI in research, it's crucial to conduct additional searches to ensure that the output doesn't overlap with existing work or violate any copyrights. Be mindful of bias in generative AI: Information in the training data can carry inherent biases, which may then be reflected in generative AI models. This can inadvertently result in biases related to specific races, genders, or social issues being incorporated into your research. Do fact-check: Generative AI may produce fake or incorrect content. You should fact-check any information obtained from Generative AIs before using it. Security Do not share important research information with AI tools: Many generative AI tools are open platforms, and third parties may record or analyze conversations with AI. Avoid sharing any confidential or proprietary research information with AI that could potentially be exposed to third parties. Ensure your devices have up-to-date security software: Ensure your devices have up-todate security software and firewalls to prevent unauthorized access by Generative AI to sensitive information. Do not share personal information with Generative AI: Avoid sharing sensitive information such as your name, address, phone number, or other personal details when interacting with Generative AI. Be cautious when using AI-generated code: The code produced by AI may contain errors or security vulnerabilities. It's crucial to go through a verification process before utilizing AI-generated code. 

Guidelines on Using Generative AI For Students 

Learning Be mindful of the course policy: Your professor may prohibit using generative AI. Carefully read the current syllabus and follow the course policy. Using generative AI could be considered academic misconduct. Do fact-check: Generative AI may produce fake or incorrect content. You should fact-check any information obtained from Generative AI before using it. Think critically: You should be aware of the drawbacks and limitations of the generative AI you are using. Always question and critically evaluate the AI's output. Furthermore, you should strive for results that surpass those generated by the AI. Use generative AI as an auxiliary tool only: The creativity and problemsolving skills gained through personal experiences cannot be replaced by generative AI. Relying on generative AI could hinder your learning and growth 

Research Check the policy on AI tools of the academic journal or conference: Academic journals or conferences may have different policies regarding the use of generative AI. It's necessary to check in advance if there are specific guidelines about the use of generative AI in the journal you plan to submit to or the conference you plan to participate in. Cite generative AI tools: Cite generative AI tools to acknowledge their contribution to your research. Verify the source: 

Generative AI learns from existing data to generate new content. When using generative AI in research, it's crucial to conduct additional searches to ensure that the output doesn't overlap with existing work or violate any copyrights. Be mindful of bias in generative AI: Information in the training data can carry inherent biases, which may then be reflected in generative AI models. This can inadvertently result in biases related to specific races, genders, or social issues being incorporated into your research. 

Security Do not share important research information with AI tools: Many generative AI tools are open platforms, and third parties may record or analyze conversations with AI. Avoid sharing any confidential or proprietary research information with AI that could potentially be exposed to third parties. Ensure your devices have up-to-date security software: Ensure your devices have up-todate security software and firewalls to prevent unauthorized access by Generative AI to sensitive information. Do not share personal information with Generative AI: Avoid sharing sensitive information such as your name, address, phone number, or other personal details when interacting with Generative AI. Be cautious when using AI-generated code: The code produced by AI may contain errors or security vulnerabilities. It's crucial to go through a verification process before utilizing AI-generated code. 

Guidelines on Using Generative AI For Researchers 

Research Check the policy on AI tools of the academic journal or conference: Academic journals or conferences may have different policies regarding the use of generative AI. It's necessary to check in advance if there are specific guidelines about the use of generative AI in the journal you plan to submit to or the conference you plan to participate in. Cite generative AI tools: Cite generative AI tools to acknowledge their contribution to your research. Verify the source: Generative AI learns from existing data to generate new content. When using generative AI in research, it's crucial to conduct additional searches to ensure that the output doesn't overlap with existing work or violate any copyrights. Be mindful of bias in generative AI: Information in the training data can carry inherent biases, which may then be reflected in generative AI models. This can inadvertently result in biases related to specific races, genders, or social issues being incorporated into your research. Do fact-check: Generative AI may produce fake or incorrect content. You should fact-check any information obtained from generative AI before using it Security Do not share important research information with AI tools: Many generative AI tools are open platforms, and third parties may record or analyze conversations with AI. Avoid sharing any confidential or proprietary research information with AI that could potentially be exposed to third parties. Ensure your devices have up-to-date security software: Ensure your devices have up-todate security software and firewalls to prevent unauthorized access by Generative AI to sensitive information. Do not share personal information with Generative AI: Avoid sharing sensitive information such as your name, address, phone number, or other personal details when interacting with Generative AI. Be cautious when using AI-generated code: The code produced by AI may contain errors or security vulnerabilities. It's crucial to go through a verification process before utilizing AI-generated code. 

Tips for Using Generative AI 

Education (Faculty) Generative AI can be a valuable tool for educators. For example, it can make class preparation more efficient. By simulating student responses with generative AI, educators may be able to predict student reactions, potentially maximizing the effectiveness of instruction. However, in classes where the use of generative AI by students needs to be limited, it is crucial to design the course in accordance with the specific characteristics of the subject matter. Course Design  

Try asking generative AI for course-specific integration advice. It can also be helpful to directly ask generative AI how it can be utilized in education according to the characteristics of each subject. Explain what subject you are teaching and ask how you can use generative AI in that specific subject. 

Try using the flipped learning strategy. If you are concerned about students using generative AI for assignments, adopting a teaching method known as flipped learning or the flipped classroom could be a good strategy. “A flipped classroom is an instructional strategy and a type of blended learning, which aims to increase student engagement and learning by having pupils complete readings at home and work on live problem-solving during class time.” (“Flipped classroom”, 2023) In a flipped classroom environment, students learn independently based on the course materials provided before class and perform tasks such as assignments and discussions during class time when the use of generative AI can be regulated. This approach can naturally alleviate concerns about misconduct caused by the use of generative AI. In the flipped classroom, it's crucial to thoroughly evaluate various activities that occur during class, such as student presentations and questions. If these diverse activities are included in the assessment criteria, students are likely to participate more actively in class.  

Try asking the generative AI for textbook recommendations for your course. If you're developing a new course, you might want to get recommendations for textbooks or reading materials from the generative AI. GPT-3.5 and GPT-4 were trained based on data up until September 2021. If you require more recent information, consider using Google's Bard or Microsoft's Bing. 

Consider using generative AI in syllabus creation. After explaining the course to the generative AI, ask it to draft an initial syllabus. If there are specific contents that need to be included in the syllabus, request the AI to incorporate them. 

Class Preparation 1. Try using generative AI to write your lecture outlines. If you want to ensure your lecture proceeds in an organized manner, having an outline ready in advance can be helpful. After explaining the content you will cover in class to the generative AI, try delegating the task of drafting the lecture outline Once the outline is created, you can also create a draft of the presentation slides through generative AI. Try asking the generative AI to convert the outline into HTML. Next, save the HTML code in Windows Notepad, then import it into Office365's Word. From there, exporting as a PowerPoint presentation will quickly complete a draft of the PowerPoint slides.4 

Try asking the generative AI to generate explanations in various ways. Depending on the students' levels, different types of explanations may be required. Consider requesting a variety of explanations from the generative AI. 

Try using generative AI to create various examples that explain concepts. When explaining concepts to students, using various examples can greatly aid their understanding. However, finding these examples can be time-consuming. Consider asking the generative AI to create examples. 

Try using generative AI to simulate potential questions from students. Inform the AI about the topic for the next class and ask it to predict possible questions. This could enable you to respond to students' queries more effectively. 

Assessment 1. Consider using oral exams. If you are concerned about the potential decline in students' academic performance due to generative AI, implementing oral exams or unexpected questions can be an effective method to evaluate students' comprehension of their submitted assignments. Do not let the learning process stop at assignment submission; instead, encourage students to articulate their understanding of their own work. This approach can prevent students from submitting assignments they have not fully grasped. 2. Try asking generative AI to create quiz problems. You can ask the generative AI to form True/False or multiple-choice questions. By revising and utilizing the questions generated by the AI, you can save time on creating quiz problems. 

3. Consider Using AI Detectors. If you prohibit students from using AI generators to write and submit essays, it is recommended to use detectors that reveal whether generative AI was used. https://www.turnitin.com/ https://gptzero.me/ The Education Innovation Task Force tested several AI detectors launched by May 2023 and found that Turnitin and GPTZero showed relatively superior performance. As a result, an AI detection functionality was added to the Turnitin service, which was previously used to check the similarity of papers and assignments. Turnitin is integrated with our university's Learning Management System (LMS), Blackboard. Encourage your students to submit their assignments via Blackboard. The setup for Turnitin in Blackboard is as follows: When using Turnitin, the percentage of AI usage is displayed in the blue box at the bottom right of the report. While AI detectors are valuable tools, they should not be wholly relied upon. An AI detector is just one reference tool. If there's a suspicion that a student’s work was generated by AI, it could be helpful to employ multiple AI detectors like GPTZero, where possible. For shorter texts, the accuracy of AI detectors can decrease. Consequently, it's advisable to use AI detectors on longer texts, when possible. Determining whether a student has used a generative AI to ghostwrite their assignment can be challenging. For an appropriate assessment, it's recommended to meticulously review the content of the student's work, evaluate their level of understanding through discussions, and then draw a conclusion about the potential use of AI. 

Grading and Feedback 1. Try using generative AI for grading. Generative AI can serve as a grading assistant. However, when using generative AI for grading, it is essential for the instructor to personally review and adjust the student's essay and grading results. Also, please notify the students that generative AI was used in the grading process. Start by creating a grading rubric, as shown in the example below.5 Generative AI typically recognizes copied and pasted table content quite well. However, to ensure it is well-understood by the generative AI, it is recommended to modify it into a more comprehensible format. This process can also be facilitated by the generative AI. For example, you can input “Reorganize the following essay rubric:”, followed by the simply copied rubric table. Then, a reorganized grading rubric will appear as follows: After doublechecking the content, ask the generative AI to grade the essay based on that rubric: Then, the generative AI will provide the grading results as shown below:  7. Try using generative AI for feedback. Besides grading, generative AI can also assist in crafting initial feedback for students. Ask the generative AI to generate feedback in a way that encourages your students. In using generative AI to give feedback to students, it is crucial that you always check the content of the feedback. 

Education (Students) Consider utilizing generative AI in your learning process. AI can provide a customized learning experience tailored to your individual level and pace, and it can assist in deepening your understanding across a range of topics. However, it is crucial to understand the limitations of generative AI and ensure that you do not miss opportunities to develop your own competencies. 

Consider developing a study plan using generative AI. You can ask the AI to help create a study schedule either for the semester or the holidays. Set your desired field of study and duration, then ask for recommendations such as textbooks, MOOCs, or YouTube content. 2. Request concept explanations from generative AI. Ask the AI about concepts you don't understand. If there are areas that you're finding difficult to comprehend, continue asking questions based on the AI's explanations. Consider asking the same question multiple times or posing it to a different generative AI. Just as you might get a better answer by asking the same question to multiple people, you could find a better answer by asking different AIs the same question. 3. Consider using generative AI to draft an email to your professor. If you have questions but find it challenging to approach your professor directly, sending an email can be a good alternative. Generative AI can provide significant assistance in writing emails. Ask generative AI for advice on the most effective way to draft your email. Also, it is a great way to learn how to compose an email politely and professionally. 

Research (Faculty, Students, Researchers) When utilizing generative AI in research, you can enhance your work's efficiency. However, as the reliance on generative AI increases, the originality of your research might gradually decrease. Determining the acceptable boundary for using generative AI is challenging. This is similar to removing a single grain from a heap and asking when it no longer qualifies as a heap. If you're employing generative AI in your research, it is advisable to use it judiciously, ensuring that it doesn't undermine your work's originality. Always remember, the responsibility for the final outcome of the research lies solely with the researcher. 1. Verify the editorial policy of the journal or publisher. It is essential to check the editorial policies of prospective journals or publishers not only at the submission stage but also throughout the research process. Below are the editorial policies from several journals and publishers. Please note that these policies may change over time 

Disclose how you used generative AI. It is important to disclose how you used generative AI in your research. Please make it clear in the appropriate places of your paper, such as the acknowledgements or methods, about the use and application of generative AI. Nature's editor-inchief, Magdalena Skipper, emphasizes, “authors using LLMs in any way while developing a paper should document their use in the methods or acknowledgments sections, if appropriate” (Chris Stoke-Walker, 2023). 3. How to cite generative AI There is a risk of being perceived as committing plagiarism if the usage of generative AI is not appropriately cited in academic writing. Holden Thorp, editor-in-chief of the Science family of journals, has made his position clear on this issue. 

He states, “use of AI-generated text without proper citation could be considered plagiarism” (Chris Stoke-Walker, 2023). Researchers must appropriately cite the use of generative AI, adhering to the style guidelines of each specific journal. Here are a few methods for appropriately citing generative AI in scholarly papers 4. Try using generative AI for proofreading your paper. You can use generative AI for proofreading your paper as follows. However, excessive editing by AI could alter the content and results of your paper, potentially compromising the originality of your work. Therefore, authors should be cautious when using generative AI for proofreading. 5. Try using generative AI for your literature review. Ask for recommendations of the most frequently cited or most influential papers in a specific field. (Please note that ChatGPT is based on data trained until September 2021. For the latest materials, try using Google’s Bard or Microsoft’s Bing.) If you are a subscriber of the paid service GPT-plus, you can search the archives of Arxiv, a prominent academic paper repository, through a plugin. Try searching for "arXiv" in the plugin store. The Chrome browser features a variety of plugins related to generative AI. One such plugin, ArxivGPT, can provide crucial information about papers uploaded on Arxiv. 

Appendix: Survey Results The Education Innovation Task Force conducted a survey to understand how generative AI is used and perceived by UNIST members. The aim of this survey was to formulate effective strategies for handling generative AI. The survey details are as follows: Survey period: April 28, 2023, to May 7, 2023 Participants: 70 faculty members, 147 graduates, 105 undergraduates, and 36 researchers Have you ever used generative AI like ChatGPT? Among the respondents, 89% of the faculty, 93% of graduate students, 90% of undergraduates, and 69% of researchers indicated they have used generative AI. Among the respondents, 43% of graduate students and 65% of undergraduates had used generative AI in their classes. In the case of undergraduates, about two-thirds of the respondents are using generative AI in their courses. How often do you use generative AI? Among those who responded that they have used generative AI in the previous question, 38% of faculty, 51% of graduate students, 39% of undergraduate students, and 16% of researchers reported using it five times a week or more. Graduate students showed the highest frequency of use. What language do you primarily use when using generative AI? Among those who responded that they have used generative AI, 83% of faculty members, 73% of graduate students, 72% of undergraduate students, and 72% of researchers revealed that they primarily use English when leveraging generative AI. The high prevalence of English usage among students seems to be attributable to the fact that courses at UNIST are conducted in English. When using generative AI, are you cautious about the potential leakage of personal information or important research data? Among those who reported using generative AI, 64% of faculty members, 71% of graduate students, 60% of undergraduate students, and 80% of researchers stated that they are cautious about security when using generative AI. What generative AI tool do you mainly use? Among the students who reported having used generative AI, most responded that they use the GPT-3.5 (free) version, while 21% of graduate students and 18% of undergraduates who have used generative AI reported using the paid services GPT-4.0 or GPT (API). Other responses included Bard, Github Copilot, ChatPDF, Stable Diffusion, and Perlexity.ai. Generative AI can produce answers that are different from the truth. Do you fact-check the answers obtained through it? 57% of graduate students and 39% of undergraduates who have used generative AI responded that they always fact-check the output. Only 1% of graduate students and 3% of undergraduates reported that they do not fact-check at all. These results suggest that students are well aware of the limitations of generative AI If you have used generative AI for coursework, specifically for what purposes have you used it? (Multiple responses) 81% of graduate students and 75% of undergraduates who reported using generative AI in their coursework indicated that they use it for assignments. Both graduate and undergraduate students were found to use generative AI more for reviewing than for previewing. 16% of graduate students and 13% of undergraduates reported using generative AI for exams. If you have used generative AI for coursework, how specifically have you used it? (Multiple responses) The application of generative AI revealed a very similar pattern among both graduate and undergraduate students. Both groups primarily use it for coding. When using generative AI, only 3% of both graduate and undergraduate students said they submit their writing assignments without any revisions. Do you think using generative AI is helpful for your learning? In a survey conducted among students who use generative AI in their studies, the majority indicated that the use of generative AI helped or significantly aided their learning. However, 3% of undergraduates responded that it seemed to obstruct their learning. Of the faculty respondents, 18% indicated they plan to ban the use of generative AI in future assignments or exams. However, 63% reported they would not prohibit the use of generative AI in these areas. Additionally, 52% of faculty expressed willingness to incorporate generative AI into their future classes. Overall, this data suggests a generally favorable attitude towards generative AI usage among faculty. In response to the question of whether they would be willing to use an AI detector assuming that the use of generative AI by students is banned, 49% of respondents answered affirmatively. Furthermore, 56% of faculty members indicated that changes in the assignment or exam formats are necessary due to generative AI How do you utilize generative AI in your research? (multiple responses) For faculty members, graduate students, and researchers, the most common use of generative AI in research was for translation or proofreading. In contrast, undergraduate students used generative AI for brainstorming and coding more frequently, with 56% and 59% respectively, compared to other groups. Plagiarism is generally defined as "taking someone else's ideas or creations without proper citation." Do you think using generative AI for writing papers constitutes plagiarism? Two-thirds of the respondents, consisting of 66% faculty members and 67% researchers, believe modifications are needed to the existing definition. Additionally, 42% of graduates and 54% of undergraduates also responded that they think the current definition needs revision. Which of the following do you think considered cheating when students use generative AI for their assignments? (Multiple responses) While 67% of faculty members responded that not citing the use of generative AI constitutes cheating, only 39% of graduate students and 48% of undergraduates shared this view, demonstrating a disparity in perception. Furthermore, the percentage of faculty members who believe that submitting work without modification constitutes academic dishonesty was 56%, lower than that of the students. 

48. SUM Framework for the use of Generative AI Tools 

INTRODUCTION 

Singapore Management University has developed a Framework for The Use of Generative Artificial Intelligence (AI) Tools which aims to provide guidance on how the SMU community can use such tools, and where resources should be channeled to ensure the responsible and effective use of generative AI tools. It provides the University’s position on the use of generative AI tools, as well as its use in the following specific contexts: [i] as a learning aid for students or [ii] as a pedagogical tool for instructors, and [iii] in assessments. 

UNIVERSITY’S POSITION ON THE USE OF GENERATIVE AI TOOLS 

The University recognises the benefits that generative AI tools bring and its increasing presence in our everyday lives. Our students will build their careers in a world where AI tools will be increasingly pervasive and it is incumbent on us to teach students how to interact with such tools in an effective and discerning way. With fast evolving technologies like AI, our response is not to shy away from it, but to assess how we can harness the best of what it can offer and adapt the way we teach and approach assessments to prevent misuse. We are committed to exploring ways to integrate generative AI tools into education, but at the same time safeguard academic integrity and standards of academic rigor. For this reason, ensuring the responsible and ethical use of generative AI tools must be part of our response. 

THE FRAMEWORK 

 

USE OF GENERATIVE AI TOOLS BY STUDENTS AS A LEARNING AID 

Generative AI tools have the potential to enhance students’ understanding of knowledge leading to better learning outcomes. Nonetheless, students need to be made aware of the limitations and ethical use of such tools. 

The Student Success Centre has launched the Guide to Learning with AI online module to educate students on how generative AI tools can be used as a learning aid in an effective and responsible manner. This module can be found on eLearn.  

USE OF GENERATIVE AI TOOLS BY INSTRUCTORS AS A PEDAGOGICAL TOOL 

Generative AI tools can lead to improved teaching quality and support instructors to create educational content. 

The Centre for Teaching Excellence (CTE) has developed a resource page on the “Use of AI Tools in Assessment and Teaching” for instructors and will be updating it as new information on AI tools arises. In addition, a series of webinars / workshops has been planned to provide support to instructors on the effective use of generative AI tools in teaching, including demonstrating best practices for incorporating these tools in their teaching. 

USE OF GENERATIVE AI TOOLS BY STUDENTS ON ASSESSMENTS 

The University will address the potential misuse of generative AI tools in assessments using the following three-pronged approach of Adapt, Incorporate, and Detect: 

ADAPT 	by 	changing 	assessment 	approach 

Instructors can adapt by redesigning assessment questions such that they are beyond the existing capabilities of generative AI tools or changing the type of assessments employed. 

INCORPORATE generative AI tools on assessments where 	appropriate. 

Instructors may choose to allow the use of generative AI tools on assessments, where its use can enhance learning. If an instructor chooses to allow the use of a generative AI tool: 

○ its permitted use must be made explicit to students; 

○ guidelines for when and how it is to be used should be provided; 

○ use of the tool should be credited using a widely accepted format, where applicable, such as the APA Style Guide or Chicago Manual of Style. 

DETECT misuse of generative AI tools with detection tools, as they become available. 

SMU instructors should follow the “DRIVE” approach if they encounter suspected cases of students’ unauthorised use of generative AI tools during assessment. Please refer to the section below for more details on the DRIVE approach. 

Communicating Expectations to Students 

Instructors should clearly communicate their expectations and policies regarding the use of Generative AI tools and ensure that students understand the importance of academic honesty and originality. For assessments that do not allow students to use generative AI tools, students should be informed of the consequences of violation.  

For assessments where the use of generative AI tools is permitted, students should be told the specific areas and tasks where generative AI tools could be applied and what constitutes unauthorised use.  

In this link (Statement Templates), instructors can access templates of statements they can adapt according to their requirements: 

Statement to explain the use of Generative AI tools in assessment to students.  

Statements of Declaration for students in assessments where the use of Generative AI is permitted, restricted, partially permitted under certain conditions specified by the instructor.  

In the event suspected unauthorised use of Generative AI tools are detected, please apply the DRIVE approach and refer to the Faculty Handbook for Academic Violation. 

Instructors may seek guidance from Associate Deans, and also contact the University Council of Student Conduct for more information: 

UNAUTHORISED USE OF GENERATIVE AI TOOLS IN ASSESSMENT 

The unauthorised use of generative AI tools will be considered cheating – a violation of the SMU Code of Academic Integrity and will be dealt with accordingly. Please refer to the Faculty Handbook for Academic Violations for more information (log in required). Penalties will align with the University's established practices for cheating. 

Protocol for reviewing suspected cases of unauthorised use of generative AI tools: The DRIVE Approach 

 

The following section outlines the protocol that SMU instructors should follow if they encounter suspected cases of students’ unauthorised use of generative AI tools during assessment. The protocol is named the DRIVE approach, which is an acronym for: 

				D 	: 	Detect 	unauthorised 	use 

				R 	: 	Review 	student 	submissions 

					I 	: 	Inform 	student 	of 	status 

					V 	: 	Verify 	using 	other 	sources 

E : Escalate via usual academic integrity channels 

Details of the DRIVE Approach 

 

49. Artificial Intelligence in Education 

The emergence of Generative Artificial Intelligence (AI) based technologies and tools that can generate content including written text, software code and images (e.g., ChatGPT, DALLE2, Midjourney), has generated much interest in higher education while concerns have also been raised about possible misuse, plagiarism, stifling creatively/originality and etc. 

 

SUTD’s stance on Generative AI Tools is as follows: the use of Generative AI tools is acceptable when used ethically and responsibly to enhance teaching and learning. 

 

SUTD educators have embraced these new technologies and are already applying Generative AI tools in their respective courses to transform teaching and learning in innovative ways. This includes continually reviewing and re-designing class assignments and assessments with the purpose of enabling students to demonstrate capacity for critical thinking, innovation, and originality. 

 

While these developments are taking place, SUTD educators are cognizant of the need to: 

prepare students to use these AI tools ethically and critically; and 

enable students to acquire critical technical knowledge, skills and core competencies needed in their domains. 

Here are some guidelines / advisories to help students better navigate in the era of these developments:  

Students can use Generative AI tools to enhance their learning but not as a replacement for their intellectual contribution.  

Students can use Generative AI tools in class, assignments, assessments, examinations, etc. only when explicitly permitted by the instructor. Students should adhere strictly to the guidelines provided by the instructor on the usage of such tools.  

Where permitted by the instructor, students shall disclose and declare how and when Generative AI tools are used in assignments and projects. The format for citation and disclosure of the use of AI tools will be advised by the instructor. Not disclosing or declaring when Generative AI is used is a breach of academic integrity. When in doubt, students can approach their instructors for guidance.  

SUTD has clear and established rules on plagiarism, including breaches of academic integrity with the use of AI-assisted tools and apps. Students are bound by the tenets of the SUTD Honour Code* to always conduct themselves with integrity and accountability. The use of AI-assisted tools and apps for all SUTD courses whether in course work or projects (including UROP and Capstone for undergraduate students) to generate content to pass off as one’s own work constitutes plagiarism and therefore a breach of academic integrity. Students who are found guilty of plagiarism will be subject to disciplinary action in accordance with the Student Disciplinary Framework. 

* Refer to policies on upholding academic integrity at MyPortal (via > Student Matters and 

Policies > Student Matters > University Policies > Academic Integrity / Student Discipline).  

Where students have been expressly informed in their courses or projects that they are accessing confidential information or personal data, students are prohibited from sharing or inputting such confidential information or personal data into Generative AI Tools.  

To help support students in using Generative AI tools ethically and appropriately, an infoguide titled 'ChatGPT - An Introduction' is available (view info-guide). The info-guide helps students understand the benefits and limitations of Generative AI tools. Further guides on commonly used Generative AI tools are being prepared and will be released soon. 

 

			Concluding 	Statement 

This is a living document which will be updated alongside developments in the field of Generative AI. Students are encouraged to reach out to instructors for more clarity on the use of generative AI tools in their courses and to be made aware of the benefits, pitfalls and policies governing the use of such AI tools. 

 

50. Generative AI at the Singapore Institute of Technology 

			Karin 	AVNIT 

							SIT 	Teaching 	and 	Learning 	Academy 	(STLA), 

Singapore Institute of Technology (SIT) 

Karin shares her team’s experiences of supporting their colleagues in engaging with GenAI, including strategies to enhance professional development and reviewing current assessment practices at SIT. 

This post is featured in a Special issue on “Navigating Generative AI in Higher Education”, where academic developers in Singapore’s institutions of higher learning discuss how they are working with their student and faculty colleagues to effectively engage with and navigate GenAI in teaching and learning. 

The emergence of generative artificial intelligence (Generative AI, or GenAI) tools like ChatGPT has opened new frontiers in teaching and learning. At the Singapore Institute of Technology (SIT), we identify three focus areas for a responsible adoption of GenAI tools. First, the urgent need to adapt our assessment practices to ensure the validity of our assessment while maintaining standards of academic integrity. Second, the exciting opportunities that GenAI tools provide for improved teaching and learning practices, and third is the need to review how GenAI tools affect the industries for which we prepare our graduates, to update the programme learning outcomes, and to ensure that our students have the right skills as well as knowledge to integrate effectively in the workforce. We share here our experiences and strategies, journeying with academic staff at SIT through this fast-changing landscape for professional development and the review of assessment practices. 

A Collaborative Approach to Professional Development 

Managing the disruption that GenAI tools introduced starts with ensuring that academic staff are aware of this technology, able to use it effectively, and appreciate its capabilities. This need to quickly upskill all academic staff at SIT is unprecedented in terms of professional development practices. With the absence of established best practices, no experts that have more than limited experience with the technology in higher education, and with a technology that evolves rapidly, upskilling staff at SIT was a challenge. 

SIT took a collaborative approach to this challenge of professional development, turning to the growing collective experience within SIT and drawing insights from the global education community. A channel for discussions on AI in teaching and learning was set up on Microsoft Teams, as a place for sharing information and collaborative learning. In this channel, the team of educational technologists and educational developers from the SIT Teaching and Learning Academy (STLA) published an academic guide for practices related to GenAI. Recognising that any guide on GenAI must be constantly updated, the guide (available only internally) is concurrently published as a shared editable document that enables all teaching and academic staff to contribute from their knowledge and experience. Sharing and dialogue sessions are also scheduled regularly and are well attended. 

Guarding the Validity of Assessments 

When it comes to the validity of assessments, SIT is perhaps at greater risk than more traditional higher education institutions of GenAI impacting the validity of our assessments. This is due to the progressive assessment practices that we promote and the limited reliance on proctored exams. Authentic and Applied Assessment practices mean that much of the work is done in project or project-like tasks, where instructors have limited oversight or control over the tools used by students in the completion of tasks. For this reason, SIT immediately put an emphasis on reviewing all current assessments to gauge and address any threat to the validity of our assessment practices, and to ensure that we are still able to assess the competencies of students in achieving the stated learning outcomes. 

At the same time, we did not change our assessment principles and policies. We still promote authentic assessment practices, rather than react to the potential threat by returning to proctored pen-and-paper exams. In the long run, as GenAI tools also change industry practices, we anticipate that the Programme Learning Outcomes will need to update and reflect the new skills of the industry for employees to co-work with AI. Then, GenAI tools may be seamlessly integrated into practices of authentic assessment. 

As part of the effort to ensure the validity of assessments, all academic staff at SIT are required to demonstrate their competency in evaluating and adjusting assessments to meet the new challenges presented by GenAI tools, as part of a mandatory Micro-Module on AI literacy. As academic staff review and revise their assessment briefs for this demonstration of competency, this naturally feeds back to the collaborative learning to co-exist with GenAI. 

Concluding Remarks, as Generated by ChatGPT 

SIT’s journey with Generative AI in education highlights a path of innovative adaptation and collaborative growth. Emphasising the integrity of assessments, enhancing teaching methods, and aligning with evolving industry standards, we are pioneering a balanced integration of GenAI in higher education. Our experience showcases the potential of AI to enrich learning while maintaining academic excellence, setting an example for the future of educational practices. 

 

51. NUT Position on the Use of Generative Artificial Intelligence in Research 

NTU Position on the Use of Generative Artificial Intelligence in Research 

Nanyang Technological University (NTU) recognizes that Generative Artificial Intelligence (GAI) 

– such as OpenAI’s ChatGPT, Microsoft Bing, and Google Bard – provides new tools to support research practices and scholarly activities, including the preparation and drafting of research proposals, manuscripts, and other scholarly work. 

  

NTU acknowledges that GAI has the potential to enhance the quality and efficiency of research, and provide new modes of inquiry. However, it is important to recognize that its use in research can raise ethical, research integrity and other concerns. Researchers must therefore carefully evaluate these issues, and have a thorough understanding of the technology – including its potential risks and limitations (e.g., current AI-generated outputs can contain bias, errors, inaccuracies, or falsehoods) – before considering its use. 

  

Researchers who use AI tools in their scholarly work must use GAI in a responsible and accountable manner, and be transparent on the extent and nature of the involvement of GAI in their work. This would include acknowledging the use of any AI tools in their research proposals, manuscripts, and scholarly works. 

  

Currently, NTU does not impose restrictions on the use of GAI in research, except in the scenarios outlined in points 3 and 4 below.   

  

  

The Responsible Use of GAI in Research 

  

Acknowledging/Declaring the Use of GAI 

  

In the interests of transparency and integrity, the use of GAI of beyond basic spelling and grammar checks should be appropriately acknowledged and cited. 

  

Additionally, any use of GAI to generate images for illustrations or figures should be clearly stated in the caption and/or document, in a manner easily understandable to the reader. 

  

Authorship 

Authorship requires the acceptance of responsibility for the work described in any manuscript. Researchers should recognise that GAI cannot be held responsible as an author for the accuracy, integrity, and content of such work. 

Therefore, any GAI (e.g. ChatGPT) will not be listed as an author of any paper with an affiliation to NTU; or listed as a Principal Investigator (PI), Co-PI, or collaborator in any research proposals. 

  

Authors and/or PIs are fully responsible for the content of their scholarly materials (e.g., research proposals, grant applications, manuscripts for publication) in which GAI was used in the preparation and/or development of such outputs. Researchers must therefore exercise caution and judgement when using GAI, and be ready to verify the accuracy and validity of their work. (See Figure 1 under resources.) 

  

Data Privacy & Confidentiality 

The use of GAI to process or analyse research data must comply with all relevant data privacy and protection laws, regulations, and institutional policies - e.g., the Personal Data Protection 

Act (PDPA), NTU’s Data Governance Policy. 

  

Any confidential or sensitive information, and/or personal data are not to be uploaded to any GAI software, system, or platform unless: 

Access to the GAI is controlled and restricted to only authorized study members involved in the research; 

The data is not retained in or by the GAI; and 

The activity does not contravene any applicable laws, regulations, or institutional policies in the process. 

 

Researchers must prioritize and safeguard the privacy and confidentiality of research data when using GAI and will be held responsible for any leakage of data. 

 

Data Owned by Non-NTU Entities 

Data owned by external parties, including but not limited to businesses, organisations, and government ministries and agencies, are also not to be uploaded to any GAI software, system, or platform unless: 

i. All requirements for confidential, sensitive data, and/or personal data listed under 

“Data Privacy & Confidentiality” are satisfied; ii. Valid written permission has been explicitly provided by the data owner/custodian; or iii. The use of such GAI has been agreed upon in the Research Collaboration Agreement (RCA). 

 

Rules established by other Parties 

If the proposal, manuscript or other document is being submitted to a agency, journal or other party with rules concerning GAI that differ from the NTU position, then the stricter rules should be followed. NTU researchers may contact RIEO for advice. 

  

In conclusion, Generative AI in research must be used in an ethical, responsible, transparent, and accountable manner that benefits society. NTU faculty, staff, and students should adhere to the following when employing GAI in their research: 

Appropriately acknowledge and cite the GAI used; 

Do not attribute or list any GAI as an author; 

Take full responsibility for the use of any GAI-generated content in their work; and 

Safeguard the privacy and confidentiality of confidential and/or sensitive research data, including Personal Data. 

 

Date issued: 4 Jul 2023 

  

Disclosure 

OpenAI’s ChatGPT (Mar 23 version) was used to improve the clarity and readability of this statement. No confidential or sensitive information was uploaded during this process. 

  

 

Resources 

UNESCO (2023). ChatGPT and Artificial Intelligence in Higher Education: Quick start guide.  

 

52. Guidelines for Collaboration, Co-learning, and Cultivation of AI 

 

Guidelines for Collaboration, Co-learning, and Cultivation of Artificial Intelligence Competencies in University Education1 NTHU AI Task Force National Tsing Hua University Considering the substantial impact generative artificial intelligence (AI) has on higher education learning environments, we recommend that our institution's faculty and students adopt a transparent and responsible approach when employing AI products, including generative AI, within educational settings: l Transparency: Instructors should establish explicit guidelines for AI utilization in their courses, with both students and teachers candidly disclosing their AI usage when relevant. l Responsibility: Instructors and students should recognize AI as one among various content sources and possess the ability to evaluate the accuracy of AI-generated content, assuming responsibility for their produced content. We suggest that the role of AI in teaching and learning should encompass collaboration and colearning: 1. Working with AI: Leverage AI tools to collaborate and optimize the benefits of diverse knowledge domains, achieving efficient, innovative, and human welfare-enhancing outcomes. 2. Learning with AI: View AI as a tool for intellectual discovery, supporting the integration and adaptation of various knowledge domains through reflection on learning and thinking processes, enabling the construction of new knowledge forms.  Students and educators should thoroughly understand the following challenges when using AI:  

Challenge 1: Technical Barriers: Be aware that language models' complex inner workings hinder the development of open-source, transparent, and democratic models. Challenge 2: Credibility: Identify that scarce training data requires validation of generated content's credibility and accuracy. Challenge 3: Bias and Fairness: Prevent usage of content generated from biased training texts or content that jeopardizes academic integrity. Challenge 4: Pedagogical Methods: Reevaluate teaching and assessment approaches, along with potential outcomes. Challenge 5: Academic Ethics: Examine issues pertaining to authorship and plagiarism. 1 ; English version has been translated by GPT-4 and proofread by Prof. Wing-Kai Hon and Dr. Tonny Menglun Kuo  Integrating AI in Teaching and Learning:  

1. Teaching Material Preparation: R AI can support summarization of video subtitles or presentation content for class notes or review. R AI can streamline the creation of presentation materials, such as generating images. R AI can suggest lesson plans (course outlines) and provide diverse, relevant examples as supplementary explanations. 2. Student Learning: R AI can facilitate interdisciplinary learning. R AI can assist in brainstorming, document refinement, and foreign language editing. R AI can efficiently consolidate key points from literature for focused comprehension and application. R Though generating in-depth reports with AI may be challenging, AI can provide frameworks for students to supplement with their knowledge or perspectives. R AI can serve as a personalized tutor, accommodating individual learning progress and potentially alleviating resource constraints. R Explore "prompt engineering" to leverage AI's integration and retrieval capabilities for innovative idea generation. 3. Educator Teaching: R The institution respects educators' AI tool usage strategies in courses; educators should clarify rules for student AI use in course syllabi, especially regarding proper citation and disclosure. R Guide students in knowledge provenance, discourage reliance solely on AI-generated content, and address academic and research ethics issues associated with AI tool usage. R Emphasize relevant domains' fundamental concepts, promoting deeper learning through extension, association, and application, rather than rote memorization. R Investigate AI's potential impact on arts, humanities, and social science disciplines; educators can facilitate group discussions and guide students in delivering oral presentations on AI utilization for creation or proposing alternative perspectives. 4. Learning Assessment (Assignments/Reports): R Depending on the course, allow AI assistance for answering questions, but require students to submit assignments in diverse formats, emphasizing domain knowledge construction and knowledge internalization over score attainment. R Utilize AI-generated answers as examples, guiding students in critique and revision, annotating edited sentences or paragraphs, and providing justifications. R Develop students' ability to trace knowledge origins, assessing sources, accuracy, and school of thought perspectives. R Focus grading on students' abilities targeted by the course. 3 5. Learning Assessment (Exams): R Design questions requiring deeper reasoning, creativity, analysis (e.g., contextual judgment, procon arguments, contentious issues), and critical thinking, emphasizing knowledge's role in problem contexts rather than merely searchable knowledge. R Consider AI-human collaboration assessments, permitting AI usage in exams while evaluating students' critical thinking and creativity. R For take-home exams, pre-test questions with AI; unsuitable questions may include those on which AI performs well.  Cultivating AI Competence  

1. What is AI Competence? AI competence encompasses more than mere programming capabilities; it entails possessing a fundamental comprehension of AI technology and its applications, along with the skills to assess, employ, and execute AI and associated applications. This competence requires the judicious utilization of AI in human learning, work, and life, contemplation of its effects on human existence, and the ultimate promotion of human welfare. Foundational: (1) Understand the basic concepts, techniques, methods, and instrumental nature of AI. (2) Recognize AI application scenarios and potential impacts, and understand the capabilities and limitations of AI tools. (3) Recognize ethical, privacy, and security issues potentially caused by AI and cultivate thinking and judgment abilities. Advanced: (4) Accurately disclose the AI usage process to ensure transparency. (5) Apply various types of AI in work and life situations, improving the ability to solve complex problems. (6) Continuously reflect on the relationship between AI and humans to enhance human welfare. 2. Cultivating AI Competence in Students: Integrating Formal (Courses, Research) and Informal Learning (Clubs, Activities, Competitions, Internships) (1) Offer foundational and specialized AI courses: Provide (micro) courses to guide students in understanding the basic knowledge, evolution, and risks of AI technologies, helping them comprehend AI's capabilities and limitations, and discern its accuracy; offer specialized AI courses covering topics such as machine learning, natural language processing, robotics, and computer vision to facilitate continuous technical refinement. 4 (2) Incorporate AI into curricula: Embed AI components within courses across disciplines like engineering, business management, education, arts, and humanities, fostering the development of critical thinking, problem-solving, and innovative collaboration skills. Simultaneously, emphasize the importance of considering social and environmental ramifications in decision-making processes. (3) Establish academic integrity and accountability mechanisms: Formulate regulations for AI research and applications to ensure compliance with academic ethics and legal requirements. (4) Provide experiential learning opportunities: Offer students opportunities to participate in AI research projects, construct AI models, and develop AI applications, as well as practical coursework to tackle real-world societal issues. (5) Forge partnerships with industry collaborators: Enable students to acquire hands-on exposure to real-world AI applications through internships or industry-academic partnerships, thereby understanding the practical implications of technological advancements. (6) Organize workshops, seminars, or forums to explore AI's impact on various aspects: Provide students with opportunities to learn from experts in different fields about AI's effects on technology, life, society, academia, and ethics, participate in discussions, and create platforms for peer knowledge sharing. (7) Advocate interdisciplinary collaboration: AI development necessitates the proactive participation of interdisciplinary talents; universities can promote interdisciplinary learning by designing and innovating courses or institutional systems. Additionally, hosting competitions, special projects, or self-study groups can facilitate interdisciplinary and cross-cultural collaboration among students. 

53. Guidance for Use of Generative AI Tools for Teaching and Learning 

 

Generative Artificial Intelligence (Generative AI) is a type of artificial intelligence technology that uses machine learning to create new things. Related developments in AI assistance and HumanRobot Collaboration (HRC) are inevitable trends for the future. NTU has adopted a positive attitude towards these trends and encourages faculty members to consider generative AI tools (such as ChatGPT) as an opportunity to enhance teaching. In response to the development of new tools, teachers can make timely adjustments to classroom teaching, and designing content and assessments that better reflect the uniqueness and objectives of your courses. At the same time, students should also understand the limitations of using AI tools, and learn how to use these tools to facilitate your learning. 

Faculty and students can gain a better understanding of these tools from the aspects of teaching and learning. Take ChatGPT as an example, we provide the following guidance for the use of generative AI tools. 

What is ChatGPT? 

ChatGPT is a large language model (LLM) released on November 30, 2022, that is currently receiving a lot of attention. The model is based on generative AI technology. Similar LLMs include PaLM and Bloom. The principle of generative AI is to analyze data models through machine learning, and then automatically generate text, images, audio, video, and other content. 

What are the functions of ChatGPT? 

The main function of ChatGPT is to perform natural language processing and generate many kinds of textual content, such as: 

Conversation: conducting a one-on-one dialog between user and AI by answering user’s question. 

Translation: translating text from one language to another. 

Summarization: condensing long texts into short summaries. 

Composition: generating articles, stories, news, poems, scripts, etc. based on keywords input by the user. 

Recommendation: recommending articles, videos, music, etc. based on the user’s interests and Internet history. 

Q&A: answering questions from users, or providing relevant content based on keywords input by users, such as answers to frequently asked questions, knowledge/informational inquiries, etc. 

Text Analysis: content analysis, topic summaries, character recognition, etc. 

What are the limitations of ChatGPT? 

Network Restriction: It operates on cloud servers and requires an intern connection to use. 

Language Restriction: Currently, it only supports a limited number of languages and may not be able to process text in certain languages. 

Data Restriction: Training data is obtained through the Internet which may lead to biases and errors in the generated text, requiring users to make their own judgments and verifications. 

Privacy Restriction: Some functions may require users to provide personal privacy information, such as chat histories, search histories, etc. Users should pay attention to what data they share. 

Guidance for Instructors 

How to respond to students using Generative AI Tools in my courses? 

If you have concerns about your students using generative AI tools such as ChatGPT, we suggest making three adjustments: 

Clearly communicate the methods and restrictions of using generative AI tools to students: First, you should clarify the principles and guidelines for using generative AI tools in your courses. In addition to verbal explanations and reminders so that students clearly understand the rules, you should also clearly state your rules on generative AI in the course syllabus at the beginning of the course, to help reach consensus with the students and prevent disputes. You should also think about which classroom activities and assignments students are permitted or not permitted to use generative AI tools on. If the tools can be used, in what forms and scopes are they allowed? If not, how will generative AI use be detected? And how will the misuse be handled? 

Enhance classroom practice and exercises: Depending on the nature of your course, provide students with learning activities that must be performed or completed in the classroom. 

Adjust evaluation methods: Broaden the scope of learning assessments. Instead of focusing on a single assessment or end result, look at progress or cumulative results that students demonstrate through the learning process. Another approach is to deepen the content of learning assessments by increasing the difficulty of assignments or exams, adding content that is unique to your course, or designing assessments that better reflect students’ personal characteristics. 

How to use ChatGPT for teaching? 

Designing exam questions and checking answers: When you create exam questions, try answering them via ChatGPT. If ChatGPT is able to get most of the questions correct, that may mean you need to adjust the questions. Make adjustments by increasing the difficulty of the questions, adding content that is unique to your course, or adding content that reflects students’ personal characteristics. 

Drafting lesson plans or assignment instructions: Try using ChatGPT to create a first draft or to organize your ideas, then refine them, to make your work more efficient. Also use ChatGPT to check whether your assignment instructions are complete and comprehensible, to identify areas that need modification or additional explanation. 

Creating teaching or learning materials: Use ChatGPT to create worksheets, practice questions, activity instructions, and resources for student self-learning. 

What courses and learning content are suitable for using ChatGPT? 

ChatGPT is a language model that can be used to support a variety of courses that require natural language processing. Examples include: 

Language and Linguistics: Help students learn and analyze various aspects of language, including grammar, syntax, and semantics. 

Communication and Media Studies: Explore how language is used in different forms of media and communication channels, including social media, news, and advertising. 

Computer Science and Artificial Intelligence: Help students understand the principles of natural language processing and machine learning, including techniques for text classification, language modeling, and sentiment analysis. 

Psychology and Cognitive Science: Study how humans process language and communicate with each other, and how technology is changing communication patterns. 

Education and Language Studies: Support language learning by providing feedback, practice, and dialogue. 

Are there any tools to detect whether or not a student is using ChatGPT? 

Currently, detection tools for ChatGPT-generated content include OpenAI AI Text Classifier, CheckforAI, GPTzero.me, and Content at Scale. However, we need to remind you that the current technology for detecting ChatGPT-generated text does not provide sufficient accuracy for you to say for certain whether AI-generated content has been used in a particular assignment. In addition, detection is more difficult if the generated content has been modified rather than used directly. Furthermore, since the content of AI-generated text is arbitrary combinations of words, even if a detection tool determines that AI-generated text was used in an assignment, it cannot provide conclusive evidence (that is, unlike existing plagiarism detection tools that can clearly identify the journals or web pages containing similar content). This being the case, teachers must be cautious about using any AI content detection tools, to avoid false detections that cannot be validated and that could lead to further disputes. 

Will ChatGPT replace introductory-level courses? 

The existence of ChatGPT does not diminish the value of learning the fundamentals of any given topic. Responses currently given by ChatGPT often have errors and do not give more in-depth reasoning or creative production. The majority of research indicates that while the quality of ChatGPT-generated content is moderate to high, it is not yet comparable to leading-edge results. When students (or anyone) work with the content provided by ChatGPT, they must first be able to identify the correctness of the content, evaluate the quality of the results, and know how to apply the relevant content. Additionally, using ChatGPT requires that the user describe their needs in a correct, logical manner. All of this requires a high level of training and knowledge in the fundamentals. 

Guidance for Students 

How to use content generated by ChatGPT? 

When you use ChatGPT to facilitate writing assignments or reports, you must clearly indicate that content produced by ChatGPT is used, so that the reader understands what resources you have used to support your argument. If you find that the content used comes from the works of others, use an appropriate citation format, such as APA, MLA, Chicago Manual of Style, etc. (as required by your School or course) to indicate the exact source of the content. When you use AI-generated content, it is necessary to conduct information verification; ensure that academic ethics and academic integrity requirements are followed, and that you don’t engage in plagiarism or copyright violations. 

How to cite content generated by ChatGPT? 

At present, there are no definite rules for citing AI-generated content in academic writing. However, the sources of AI-generated content cannot be retrieved, accessed, or provided with direct links. Therefore, we recommend treating it as “personal communication” or “correspondence” and make use of the appropriate citation format. For details and citation methods, please refer to APA, MLA, Chicago Manual of Style, and other citation format. You can also refer to Scribbr for citation suggestions and examples: ChatGPT Citations | Formats & Examples 。 

How to use ChatGPT to help with learning? 

Answering questions: Ask ChatGPT questions to further clarify concepts or ideas that you’re unclear about within a topic of study or course content. 

Providing feedback: Use ChatGPT to analyze your assignments and provide feedback as a reference for reflection and improvement. 

Providing Examples: Use ChatGPT generated content as examples to compare or analyze the strengths and weaknesses of your own work. 

Editing written content: Use ChatGPT to assist with coursework or reports writing by correcting grammar or refining content. 

Practicing languages: Use the conversation and question-and-answer functions for learning foreign languages. 

Practicing critical thinking: Content generated by ChatGPT may include information bias and errors. It is thus necessary to learn to examine, evaluate, and analyze information. With content that lacks supporting evidence or seems incorrect, seek other authoritative sources 

to ensure that the information is accurate, reliable, and meets academic and research requirements 

Clarifying ideas and identifying goals: When you use ChatGPT, your questions must be as clear and specific as possible to receive high-quality responses. The question-and-answer process with ChatGPT can thus help you clarify your ideas and better identify your learning goals. 

What should be aware of when using ChatGPT? 

Avoid over-reliance on ChatGPT: The content generated by ChatGPT can only be used as a reference; it cannot replace personal thinking and research results. Therefore, you cannot rely on ChatGPT-generated content for learning, or even research. Instead, use the content generated by ChatGPT as a reference and combine it with personal analysis and reflection to complete your learning. 

Improving the quality of questions: To get quality answers from AI-generated content, you must first have quality questions. The questions you ask must be as clear and specific as possible, so that ChatGPT can interpret them more readily and provide meaningful answers. Even then, ChatGPT may still produce incorrect or ambiguous answers, so it is up to you to assess the correctness of the answers. 

Clearly defining your learning objectives: It is important to have clear learning objectives before using ChatGPT. That way, you can focus on questions and answers related to these objectives, and deepen your understanding of the topics through the information you obtain from ChatGPT. In addition to checking the information yourself, we suggest that you discuss the information with other students and teachers. By obtaining different perspectives and opinions, you can confirm that the information you’re using is consistent with your learning objectives. 

 

 

54. Use of Artificial Intelligence Tools  

 

THE CHINESE UNIVERSITY OF HONG KONG Use of Artificial Intelligence Tools in 

Teaching, Learning and Assessments A Guide for Students Artificial intelligence (AI) is sweeping the globe, and generative AI in particular has been hotly discussed because of its potential to revolutionize the way we teach and learn. The University believes that it is crucial for teachers and students to embrace and become acquainted with AI in order to optimize its potential in education. Students should learn to make sensible use of AI tools, not only for their studies, but also for their future professional development and advancement in order to thrive in this AI era. Like any other educational resources, teachers and students should approach AI tools critically, recognising their limitations in an honest and authentic manner and how these tools could be incorporated into teaching and learning in order to attain the desired learning outcomes. To optimize the use of AI in education, the University has prepared for teachers the “Guidelines on the Use of Artificial 

Intelligence Tools in Teaching, Learning and Assessments” (Guidelines) to i) set out how the University may integrate AI tools in its teaching and learning while upholding academic honesty, integrity and quality; ii) recommend some possible approaches in adopting AI tools in teaching and learning; iii) make it clear and explicit that improper/unauthorized use of AI tools in assignments/assessments constitute acts of academic dishonesty which will be handled in accordance with the University’s existing guidelines and procedures; and iv) provide some readily available references and resources for supporting the adoption of AI tools in teaching and learning. Students should take note of the following salient points extracted from the Guidelines and follow strictly the instruction and/or permission given in the course outline by the teachers regarding the use of AI tools in teaching, learning and assessments. The Guidelines will be reviewed and updated as needed to reflect changes in technology, best practices, and other relevant developments. a) There are different types of AI tools, for instance generative AI tools (e.g. Chat GPT) which can be easily instructed using ordinary human language to generate various formats of texts. Some AI tools facilitate the creation of ‘original’ artwork (e.g. DALL·E 2), translated text (e.g. Google Translate), formulas (e.g. Sheet+), and computer code (e.g. OpenAI Codex), etc. applicable to a great variety of use. While teachers and students are encouraged to explore and take advantage of the benefits of adopting appropriate AI tools to enhance their teaching and learning activities, decisions on which AI tools to adopt and how to use them in teaching and learning should be made cautiously and thoroughly. b) The availability and accessibility of AI tools to students will be carefully evaluated before adopting AI tools into any teaching and learning activities. AI is a double-edged sword; we should use but not abuse it, use it as a research but not cheating tool, and most importantly, use AI to think with you, but not for you. c) Where applicable and permitted, approaches to the use of AI tools in different disciplines will be worked out taking into consideration the needs of different disciplines, their pedagogical approaches and assessment means. When adopting AI tools in teaching and learning, teachers and students should be cautious of their accuracy and reliability and bear the responsibility of using the educational resources and references obtained through these tools. 2 d) As a general principle,students are prohibited from using any AI tools to complete their assignments, assessments and any other works that count towards their final grade of the course or attainment of the desired learning outcomes, unless explicitly permitted. e) Depending on the learning outcomes, pedagogical design, and assessment scheme of different courses, the following are some possible approaches to adopt AI tools in teaching and learning. Relevant details will be spelt out clearly in the course outline and/or the instruction of the assignments. Students shall follow the instruction and permission strictly and seek clarification from the course teacher if in doubt. Students are also expected to understand the limits and appropriate uses of these tools. i. Approach 1 (by default) - Prohibit all use of AI tools In assessing the level of achievement of learning outcomes and students’ performance, students are expected to produce their own work independently without any collaboration or the use of AI tools. That says students are prohibited from using any AI tools in their assignments and assessments that count towards students’ final grade of the course, or for evaluating their attainment of the desired learning outcomes. ii. Approach 2 - Use only with prior permission In some courses, it may be appropriate to use AI tools in some in-class exercises or assignments. Where applicable and permitted, students will be clearly and explicitly informed of when and how they can use these tools which shall be cited or acknowledged in their work. Details will be spelt out clearly in the course outline and/or the instruction of the assignments. Students shall follow the instruction and permission strictly and are expected to understand the limits and appropriate uses of these tools. iii. Approach 3 - Use only with explicit acknowledgement In courses where students are allowed or expected to collaborate with or use AI tools, students may use these tools for in-class learning activities, exercises or assignments as long as they explicitly cite or acknowledge the use of these tools. Details will be spelt out clearly in the course outline and/or the instructions of the assignments. Students shall follow the instruction strictly and are expected to understand the limits and appropriate uses of these tools. iv. Approach 4 - Use is freely permitted with no acknowledgement In courses where students are allowed or expected to frequently collaborate with or use AI tools, students may use these tools for in-class learning activities, exercises or assignments without citing or acknowledging the use of these tools. In these classes, it is critical that students understand the limits and appropriate uses of these tools. Details on which AI tools are to be used will be spelt out clearly in the course outline and/or the instruction of the assignments. Students shall follow the instruction strictly and are expected to understand the limits and appropriate uses of these tools. f) The adoption of permitted use of AI tools in courses are subject to regular review by the course teacher(s) and the programme concerned. It is the responsibility of students to study the course outline, assessment scheme and instruction of individual assignments in detail to ensure that they follow the instruction and permission strictly. Improper/unauthorized use of AI tools in learning 3 activities and assessments constitute acts of academic dishonesty which will be handled in accordance with the University’s Procedures for Handling Cases of Academic Dishonesty. g) As a general principle, students are expected to complete assignments/assessments on their own without any external assistance, unless otherwise specified. If AI tools are permitted for use in the course, students should pay attention to the following for proper use of these tools: i. students should learn and use these tools responsibly and ethically, and be aware of their limitations; ii. the quality of output of some generative AI tools correlates directly to the quality of input, students should master “prompt engineering” by refining their prompts in order to get good outcomes; iii. students should fact-check all outputs of AI tools by cross-checking the claims with reliable sources and are responsible for any errors or omissions, if any, when using these tools; iv. like any other tools and references, permitted use of AI tools should be acknowledged unless otherwise specified; specific and detailed information on the AI tools used, including prompts used if applicable, for completing the assignments/assessments should be provided in the work concerned and, if deemed necessary, the output of generative AI should be included as an appendix of the work submitted by students. h) As a general principle, students are expected to complete all coursework, formative and summative assessments independently without the use of AI tools or other forms of unauthorized assistance, unless specifically permitted. Improper and unauthorized use of AI tools not only jeopardize the quality and efficacy of teaching and learning, but they also constitute acts of academic dishonesty. Students should be cautious of the following which may result in improper/unauthorized use of AI tools in learning: i. using AI tools in completing assignments/assessments without prior permission; ii. handing in an AI-generated work as one’s own; iii. using AI tools to cheat in a course; iv. using AI tools that are not up to date and result in the use of outdated and inaccurate resources; and v. using AI tools in an unethical and irresponsible manner. i) If the use of AI tools is not permitted in an assignment/assessment, and a student is later found to have used such a tool in the assignment/assessment, the case should be handled in accordance with the University’s Procedures for Handling Cases of Academic Dishonesty. j) Similar to the submission of other assignments, students are required to declare and assure that the works submitted are their original works except for source material explicitly acknowledged, and the permitted use of AI tools in the assignment(s), if applicable. The academic honesty declaration statement is updated accordingly in the VeriGuide System. k) While appropriate enhancement would be implemented to the VeriGuide system for detecting cases of improper/unauthorized use of AI tools, the University will explore and devise other appropriate measures in detecting students’ submissions and assessments. 

All identified cases will be handled in accordance with the University’s Procedures for Handling Cases of Academic Dishonesty. l) Similar to other serious cases of academic dishonesty, penalties for improper/unauthorized use of AI tools in assignments/assessments may include reviewable/permanent demerit(s), failure grade 4 for the course concerned, suspension from the University, lowering the degree classification, and termination of studies at the University. m) For cases in which improper/unauthorized use of AI tools in assignments/assessments was committed by a person when s/he was still a student of the University studying for the award in question (but only came to light after graduation) may also constitute good cause under which the University may revoke his/her academic award in accordance with the University’s procedure for revoking an academic award. n) The educational needs of students in the use of AI tools will be reviewed. o) University will provide professional development opportunities and support to teachers to enhance their AI literacy so as to help enhance sensible and critical use of AI tools among students. 

p) Guidelines and policies on the use and application of AI tools in teaching and learning will be regularly reviewed and updated to reflect changes in technology, best practices, and other relevant developments.  

55. Chulalongkorn University Principles and Guidelines for using AI Tools 

Principles 

Chulalongkorn University supports its students and staff in gaining understanding and being able to appropriately use AI tools. 

Chulalongkorn University supports the modification of teaching and assessment processes, as well as work tasks, appropriate for the creative and ethical use of AI tools. 

Chulalongkorn University places the utmost emphasis on academic integrity. 

Guidelines 

Teaching 	and 	Assessment 

Instructors should understand the capabilities and limitations of the chosen AI tools, and design teaching and assessment processes suitable for these tools. 

Instructors should clearly define in the course syllabus the scope and directions for using AI tools, such as ChatGPT, Google Bard, in the course, along with explaining the reasons to the students. 

If a course allows students to use AI tools, the instructor should adjust the evaluation methods appropriately, and should not directly assess the work that students can use AI tools to respond to. 

Usage 	of 	AI 	Tools 

AI is merely a tool. The user is responsible for the correctness of the information and resulting 	work. 

If AI tools are used in any task, reference and clearly state the scope of usage in that task. Concealing and not disclosing information about using AI tools is considered an ethical violation, which could be penalized according to relevant regulations and rules. 

Privacy 	and 	Personal 	Information 

It is prohibited that any confidential information should be uploaded from the organization or personal information into the AI system without consent from the concerned individuals. 

 

ChatGPT General Usage 

 

The use of AI in academia presents both opportunities and challenges to academic integrity. 

Concerns include the use of AI-generated papers and the potential for biased or inaccurate analysis. However, guidelines and protocols can be developed to ensure ethical use of AI in academic work. 

It is important for academic institutions, researchers, and students to work together to maintain academic integrity while utilizing the transformative power of AI in education and research. Lecturers, do you... 1. have to ask students to STOP students using ChatGPT? NO. As a teacher and a researcher, we should embrace the use of technology. However, as highlighted by Mr Nadella, a SAFETY element must be put in place. For example, lecturers should inform the students about academic integrity and highlight the rules and regulation in UM (refer to KaedahKaedah Universiti Malaya (Tatatertib Pelajar) 1999) if students abuse the technology. BANNING ChatGPT is not the solution! 2. know that there are other AI that can help you to counter ChatGPT? You may use ChatGPT counter-AI to help you identify 'cheating' students. Or you can simply use alternative mode of assessment for you course. 3. provide resources and support to help students complete their coursework without resorting to plagiarism? Students may use ChatGPT to complete their assignment due to lack of understanding, motivation or even because they desire to get good grades easily without putting in the necessary effort. As such you may also provide necessary support by providing additional learning materials, or perhaps provide "sentences" that student may use to ask for info from ChatGPT. 4. use plagiarism software to check for students work? As of this writing, many plagiarism tool DO NOT detect AI generated text, including the most famous – TurnItIn and Grammarly. Lecturers should be mindful when giving written-based assignment to students. world, understanding, learning human preferences, with safety..." 

Guide for ChatGPT usage in Teaching and Learning 

 

ChatGPT is a natural language processing (NLP) tool that uses a type of AI called a GPT-3 model to generate responses to text-based chat input. It is designed to simulate human conversation and provide responses that are relevant to the user's input. It can be used for a variety of applications, including customer service, personal assistants, and chatbots. 

As an educator, it is important to have a general understanding of artificial intelligence and how it can be used in education. Students will have to learn how to navigate life with AI. Usage of AI in teaching and learning should be conducted in a safe and ethical manner, and with integrity. ChatGPT usage requires educators to redesign their assessment. This technology will eventually start to push some of those terrible assignments out and force us to come up with something new LET STUDENT USE GPT Allow students to use ChatGPT and hold discussions according to established rules. 

ENSURE STUDENTS UNDERSTANDPractice recall and other memorization exercises that mention a specific period of time, a particular subject, or past actions are used to make sure that students make an attempt to comprehend and evaluate any references they have used. 

COLLABORATIVE ACTIVITIESIncrease the number of discussions and collaborative activities. Students use their own short- and long-term memories when they converse. While individuals can search up short answers, most of the effort involved in having a discussion comes from their own thoughts. Students can summarise a discussion and share their comments on it afterward, which is much more difficult to do with a bot. 

ENGAGE WITH STUDENTPut an emphasis on experiential learning and include students in personalized elaborations that are related to their daily routines and immediate surroundings. Allow students to demonstrate their learning. It will be more challenging (but not impossible) for students to simply ask an AI to write their assignment if you require them to incorporate ideas, evidence, viewpoints, and data from current or personal events or geographical contexts. 

UNIQUE CASE STUDYUse AI to your advantage. For your authentic evaluation, utilise ChatGPT to tailor or create a special case study for each student or their group based on their interests and proficiency level. 

DIFFERENT TYPE OF ASSESSMENTTry utilising various assessment modalities, such as oral evaluation and live demonstration, that are more resistant to AI and can help students grow and exhibit comprehension. Furthermore, generative AI poses less of a threat to staging exams, which require students to submit draft, get feedback, and then revise their work. create questions that involve :- contextual and real world problem (eg relate to a specific issue/discussion/topic in a past conducted lesson) personal opinion with reasoning and justification current issues drafting sketches/figures/illustrations 

STUDENT OPINIONS AND JUSTIFICATIONSInclude a section in assessments to allow students to give feedback on how they can improve (what they got, if it fits, how to organise it, how to communicate it effectively, etc.) and reflect their synthesis of the information they have learned through reading, internet research, peer discussions, and ChatGPT responses they have used. 

58. Guidelines for Responsible Research Conduct (2023) 

Table of Contents 1. Research Topic Selection and Implementation........................................ 

.................. 12. Data Management ............................. ................................................................. ........33. Literature citations........................................ ..................................64. Achievements signature................................................. 	..................75. 	Results 	published............ ................................................................. 	.............86. 	Peer 	review........................ .................................................12 7. Ethical review........................................ ..................148. Academic exchanges and cooperation............ ................................................................. ..... 179. Intellectual property protection...................................... .................................. 1810. Training and guidance............ 	................................................................. 	........ 	1911. 	Supervision 	and management............................. ......................................... twenty one 

 

Guidelines for Responsible Research Conduct (2023) Responsible scientific research is an important guarantee for promoting the healthy development of science and technology, and is an inevitable requirement for achieving high-level scientific and technological self-reliance. In order to guide scientific researchers and scientific research institutions, universities, medical and health institutions, enterprises, etc. (hereinafter collectively referred to as "scientific research institutions") to carry out responsible scientific research, the Supervision Department of the Ministry of Science and Technology organized the preparation of the "Guidelines for Responsible Research Conduct" and proposed Scientific ethics and academic research norms that should be generally followed in scientific research practice. 

1. Research Topic Selection and Implementation 

Research topics should adhere to the "four aspects", highlight the problem orientation, comply with the requirements of science and technology ethics and science and technology safety regulations, avoid simple duplication or low-level research, avoid being divorced from reality or blindly pursuing hot topics, and must not conduct research prohibited by laws and regulations. The application, implementation and final acceptance of research projects should comply with relevant regulations, and necessary resources should be invested in the research process. 

(1) Scientific researchers 

The selection of research topics should consider the scientificity, innovation, applicability and feasibility of the research. After sufficient literature review, investigation and scientific demonstration, combined with the necessary resource conditions to complete the research, the difficulties and doubts in the research field should be sought. , blank spot. If the purpose is not verification, you should avoid simply repeating research that has been carried out by others. 

Application materials for research projects should be true, accurate and objective. The same or similar research content shall not be used for repeated declarations, and others shall not be listed as members of the research team without consent. It is not allowed to plagiarize, buy, sell or ghostwrite application materials, and it is not allowed to use generative artificial intelligence to directly generate application materials. 

Research funding budgets should be prepared in accordance with relevant regulations and actual needs, and research funding should be used rationally and prudently. Expenses for completed research or expenses unrelated to the applied project must not be included in the budget. 

It is not allowed to seek improper benefits from the review organizer, its staff, review experts, etc., directly or indirectly, explicitly or implicitly. 5. The time and energy required for research should be ensured, and the number of projects hosted and mainly participated in during the same period should comply with the restrictions of the relevant funders. The implementation of research should be rigorous and scientific, with appropriate methods and technical means. The mission statement or contract obligations should be strictly performed. The target tasks and agreed requirements should not be arbitrarily reduced. Research tasks should not be subcontracted or subcontracted to others in violation of regulations, and irrelevant research results should not be used as offsets. Crossover. 6. In activities such as research topic selection, project application, research implementation, project acceptance, and participation in project review as an expert, possible conflicts of interest should be promptly identified and proactively declared to avoid affecting the objectivity and impartiality of the research or review, and damaging the interests of others or society. 

7. Relevant regulations on security and confidentiality, fund use, resource and data sharing, and intellectual property ownership should be strictly observed. Use generative artificial intelligence appropriately and in compliance with regulations to participate in research implementation. 

(2) Scientific research units 

Review and check the scientific research integrity of the project applicant and the authenticity and completeness of the application materials, and make good scientific research integrity a prerequisite for application. 

Fulfill the main responsibilities, provide necessary supporting conditions, track research progress in a timely manner, and strengthen full-process management of research activities. 

2. Data management 

The collection and recording of research data should be complete, accurate, and traceable, and the storage and use should comply with professional norms and management regulations to ensure data quality and data security.  

(1) Scientific researchers 

1. Data collection operating specifications should be strictly implemented, appropriate data collection methods should be selected, and research data should be collected objectively, completely, and accurately. 2. Record the research process and experimental data promptly and accurately to ensure the integrity, objectivity and traceability of research records and data. Data must not be recorded or used selectively to obtain specific results. 

3. If written records are used, an experimental record book with continuous page numbers and that meets the storage requirements should be selected; the original data, charts, photos, etc. generated by the experiment should be pasted in the corresponding positions of the experimental record book in an orderly manner and marked in detail. Corrections to the record should be made by the original recorder, and the original content must not be obscured. The reason for the correction should be stated and signed. Do not alter data or destroy any part of the notebook. It is not allowed to fabricate or tamper with original data, or save artificially processed data as original data. If electronic records are used, they should be combined with experimental records 

Correlate and ensure that the data and generation time have not been artificially changed. 4. If you use data that has not been officially published by others, you must obtain the consent of the data owner in advance and explain the source of the data. 

5. The use, dissemination, copying, storage, deletion, etc. of data should comply with the requirements of the "Data Security Law", "Personal Information Protection Law", "Scientific Data Management Measures", etc. The collection of human experiment data or sensitive data involving privacy and confidentiality should strictly abide by relevant laws, regulations and ethical norms, and can only be carried out after obtaining the informed consent of the relevant personnel or the approval of an agency with approval authority. The data may not be used for purposes other than the agreed purpose, or the data may be transferred or disclosed to other institutions or persons without consent. 6. When analyzing and processing data, appropriate analysis methods and processing methods should be used to comprehensively, clearly and accurately reflect the research process and research results, and explain them in detail in the research report. 

When processing academic images, you should comply with the specifications of the corresponding discipline or academic publishing unit, and indicate the portion of the academic image that is processed when publishing. The key information contained in the original academic image shall not be changed, blurred, eliminated or distorted, and the academic image shall not be subjected to inappropriate or deceptive processing, including adding, removing or moving objects, removing or blurring the background, etc. The spliced combined pictures should add obvious dividing lines between each group of pictures, or clearly explain the splicing of the pictures. Other pictures not obtained under the conditions of this experiment may not be used to replace the real experimental pictures, and the source or source must be indicated to directly use pictures from other people's research results. 

After the research results are published, it is recommended that they be published without violating confidentiality and intellectual property regulations. 

Under this circumstance, the original data involved, as well as methods, reagents, software, source code and other materials involved should be submitted or openly shared in an appropriate manner to improve the application value of the data. 9. Organize, save, and back up research data in a timely manner, and take effective measures to prevent data from being lost, leaked, damaged, or tampered with. 

10. Properly preserve all experimental records, experimental data (including unpublished data, negative data, etc.) and experimental notebooks in accordance with the regulations of the subject field or the scientific research unit where you are located, and preserve experimental samples in accordance with relevant technical specifications. Within one month after the publication of research results such as papers, the experimental records, experimental data and other original materials involved should be submitted to the scientific research unit for centralized archiving, or in accordance with the relevant management regulations of the scientific research unit. 11. The project leader should supervise the collection, storage and utilization of data, conduct necessary inspections or verifications on the collected data to ensure that the data is reliable, and properly preserve all records and original data within the specified period. 12. When it is discovered from the research data that there may be a serious impact or threat to public health, ecological environment, public security or social order, it should be promptly and proactively reported to the relevant departments. Data release should comply with relevant regulations, remain transparent and objective, and avoid intentionally highlighting, emphasizing or concealing or ignoring specific content. 13. Relevant laws, regulations and academic norms should be followed, and generative artificial intelligence should be used reasonably to process text, data or academic images in accordance with regulations to prevent risks such as forgery and tampering with data. 14. It is not allowed to obtain experimental research data by paying third-party organizations or others without actually conducting the research. When the conditions are not met to entrust a third-party organization to conduct experiments or data collection, the scientific researchers should propose an experimental design plan and Conduct analysis and research based on original experimental records and data provided by third-party institutions, and the source of the data should be stated when publishing. The use of third-party survey statistics or relevant public database data should be obtained through legal channels, and the source or source should be indicated. (2) Scientific research units 

Establish a management system and quality control system for research data, and clearly stipulate and strictly implement the collection, collection, storage, ownership, use, sharing, confidentiality, and security of data. Regular inspections are carried out to ensure that the original records of research activities are timely, accurate, complete, properly preserved, and queryable and traceable. 2. Provide guarantees in terms of software and hardware facilities, funds and personnel required for research data storage, management, services and security. According to the characteristics of research activities, original recording media in a unified format, continuously numbered, and easy to use are produced and properly preserved and archived. 3. Literature citations 

Researchers should clearly distinguish their own research results from those of others in project applications, final reports, papers or other research results. When referring to other people's opinions or research results, they should be realistic and accurate, and indicate the source in an appropriate manner. 1. If you refer to or draw on other people’s academic opinions, research ideas, or published works in your research, you should indicate it in the form of citations, notes, acknowledgments, etc. in accordance with the general standards or norms of this discipline. 

Quote original documents as much as possible. If it is necessary to cite original documents cited or summarized by other authors due to inability to obtain original documents or other reasons, they should be marked as quotations and strive to be accurate. 

Be objective and accurate when quoting other people’s documents, and avoid misquoting or quoting out of context. You should not cite results in unfamiliar research fields, you should not cite without understanding the research content or progress, and you should not intentionally distort, elevate, or belittle other people's academic opinions or research findings. In principle, retracted articles will not be cited except for critical purposes. 

Content generated using generative artificial intelligence, especially when it involves key content such as facts and opinions, should be clearly labeled and explained its generation process to ensure authenticity and accuracy and respect for the intellectual property rights of others. Content that has been marked as generated by artificial intelligence by other authors should generally not be cited as original literature. If it is indeed necessary to cite it, an explanation should be given. 5. If you use charts or pictures that have been published by others, you should obtain permission from the copyright owner in advance and use it within the scope of permission, and indicate the source or source. 6. You should not deliberately ignore or conceal relevant and important literature published by others or literature that is detrimental to your own research. 

7. Documents that have not been referenced or are not relevant to the research content should not be included in the references, including inappropriate self-citation, cross-citation in agreement with others, or citation of irrelevant documents according to the requirements of reviewers and editors, etc. References generated by generative AI may not be used directly without verification. 4. Signature of results 

The signer should have made substantial academic contributions, that is, made important contributions to research ideas, design, implementation, data acquisition, data analysis and interpretation, etc., or made critical revisions to important intellectual content. Those who have no substantial academic contribution to the results shall not be signed. 

1. All signatories should review and agree in advance to publish the results with their signatures, and are responsible for the content that they have completed or participated in. The first completer, first author and corresponding author bear primary responsibility for the authenticity and reliability of the results. 2. All signatories should make substantial academic contributions to the results and may not be named or impersonated. If you find that you have been named or impersonated, you should take the initiative to raise questions and request corrections. 3. The order of signatures is usually arranged according to the size of the contribution to the results. It should generally be decided jointly by all those who completed the results, or follow the signature conventions of relevant disciplines. 4. For individuals and organizations that are not eligible for authorship but have contributed or helped the research work, their contributions can be explained through acknowledgments, notes, etc. 5. For funded research results, the funding agency, project name and approval number should be truthfully labeled as required. For project results funded by multiple institutions, in principle, they will be sorted by the size of their contribution to the results. Projects that are irrelevant to research work or that are false shall not be marked. Do not withhold funding sources, withhold true authorship information, or fictitious authorship to conceal a conflict of interest. 

6. The main unit that completes the results shall not be changed at will due to changes in the work unit of the person who completed the results. Personal information such as work unit and job title shall not be fabricated or falsified. 7. Generative artificial intelligence shall not be listed as a cocontributor of the results. The main methods and details of using generative AI should be disclosed in relevant places such as research methods or appendices. 5. Publication of results 

When publishing or distributing papers, monographs and other results, you should fully state the research process, clearly introduce the research methods, accurately describe the research conclusions, and submit or share relevant data as required to facilitate others to repeatedly verify and judge the reliability of the research results. (1) Scientific researchers 

1. Research results should first be published through the peer review process, or communicated within the scientific community through academic reports, academic seminars, preprints, etc. Publication of breakthrough research results and major research progress must be approved by the scientific research institution where the applicant is located. Research results that have not been scientifically verified or peer reviewed may not be disseminated to the public. 2. The publishing unit of the results to be published, the database containing the results, etc. should be verified to avoid publishing units that lack quality assurance or are false. 3. The same manuscript reporting research results or manuscripts based on the same data with only minor differences may not be submitted to two or more publishing units for publication at the same time. Only after receiving a rejection notice, or exceeding the prescribed review period, or applying to withdraw the submission and receiving confirmation from the publishing unit, can the manuscript be transferred to another publishing unit. If the work is jointly completed by multiple authors, the consent of all authors must be obtained before the decision is made to resubmit. 4. Published papers or their data, pictures, etc. are not allowed to be republished, and parts of multiple published papers are not allowed to be pieced together to create "new results" for publication. If it is really necessary to republish, permission must be obtained from the published and to-be-published publishing units in advance. When re-publishing, an explanation should be made in a prominent position and the original publication location should be noted. 5. A complete research result shall not be split into several results for publication in order to maintain the integrity, systematicness, scientificity and logic of the relevant results, and results signed by different authors based on the same research content shall not be written. 6. The first completer, first author and corresponding author are responsible for ensuring that all signatories agree to publish and recognize the final results. 

7. When publishing results, you should declare conflicts of interest and indicate the source of funding for the research results as required. 

(2) Scientific research units 

1. Strengthen the management of research results published by scientific researchers, and establish systems such as integrity commitments for publishing research results, collection and verification of original data, traceability of research processes, inspection and reporting of research results, etc. For projects supported by fiscal funds, scientific researchers should be urged to submit relevant scientific and technological reports as required. For those who publish multiple papers, obtain multiple patents and other achievements in a short period of time, verification and verification should be strengthened in accordance with regulations. Results that scientific researchers plan to publish involving confidential or sensitive information will be reviewed and checked in accordance with relevant regulations. 2. Those who publish research results in academic journals that are included in the early warning list should be promptly warned; research results published in academic journals that are included in the "blacklist" will not be recognized in various reviews and evaluations. , and related publication expenses will not be reimbursed. 3. If the academic papers and other research results published by the scientific researchers of the unit violate the requirements of scientific research integrity, the relevant responsible persons should be severely dealt with and required to take measures such as withdrawing the papers. 

(3) Academic publishing units 

 

1. Establish and improve systems such as peer review, ethics supervision, copyright management, academic standard commitment, handling of objections to retractions, and conflict of interest management, and establish a management and supervision system for editors, editorial board members, and reviewers. 2. Clarify the publication standards of research results through the "Call for Papers" and "Instructions for Authors", etc., and may require the contribution of each signatory to be stated when publishing the results. 3. Authors should be required to disclose whether they use generative artificial intelligence, indicate the specific software name, version and time of use, and make specific annotations for auxiliary generated content involving citations of facts and opinions. 

4. Records of original submissions, review comments, revised drafts, correspondence, and editorial rejection or acceptance decisions of published research results should be kept for at least 3 years for verification. 5. Scientific research dishonesty in authors’ submissions should be detected and screened, and complaints and reports about scientific research dishonesty should be accepted. For manuscripts with scientific research dishonesty or serious errors, measures such as commenting, attention, correction, and withdrawal should be taken, and the relevant databases that include the research results and the author's unit should be promptly informed. 6. Reasonably select reviewers, urge reviewers to conduct serious and fair reviews, and conduct corresponding supervision and evaluation of their compliance with scientific research integrity requirements. Reviewers are reminded to be cautious when using generative artificial intelligence during the review process. You shall not exert undue influence on the reviewer's compliance review, or negate or distort the reviewer's review opinion without reason. 7. Editors and reviewers are not allowed to disclose, publicly discuss, plagiarize or appropriate the author’s unpublished research results without authorization; they are not allowed to deliberately delay the review or publication progress; they are not allowed to take advantage of the publishing process and the content of the manuscript to seek improper interests; and they are not allowed to increase the influence of the journal. Authors are asked to cite specific literature where necessary. 

8. Comply with relevant regulatory requirements on conflicts of interest. Editors should be required not to conceal their interest relationships with contributors, or intentionally select reviewers with potential or actual interests or conflicts of interest to review manuscripts. 6. Peer review 

Peer review is an important reference for research resource allocation, acceptance of research results, publication of research results, talent evaluation, science and technology awards, professional title promotion, etc. Review activity organizers and reviewers should ensure the scientificity, authority, objectivity and fairness of the peer review process and create a good peer review ecosystem. Researchers should actively participate in peer review activities. 

3. Reviewer 

1. Carry out review work objectively, fairly and rigorously, respect the dignity and academic autonomy of the reviewees, respect different academic viewpoints, and put forward review opinions and suggestions constructively. Comments must not contain words or comments that are insulting, deliberately disparaging, or unfair. Comments should not be influenced by non-academic factors. 2. Participants should participate in peer reviews based on their own professional knowledge and abilities, and should not participate in review work that is unfamiliar to the matters being reviewed or related research directions or that cannot be completed within the specified time. 3. Provide specific and detailed comments and explain reasons or evidence when necessary. You are not allowed to ask others to review or write reviews on your behalf. 4. If there is a conflict of interest with the person being reviewed, you should take the initiative to explain the situation to the review organizer, and actively recuse yourself as required or let the review organizer decide whether to participate in the relevant review. 

5. Strictly abide by the disciplines of the review work, and are not allowed to accept requests such as "saying hello" or "building relationships", and are not allowed to ask for or accept gifts or other gifts from stakeholders. 6. Keep the review content and process confidential as required. Do not copy or spread the reviewed materials without authorization, and do not disclose information such as review objects, expert opinions, review conclusions, etc. that need to be kept confidential. The opinions, data and methods of the person being reviewed are not allowed to be used, shared or discussed with others outside the peer review process. The opinions, data and methods of the person being reviewed are not allowed to be used without permission. Reviewers are not allowed to ask the person being reviewed to cite their own literature. 7. When using generative artificial intelligence in review activities, the consent of the organizer of the review activity should be obtained in advance. The review content should be prevented from being leaked during the operation. If information leakage occurs, necessary remedial measures should be taken in a timely manner. 

8. If during the review process, any violation of scientific research integrity, science and technology ethics, science and technology safety and confidentiality is discovered or has legitimate reasons, it should be reported to the organizer of the review activity in a timely manner. (2) Reviewee 

Ensure that the materials provided are true, reliable, and accurate, and clearly indicate the source or attribution of all research results, and do not include the research results of other projects or other personnel without explanation. 

If you believe that a reviewer has a conflict of interest with you, you should report it to the organizer of the review activity in accordance with the procedures, request the reviewer to recuse yourself, and provide sufficient and reliable reasons. 3. Do not interfere with the review process, do not contact privately or bribe or threaten reviewers or review activity organizers. 

4. If you have any objection to the evaluation results, you should submit a review application in accordance with relevant procedures. Do not threaten, attack or retaliate against reviewers or review organizers. (3) Review activity organizers 1. Develop scientific, fair and transparent review rules and procedures, and establish reviewer selection, avoidance, work supervision and credit evaluation systems. 2. Strictly perform duties and promptly discover and control possible conflicts of interest. Maintain the independence of review and do not interfere with the legitimate review of reviewers by the will or authority of the organizer or individual. 

Comply with confidentiality requirements and shall not disclose information such as the list of review objects or reviewers, review opinions, review results, etc. in violation of regulations. 

Any scientific research dishonesty discovered during the review will be dealt with in accordance with relevant regulations. 7. Ethical review 

Science and technology ethics are the values and behavioral norms that should be followed when carrying out scientific research and technological development and other scientific and technological activities. Scientific and technological activities should be carried out in accordance with the principles of "enhancing human welfare, respecting the right to life, adhering to fairness and justice, reasonably controlling risks, and maintaining openness and transparency", and conduct scientific and technological ethical risk assessments or scientific and technological ethics reviews in accordance with regulations. Behaviors that violate the requirements of scientific and technological ethics should be proactively reported, resolutely resisted, and severely investigated and punished.  

(1) Scientific researchers 

1. Students should learn science and technology ethics knowledge and relevant management regulations, improve their awareness of science and technology ethics, strictly abide by science and technology ethics norms, and actively participate in science and technology ethics governance. 2. Scientific and technological activities involving human research participants, experimental animals, and scientific and technological activities that do not directly involve humans or animals but may bring ethical risks and challenges in aspects such as life and health, ecological environment, public order, and sustainable development should be carried out. Conduct scientific and technological ethics review in accordance with regulations. Research can only be carried out after obtaining approval, and must not exceed the scope of the approved implementation plan for scientific and technological activities. 

3. Research participants should be selected fairly and reasonably to ensure the scientificity, rationality, appropriateness and fairness of their inclusion and exclusion criteria. Research participants shall not be recruited through inducement, coercion, deception, or other improper means. Special protection should be given to research participants involving specific groups such as children, pregnant women, the elderly, people with intellectual disabilities, and people with mental disorders; research involving fertilized eggs, embryos, fetuses, or those that may be affected by assisted reproductive technology should be proactively protected Detailed description. 4. Research participants or their guardians should be clearly informed of all relevant matters and rights they should enjoy, obtain informed consent, ensure that the informed consent process is standardized, and strictly implement agreements or agreements with research participants or their guardians. 5. The collection, storage, use and disposal of biological samples must comply with relevant laws and regulations, and the processing of personal privacy data, biometric information, etc. must comply with relevant regulations on personal information protection. 

It should be ensured that research is conducted by personnel with relevant qualifications to ensure that research risks are minimized and unnecessary harm to research participants is avoided. If there is reason to believe that death or disability or other injuries will result before the start of the test, the test shall not be carried out; if there are signs during the test that death or disability or other injuries may result, the test must be stopped immediately. 

To carry out scientific and technological activities involving experimental animals, the use of experimental animals should comply with the principles of substitution, reduction, and optimization, ensuring that the sources of experimental animals are legal and reasonable, and that technical operation requirements such as breeding, use, and disposal comply with animal welfare standards. 8. When carrying out scientific and technological activities involving emergencies such as major public incidents, the scientific and technological ethics emergency review procedures and related requirements shall be observed. Emergency situations shall not be used as an excuse to avoid scientific and technological ethics review or lower the standards of scientific and technological ethics review. 9. To carry out scientific and technological activities that are included in the management of the ethical review review list, after passing the preliminary review by the Science and Technology Ethics (Review) Committee, the scientific research unit should be reported to the local or relevant industry authorities to organize expert review through the scientific research unit. 10. International cooperative scientific and technological activities that require scientific and technological ethics review must pass the scientific and technological ethics review stipulated by the countries where the cooperation parties are located before they can be carried out.  

(2) Scientific research units 

Fulfill the main responsibilities of science and technology ethics management, strengthen science and technology ethics supervision and risk monitoring throughout the entire process of science and technology activities, and actively study and judge and resolve science and technology ethics risks in a timely manner. When carrying out scientific and technological activities that are included in the ethical review review list management, dynamic tracking and ethical risk prevention and control should be strengthened. 

Establish a science and technology ethics (review) committee in accordance with the actual situation of the unit and provide it with necessary staff, office space, funding and other conditions to perform its duties, and take effective measures to ensure that it independently carries out science and technology ethics review work. 3. Improve the unit’s science and technology ethics review supervision mechanism and review quality control, supervision and evaluation mechanism, guide the science and technology ethics (review) committee to formulate charters, and establish system specifications, work procedures and conflict of interest management mechanisms for review, supervision, confidentiality management, file management, etc. , ensuring that science and technology ethics review is compliant, transparent, and traceable. 4. Regularly carry out science and technology ethics education and training to improve the ethical awareness and risk prevention and control capabilities of scientific researchers. 

4 . Academic exchanges and cooperation 

Scientific researchers are encouraged to fully exchange academic opinions, research ideas and research findings, and openly share research data and research results in accordance with relevant requirements. When conducting research together, we should strengthen understanding, mutual respect, and promote mutual trust, conscientiously fulfill our responsibilities, and fulfill our commitments and obligations. Through full consultation, the purpose of cooperation, project indicators, expected outputs, rights and responsibilities of all parties, the ownership and use of data and intellectual property rights, and the basis for measuring the contribution of results will be clarified. 1. When conducting academic exchanges, academic democracy should be promoted, originality should be respected, and openness and transparency should be adhered to. You must not use your authority, status, or resources at your disposal to suppress the academic opinions of others. 2. When conducting academic criticism or responding to criticism and doubts from others, rational questioning and criticism should be carried out in a scientific spirit and professional attitude, and the influence of non-academic factors such as personal grievances and conflicts of interest should be excluded. It is not appropriate to make excessive remarks in public and not to easily Scientific disagreements should be resorted to public opinion or use of online public opinion to coerce academic discussions. Personal attacks and retaliation are not allowed. 

All parties involved in collaborative research should agree in advance on matters such as rights and obligations, responsibilities and division of labor, allocation of funds, publication and signature of results, ownership of research data and results, intellectual property arrangements and dispute settlement mechanisms through agreements and other forms. The costs and benefits of research should be reasonably allocated among the collaborating parties. 

All parties involved in multidisciplinary or interdisciplinary collaborative research should understand the research norms and practices of the relevant disciplines. Differences between different disciplines should be negotiated and reached in advance to ensure compliance. 5. In collaborative research, data sources should be compliant and data quality should be ensured, and data from partners should be verified when necessary. without violating relevant laws 

In collaborative research, data sources should be compliant and data quality should be ensured, and data from partners should be verified when necessary. Under the principle of not violating relevant laws, regulations and confidentiality provisions, relevant research data and research results should be disclosed to collaborators as agreed. 6. In international collaborative research, the relevant regulations on scientific research management and supervision of our country and the country or region where the partner is located should be strictly observed. If you discover or have legitimate reasons to suspect that a partner has engaged in scientific research dishonesty or violated scientific and technological ethics, you should immediately notify the partner and suspend or terminate the cooperation if necessary. 

7. If relevant data needs to be provided in foreign scientific and technological exchanges and cooperation, the approval procedures must be completed in accordance with relevant requirements, and relevant laws and regulations on scientific and technological confidentiality and the publication of specific research results must be strictly observed. 

9. Intellectual Property Protection 

When carrying out scientific and technological activities, one should respect the intellectual property rights of others, abide by my country's intellectual property laws and regulations and relevant international conventions, and strengthen the intellectual property protection, management and application of research results. 

(1) Scientific researchers 

Before publishing research results, the intellectual property protection plan for the research results should be fully considered and reasonable and appropriate intellectual property protection methods should be adopted. If patent protection is adopted, the patent application shall truthfully provide materials in accordance with relevant regulations, and shall not fabricate, forge, or alter the content of the proposed application, experimental data, or exaggerate the technical effects, and shall not plagiarize, simply replace, or piece together existing technology or existing designs. 

Comply with the laws, regulations and institutional norms of the state and the scientific research unit regarding the ownership of intellectual property rights and the distribution of interests in research results, and promptly and proactively disclose job research results to the scientific research unit where the researcher works. 

Respect the intellectual property rights of others and do not infringe upon the legitimate rights and interests of intellectual property rights holders. Improve the ability to protect intellectual property rights, take effective measures to protect the intellectual property rights of important research results, properly handle intellectual property disputes, and safeguard their legitimate rights and interests in accordance with the law.  

(2) Scientific research units 

Improve the intellectual property management system and explore the establishment of specialized internal institutions for the transfer and transformation of intellectual property rights. 

Improve the intellectual property management system, clarify the ownership of intellectual property rights and benefit distribution mechanisms for research results, and encourage the creation of intellectual property. Actively promote the transformation and application of research results and safeguard the legitimate rights and interests of scientific researchers. 

Strengthen intellectual property risk management, improve scientific researchers’ awareness of intellectual property risk prevention, and carry out regular intellectual property risk warnings and infringement risk investigations. 4. Conduct regular intellectual property training to improve intellectual property management service capabilities and create a good atmosphere that respects creation and intellectual property rights. 10. Training and guidance 

Tutors and project leaders should strengthen guidance and supervision of students and research team members. Scientific research units should focus on cultivating scientific researchers' rigorous and serious academic attitudes and truth-seeking and pragmatic scientific spirit, and encourage them to abide by scientific ethics and scientific and technological ethics. (1) Graduate tutors and project leaders 1. Practice the requirements of being a teacher and being a role model, give full play to the role of teaching by words and deeds, and regularly provide education and guidance on scientific research integrity, science and technology ethics, etc. to students and research team members. 2. It should ensure that there is sufficient time and energy to guide students and research teams, and provide necessary research resource support. 

Understand and supervise the daily scientific research activities of students and research team members, follow up and guide experimental progress, review experimental records and data, review research manuscripts, sign signatures of important papers and other research results, research data authenticity, and experimental repeatability etc. for integrity review and academic control. Students and research team members shall not be required or acquiesced in any way to commit scientific research dishonesty or other violations of scientific and technological activities. 

Adhere to academic democracy and respect the academic opinions and reasonable requirements of students and research team members for research work. The legitimate rights and interests of students and research team members shall not be infringed upon in aspects such as authorship of results and ownership of intellectual property rights. (2) Students and research team members 1. Invest sufficient time and energy to complete the research tasks assigned by the mentor or project leader, and respect the training and dedication of the scientific research unit, mentor, and project leader. 2. Comply with scientific research management regulations and related requirements, report research progress to the instructor and project leader in a timely manner, collect and save experimental records, data, etc. in accordance with regulations to ensure that the research process is authentic, transparent, and traceable. 

3. The announcement, publication or transfer of research results obtained using the research funds, experimental equipment, data materials, etc. of the scientific research unit or team project must comply with relevant regulations. 4. Before leaving school after graduation or leaving the scientific research unit or research team, all original data, pictures, experimental records, samples and other scientific research materials should be returned in accordance with regulations. They are not allowed to take them away without permission. Regarding the permission to use data obtained or accessed from the original unit, the relevant regulations or prior agreement of the original unit shall be followed.  

(3) Scientific research units 

Qualified scientific research units should incorporate scientific research integrity, science and technology ethics, etc. into the curriculum system and allocate corresponding teachers. 

Establish and improve the education and training system for scientific research integrity and science and technology ethics, carry out scientific research integrity and science and technology ethics training at important points such as enrollment, professional title promotion, and participation in projects, strengthen daily education guidance, and provide scientific research for students and researchers in need Provide consultation and guidance on integrity and science and technology ethics, and provide timely reminders and conversations to personnel with tendencies and emerging problems. 

Encourage the development of popular science propaganda on scientific research integrity and science and technology ethics for the public, and guide the public to rationally view the issues of scientific research integrity and science and technology ethics in the development of science and technology.  

 

5. Supervision and management 

Adhere to both prevention and punishment, self-discipline and supervision, and prevent and punish irregularities such as dishonesty in scientific research and violations of scientific and technological ethics. Scientific research units should effectively fulfill their main responsibilities, scientific research funding agencies should strengthen supervision of funded projects, the scientific community should play a role in self-discipline and self-purification, and scientific researchers should stick to the bottom line and consciously practice good academic styles.  

(1) Scientific research units 

1. Establish and improve internal management systems and working mechanisms, and incorporate scientific research integrity, scientific and technological ethics, etc. into normal management. For those who violate the regulations on project application and implementation, fund use, review and evaluation, etc., as well as the requirements for scientific research integrity and scientific and technological ethics, we must dare to expose shortcomings, not accommodate or cover up, seriously investigate and deal with them, and publicly expose them. 2. Organize or entrust a thirdparty organization to conduct a comprehensive verification of important academic papers and other research results of the unit's scientific researchers. The verification work should be carried out continuously on a 3-5 year cycle. 

3. Equip corresponding full-time and part-time personnel to carry out regular work such as monitoring of paper retractions, verification of original experimental data, and review of scientific research integrity involving scientific researchers of the unit.  

(2) Scientific research funding agencies 

1. Embed scientific research integrity, science and technology ethics and other relevant requirements into the entire management process of project guide preparation, review and project establishment, process management, project completion and acceptance, supervision and evaluation, etc., establish and improve prevention, supervision and investigation and punishment mechanisms, and carry out investigation and punishment according to regulations. 2. Before approval of a funded project, the scientific research integrity status of the project applicant, project leader and relevant personnel should be reviewed. If the project is included in the database of serious breaches of trust in scientific research integrity and is within the processing period, a "onevote veto" will be implemented. 3. Designate internal institutions or entrust third-party institutions to supervise and evaluate the implementation of funded projects, and take corresponding measures such as terminating projects, suspending allocations or recovering research funds in accordance with regulations. 

(3) Scientific researchers 

1. If you discover or have reasonable grounds to suspect that others have violated scientific research integrity standards or violated scientific and technological ethical requirements, you should truthfully report it to the relevant institutions in accordance with relevant regulations. 2. Students should consciously accept academic supervision and proactively cooperate with investigations into scientific research dishonesty and project management inspections. 3. When participating as an expert in supervision and management activities such as investigations into scientific research dishonesty, you should proactively disclose possible conflicts of interest and recuse yourself in accordance with regulations. (4) Science and technology social groups 

Scientific and technological social groups such as societies, associations, and research associations must actively play a role in formulating codes of conduct for scientific research activities, providing education and guidance on integrity, and investigating and identifying untrustworthy conduct in scientific research in their respective fields, so as to promote scientific researchers to conduct responsible research and achieve self-regulation. , self-management, self-purification. 1. Self-discipline conventions and professional ethics guidelines for scientific research activities in this field should be formulated and improved based on actual conditions, and education on professional ethics and academic style should be regularly carried out to play the role of selfdiscipline and self-purification. 2. Actively participate in the formulation of relevant institutional norms such as the Code of Conduct for Scientific Research Activities and the Standards for Identification of Untrustworthy Conduct in Scientific Research, and regard compliance with scientific research integrity and scientific and technological ethics as a guide for membership development, award selection, talent recommendation, academician selection, commissioned project evaluation, and youth support projects. and other important conditions for science and technology evaluation activities. Members who violate scientific research integrity standards and scientific and technological ethics requirements will be punished accordingly. 3. Take the initiative to accept the entrustment of the competent department or relevant units and organize and carry out academic investigation activities related to untrustworthy conduct in scientific research. 

4. Set up academic criticism topics, special sections, etc. in hosted conferences and journals, advocate serious academic discussions and comments, encourage young researchers to boldly put forward their own academic opinions, actively communicate and dialogue with academic authorities, and create a free, open, and An equal academic ecosystem.